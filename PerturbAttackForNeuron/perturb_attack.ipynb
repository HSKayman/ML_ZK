{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "544353d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import os\n",
    "import gc\n",
    "from typing import List, Dict, Any, Optional, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a152cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "# from huggingface_hub import login\n",
    "# login()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66818943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "DEVICE = torch.device('cpu')#'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34004cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb78d9e947046d89165e03080665350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# %%\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=DEVICE\n",
    ")\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3adf6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# Distance Metrics for Comparing Logit Distributions\n",
    "# =============================================================================\n",
    "\n",
    "def compute_l2_distance(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "    # apply softmax to the logits\n",
    "    original_logits = F.softmax(original_logits, dim=-1)\n",
    "    perturbed_logits = F.softmax(perturbed_logits, dim=-1)\n",
    "    # Compute L2 (Euclidean) distance between two logit vectors\n",
    "    return torch.norm(original_logits - perturbed_logits, p=2).item()\n",
    "\n",
    "def compute_cosine_distance(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "    # Compute cosine distance (1 - cosine_similarity) between two logit vectors\n",
    "    cos_sim = F.cosine_similarity(original_logits.unsqueeze(0), perturbed_logits.unsqueeze(0))\n",
    "    return (1 - cos_sim).item()\n",
    "\n",
    "def compute_kl_divergence(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "    # Compute KL divergence: KL(original || perturbed) after softmax\n",
    "    original_probs = F.softmax(original_logits, dim=-1)\n",
    "    perturbed_log_probs = F.log_softmax(perturbed_logits, dim=-1)\n",
    "    # KL(P || Q) = sum(P * log(P/Q)) = sum(P * (log_P - log_Q))\n",
    "    kl_div = F.kl_div(perturbed_log_probs, original_probs, reduction='sum')\n",
    "    return kl_div.item()\n",
    "\n",
    "def compute_js_divergence(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "   # Compute Jensen-Shannon divergence: 0.5*KL(P||M) + 0.5*KL(Q||M) where M = 0.5*(P+Q).\n",
    "    P = F.softmax(original_logits, dim=-1)\n",
    "    Q = F.softmax(perturbed_logits, dim=-1)\n",
    "    M = 0.5 * (P + Q)\n",
    "    \n",
    "    # KL(P || M)\n",
    "    kl_pm = F.kl_div(M.log(), P, reduction='sum')\n",
    "    # KL(Q || M)\n",
    "    kl_qm = F.kl_div(M.log(), Q, reduction='sum')\n",
    "    \n",
    "    js_div = 0.5 * (kl_pm + kl_qm)\n",
    "    return js_div.item()\n",
    "\n",
    "def compute_all_distances(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> Dict[str, float]:\n",
    "    # Compute all distance metrics between original and perturbed logits.\n",
    "    return {\n",
    "        'l2_distance': compute_l2_distance(original_logits, perturbed_logits),\n",
    "        'cosine_distance': compute_cosine_distance(original_logits, perturbed_logits),\n",
    "        'kl_divergence': compute_kl_divergence(original_logits, perturbed_logits),\n",
    "        'js_divergence': compute_js_divergence(original_logits, perturbed_logits),\n",
    "    }\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83b8ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# RMSNorm and Gradient-Based Perturbation Functions\n",
    "# =============================================================================\n",
    "\n",
    "def compute_swap_gradient(\n",
    "    z: torch.Tensor,\n",
    "    W: torch.Tensor,\n",
    "    top1_idx: int,\n",
    "    top2_idx: int,\n",
    "    norm_layer: nn.Module,\n",
    "    bias: Optional[torch.Tensor] = None\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    # Compute gradient of swap loss w.r.t. pre-norm activations z.\n",
    "    # The swap loss is: L = p[top1] - p[top2] We want to minimize this (decrease top1 prob, increase top2 prob).\n",
    "    z = z.clone().detach().requires_grad_(True)\n",
    "    \n",
    "    # Forward pass through models RMSNorm\n",
    "    z_norm = norm_layer(z)\n",
    "    \n",
    "    # Compute logits\n",
    "    logits = F.linear(z_norm, W, bias)\n",
    "    \n",
    "    # Compute probabilities\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Swap loss: minimize p[top1] - p[top2]\n",
    "    # Gradient will point in direction that INCREASES this loss\n",
    "    # So we negate it to get direction that DECREASES the loss (achieves swap)\n",
    "    swap_loss = probs[top1_idx] - probs[top2_idx]\n",
    "    \n",
    "    # Backward pass\n",
    "    swap_loss.backward()\n",
    "    \n",
    "    # Return negative gradient\n",
    "    return -z.grad.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db39116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_neurons_by_alignment(\n",
    "    gradient: torch.Tensor,\n",
    "    W: torch.Tensor,\n",
    "    exclude_indices: Optional[List[int]] = None\n",
    ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "    # Rank neurons by alignment: gradient sensitivity weighted by W column norms\n",
    "    # gradient is [hidden_size], W is [vocab_size, hidden_size]\n",
    "    # W[:,i] column norm tells us how much neuron i affects outputs\n",
    "    \n",
    "    w_col_norms = torch.norm(W, dim=0)  # [hidden_size]\n",
    "    projections = gradient * w_col_norms  # [hidden_size]\n",
    "    \n",
    "    # Scores are absolute values\n",
    "    scores = torch.abs(projections)\n",
    "    \n",
    "    # If excluding certain neurons, set their scores to -inf so they're ranked last\n",
    "    if exclude_indices is not None and len(exclude_indices) > 0:\n",
    "        for idx in exclude_indices:\n",
    "            scores[idx] = -float('inf')\n",
    "    \n",
    "    # Sort by score descending\n",
    "    sorted_scores, sorted_indices = torch.sort(scores, descending=True)\n",
    "    \n",
    "    # Get signs for perturbation direction\n",
    "    signs = torch.sign(projections)\n",
    "    \n",
    "    return sorted_indices, sorted_scores, signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa7b78b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_special_node(\n",
    "    gradient: torch.Tensor,\n",
    "    W: torch.Tensor\n",
    ") -> Tuple[int, float]:\n",
    "    #special_node_idx: Index of the special neuron\n",
    "    # special_node_score: Its impact score\n",
    "\n",
    "    w_col_norms = torch.norm(W, dim=0)  # [hidden_size]\n",
    "    projections = gradient * w_col_norms  # [hidden_size]\n",
    "    scores = torch.abs(projections)\n",
    "    \n",
    "    special_node_idx = torch.argmax(scores).item()\n",
    "    special_node_score = scores[special_node_idx].item()\n",
    "    \n",
    "    return special_node_idx, special_node_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f73eed8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_neurons_for_swap(\n",
    "    z: torch.Tensor,\n",
    "    W: torch.Tensor,\n",
    "    epsilon: float,\n",
    "    norm_layer: nn.Module,\n",
    "    bias: Optional[torch.Tensor] = None,\n",
    "    max_neurons: Optional[int] = None,\n",
    "    exclude_neurons: Optional[List[int]] = None,\n",
    "    special_node_idx: Optional[int] = None\n",
    ") -> Dict[str, Any]:\n",
    "    # Find minimum number of neurons to perturb to achieve a swap of top-1 and top-2 predictions.\n",
    "\n",
    "    hidden_size = z.shape[-1]\n",
    "    if max_neurons is None:\n",
    "        max_neurons = hidden_size\n",
    "    \n",
    "    # Compute original probabilities and find top-1, top-2\n",
    "    z_norm = norm_layer(z)\n",
    "    original_logits = F.linear(z_norm, W, bias)\n",
    "    original_probs = F.softmax(original_logits, dim=-1)\n",
    "    \n",
    "    top2_values, top2_indices = torch.topk(original_logits, 2)\n",
    "    top1_idx = top2_indices[0].item()\n",
    "    top2_idx = top2_indices[1].item()\n",
    "    \n",
    "    # Compute gradient direction for swap\n",
    "    gradient = compute_swap_gradient(z, W, top1_idx, top2_idx, norm_layer, bias)\n",
    "    \n",
    "    # Rank neurons by alignment with gradient (excluding specified neurons)\n",
    "    sorted_indices, sorted_scores, signs = rank_neurons_by_alignment(gradient, W, exclude_neurons)\n",
    "    \n",
    "    # Greedy selection - add neurons one by one\n",
    "    z_mod = z.clone()\n",
    "    perturbed_neurons = []\n",
    "    perturbations = {}\n",
    "    special_node_used = False\n",
    "    special_node_rank = None\n",
    "    \n",
    "    # Track where special node appears in ranking\n",
    "    if special_node_idx is not None:\n",
    "        for rank, idx in enumerate(sorted_indices):\n",
    "            if idx.item() == special_node_idx:\n",
    "                special_node_rank = rank\n",
    "                break\n",
    "    \n",
    "    for i in range(min(max_neurons, hidden_size)):\n",
    "        neuron_idx = sorted_indices[i].item()\n",
    "        \n",
    "        # Skip if this neuron has -inf score (was excluded)\n",
    "        if sorted_scores[i] == -float('inf'):\n",
    "            continue\n",
    "        \n",
    "        # Check if we're using the special node\n",
    "        if special_node_idx is not None and neuron_idx == special_node_idx:\n",
    "            special_node_used = True\n",
    "        \n",
    "        # sign(v Â· W[:,i]) * epsilon\n",
    "        delta = signs[neuron_idx].item() * epsilon\n",
    "        z_mod[neuron_idx] += delta\n",
    "        \n",
    "        perturbed_neurons.append(neuron_idx)\n",
    "        perturbations[neuron_idx] = delta\n",
    "        \n",
    "        # Check if swap is achieved\n",
    "        z_mod_norm = norm_layer(z_mod)\n",
    "        new_logits = F.linear(z_mod_norm, W, bias)\n",
    "        new_probs = F.softmax(new_logits, dim=-1)\n",
    "        \n",
    "        new_top1_idx = torch.argmax(new_logits).item()\n",
    "        \n",
    "        # Swap achieved if original top-2 is now top-1\n",
    "        if new_top1_idx != top1_idx:\n",
    "            return {\n",
    "                'success': True,\n",
    "                'num_neurons': len(perturbed_neurons),\n",
    "                'neuron_indices': perturbed_neurons,\n",
    "                'perturbations': perturbations,\n",
    "                'z_modified': z_mod,\n",
    "                'original_probs': original_probs,\n",
    "                'final_probs': new_probs,\n",
    "                'original_logits': original_logits,\n",
    "                'final_logits': new_logits,\n",
    "                'original_top1': top1_idx,\n",
    "                'original_top2': top2_idx,\n",
    "                'final_top1': new_top1_idx,\n",
    "                'special_node_used': special_node_used,\n",
    "                'special_node_rank': special_node_rank,\n",
    "            }\n",
    "    \n",
    "    # Failing to achieve swap within max_neurons\n",
    "    z_mod_norm = norm_layer(z_mod)\n",
    "    final_logits = F.linear(z_mod_norm, W, bias)\n",
    "    final_probs = F.softmax(final_logits, dim=-1)\n",
    "    \n",
    "    return {\n",
    "        'success': False,\n",
    "        'num_neurons': len(perturbed_neurons),\n",
    "        'neuron_indices': perturbed_neurons,\n",
    "        'perturbations': perturbations,\n",
    "        'z_modified': z_mod,\n",
    "        'original_probs': original_probs,\n",
    "        'final_probs': final_probs,\n",
    "        'original_logits': original_logits,\n",
    "        'final_logits': final_logits,\n",
    "        'original_top1': top1_idx,\n",
    "        'original_top2': top2_idx,\n",
    "        'final_top1': torch.argmax(final_logits).item(),\n",
    "        'special_node_used': special_node_used,\n",
    "        'special_node_rank': special_node_rank,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e5ee6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_logit_shift_for_swap(p_top1: float, p_top2: float) -> float:\n",
    "    # Compute the required logit shift to swap top-1 and top-2.\n",
    "    # Convert probabilities to logits (log-odds)\n",
    "    # For softmax with 2 classes: logit_diff = ln(p1/p2)\n",
    "    # We need to flip the sign of this difference\n",
    "    \n",
    "    eps = 1e-10\n",
    "    p_top1 = max(min(p_top1, 1 - eps), eps)\n",
    "    p_top2 = max(min(p_top2, 1 - eps), eps)\n",
    "    \n",
    "    # The logit gap we need to overcome\n",
    "    logit_gap = np.log(p_top1 / p_top2)\n",
    "    \n",
    "    # Need to shift by at least this much\n",
    "    return abs(logit_gap) + 0.1  # Small margin for numerical stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38cfd3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_required_alpha(\n",
    "    z: torch.Tensor,\n",
    "    W: torch.Tensor,\n",
    "    p_top1: float,\n",
    "    p_top2: float\n",
    ") -> float:\n",
    "   \n",
    "    # Compute RMS of z\n",
    "    rms_z = torch.sqrt(torch.mean(z ** 2)).item()\n",
    "    \n",
    "    # Average weight column norm (layer gain)\n",
    "    w_col_norms = torch.norm(W, dim=0)  # [hidden_size]\n",
    "    avg_w_norm = w_col_norms.mean().item()\n",
    "    \n",
    "    # Required logit shift\n",
    "    delta_logit = compute_logit_shift_for_swap(p_top1, p_top2)\n",
    "    \n",
    "    # Estimator from equation\n",
    "    alpha_total = (rms_z / avg_w_norm) * delta_logit\n",
    "    \n",
    "    return alpha_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f15907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_neurons_with_adaptive_epsilon(\n",
    "    z: torch.Tensor,\n",
    "    W: torch.Tensor,\n",
    "    norm_layer: nn.Module,\n",
    "    bias: Optional[torch.Tensor] = None,\n",
    "    max_neurons: Optional[int] = None,\n",
    "    exclude_neurons: Optional[List[int]] = None,\n",
    "    special_node_idx: Optional[int] = None,\n",
    "    epsilon_values: Optional[List[float]] = None\n",
    ") -> Dict[str, Any]:\n",
    "\n",
    "    # Find minimum neurons for swap with adaptive epsilon.\n",
    "    # Try increasing epsilon values until output changes are achieved.\n",
    "   \n",
    "    if epsilon_values is None:\n",
    "        epsilon_values = [0.1, 0.5, 1.0, 2.0, 5.0, 10.0,20.0,50.0,100.0]\n",
    "    \n",
    "    hidden_size = z.shape[-1]\n",
    "    if max_neurons is None:\n",
    "        max_neurons = hidden_size\n",
    "    \n",
    "    best_result = None\n",
    "    \n",
    "    for epsilon in epsilon_values:\n",
    "        result = find_min_neurons_for_swap(\n",
    "            z=z,\n",
    "            W=W,\n",
    "            epsilon=epsilon,\n",
    "            norm_layer=norm_layer,\n",
    "            bias=bias,\n",
    "            max_neurons=max_neurons,\n",
    "            exclude_neurons=exclude_neurons,\n",
    "            special_node_idx=special_node_idx\n",
    "        )\n",
    "        \n",
    "        result['epsilon_used'] = epsilon\n",
    "        \n",
    "        # Compute total perturbation magnitude\n",
    "        if result['perturbations']:\n",
    "            perturbation_values = list(result['perturbations'].values())\n",
    "            result['total_perturbation_magnitude'] = sum(abs(d) for d in perturbation_values)\n",
    "            result['max_single_perturbation'] = max(abs(d) for d in perturbation_values)\n",
    "        else:\n",
    "            result['total_perturbation_magnitude'] = 0.0\n",
    "            result['max_single_perturbation'] = 0.0\n",
    "        \n",
    "        if result['success']:\n",
    "            return result\n",
    "        \n",
    "        # Keep track of best attempt (most neurons perturbed)\n",
    "        if best_result is None or result['num_neurons'] > best_result['num_neurons']:\n",
    "            best_result = result\n",
    "    \n",
    "    # If no epsilon achieved swap, return the best attempt\n",
    "    return best_result if best_result is not None else result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7ca53d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Global variables for detailed activation capture\n",
    "captured_activations = {}\n",
    "current_hooks = []\n",
    "hook_errors = []\n",
    "\n",
    "def clear_activations():\n",
    "    global captured_activations\n",
    "    captured_activations.clear()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def remove_all_hooks():\n",
    "    global current_hooks\n",
    "    for hook in current_hooks:\n",
    "        try:\n",
    "            hook.remove()\n",
    "        except:\n",
    "            pass\n",
    "    current_hooks.clear()\n",
    "\n",
    "def get_activation_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        global hook_errors\n",
    "        try:\n",
    "            # Handle different output types\n",
    "            if output is None:\n",
    "                activation = None\n",
    "            elif isinstance(output, tuple):\n",
    "                activation = output[0]\n",
    "            elif hasattr(output, 'last_hidden_state'):\n",
    "                # Handle model output objects\n",
    "                activation = output.last_hidden_state\n",
    "            else:\n",
    "                activation = output\n",
    "            \n",
    "            # Handle input\n",
    "            input_tensor = input[0] if isinstance(input, tuple) and len(input) > 0 else None\n",
    "\n",
    "            # Safely detach and move to CPU\n",
    "            def safe_detach_cpu(tensor):\n",
    "                if tensor is None:\n",
    "                    return None\n",
    "                try:\n",
    "                    # Check if tensor is on meta device\n",
    "                    if hasattr(tensor, 'device') and str(tensor.device) == 'meta':\n",
    "                        return None\n",
    "                    return tensor.detach().cpu()\n",
    "                except Exception as e:\n",
    "                    hook_errors.append(f\"Detach error in {name}: {str(e)}\")\n",
    "                    return None\n",
    "\n",
    "            captured_activations[name] = {\n",
    "                'output': safe_detach_cpu(activation),\n",
    "                'input': safe_detach_cpu(input_tensor),\n",
    "                'weight': safe_detach_cpu(module.weight) if hasattr(module, 'weight') and module.weight is not None else None,\n",
    "                'bias': safe_detach_cpu(module.bias) if hasattr(module, 'bias') and module.bias is not None else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Hook error in {name}: {str(e)}\"\n",
    "            hook_errors.append(error_msg)\n",
    "            captured_activations[name] = {'output': None, 'input': None, 'weight': None, 'bias': None}\n",
    "    return hook\n",
    "\n",
    "def register_llama_hooks(model):\n",
    "    global current_hooks\n",
    "    remove_all_hooks() # clear any old hooks first\n",
    "    hook_errors.clear()\n",
    "\n",
    "    total_layers = len(model.model.layers)\n",
    "\n",
    "    for i in range(total_layers):\n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        components = [\n",
    "            (layer.self_attn.q_proj, f\"{layer_prefix}_attention_q\"), (layer.self_attn.k_proj, f\"{layer_prefix}_attention_k\"),\n",
    "            (layer.self_attn.v_proj, f\"{layer_prefix}_attention_v\"), (layer.self_attn.o_proj, f\"{layer_prefix}_attention_output\"),\n",
    "            (layer.mlp.gate_proj, f\"{layer_prefix}_mlp_gate\"), (layer.mlp.up_proj, f\"{layer_prefix}_mlp_up\"),\n",
    "            (layer.mlp.down_proj, f\"{layer_prefix}_mlp_down\"), (layer.input_layernorm, f\"{layer_prefix}_input_norm\"),\n",
    "            (layer.post_attention_layernorm, f\"{layer_prefix}_post_attn_norm\"),\n",
    "        ]\n",
    "        for module, name in components:\n",
    "            current_hooks.append(module.register_forward_hook(get_activation_hook(name)))\n",
    "    \n",
    "    current_hooks.append(model.model.norm.register_forward_hook(get_activation_hook(\"final_norm\")))\n",
    "    current_hooks.append(model.lm_head.register_forward_hook(get_activation_hook(\"lm_head\")))\n",
    "    # print(f\"Registered {len(current_hooks)} hooks.\")\n",
    "\n",
    "def run_model_and_capture_activations(model, inputs=None, inputs_embeds=None):\n",
    "    global hook_errors\n",
    "    clear_activations()\n",
    "    register_llama_hooks(model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if inputs is not None:\n",
    "            _ = model(**inputs)\n",
    "        elif inputs_embeds is not None:\n",
    "            _ = model(inputs_embeds=inputs_embeds)\n",
    "        else:\n",
    "            raise ValueError(\"Either inputs or inputs_embeds must be provided.\")\n",
    "            \n",
    "    remove_all_hooks()\n",
    "    \n",
    "    # Print any hook errors that occurred\n",
    "    if hook_errors:\n",
    "        print(f\"WARNING: {len(hook_errors)} hook errors occurred:\")\n",
    "        for err in hook_errors[:5]:\n",
    "            print(f\"  - {err}\")\n",
    "        if len(hook_errors) > 5:\n",
    "            print(f\"  ... and {len(hook_errors) - 5} more\")\n",
    "    \n",
    "    # return a copy of the captured activations\n",
    "    return captured_activations.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228fd910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Neuron Perturbation Sensitivity Analysis\n",
    "\n",
    "def get_top_k_predictions(logits: torch.Tensor, tokenizer, k: int = 3) -> Dict[str, Any]:\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    top_logits, top_indices = torch.topk(logits, k)\n",
    "    top_probs = probs[top_indices]\n",
    "    \n",
    "    result = {}\n",
    "    for i in range(k):\n",
    "        idx = top_indices[i].item()\n",
    "        word = tokenizer.decode([idx])\n",
    "        result[f'top{i+1}_word'] = word\n",
    "        result[f'top{i+1}_index'] = idx\n",
    "        result[f'top{i+1}_logit'] = top_logits[i].item()\n",
    "        result[f'top{i+1}_softmax'] = top_probs[i].item()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def run_gradient_swap_attack_with_special_node(\n",
    "    model: \"LlamaForCausalLM\",\n",
    "    tokenizer: \"LlamaTokenizer\",\n",
    "    pre_norm_activations: torch.Tensor,\n",
    "    input_id: int = 0,\n",
    "    filename: str = \"gradient_swap_attack_special_node_results.csv\",\n",
    "    use_adaptive_epsilon: bool = True,\n",
    "    max_neurons: Optional[int] = None,\n",
    "    epsilon_values: Optional[List[float]] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    # Run gradient swap attack with special node monitoring.\n",
    "    # Compares baseline (can use any neuron) vs constrained (avoiding special node).\n",
    "\n",
    "    # Get dimensions\n",
    "    seq_len = pre_norm_activations.shape[1]\n",
    "    hidden_size = pre_norm_activations.shape[2]\n",
    "    last_token_pos = seq_len - 1\n",
    "    \n",
    "    # Get the pre-norm activation for the last token\n",
    "    z = pre_norm_activations[0, last_token_pos, :].float()\n",
    "    \n",
    "    # Get models RMSNorm layer and lm_head weights\n",
    "    norm_layer = model.model.norm  # The final RMSNorm layer\n",
    "    W = model.lm_head.weight.detach().float()\n",
    "    bias = model.lm_head.bias.detach().float() if hasattr(model.lm_head, 'bias') and model.lm_head.bias is not None else None\n",
    "    \n",
    "    # Get original predictions using models actual RMSNorm\n",
    "    z_norm = norm_layer(z)\n",
    "    original_logits = F.linear(z_norm, W, bias)\n",
    "    original_probs = F.softmax(original_logits, dim=-1)\n",
    "    \n",
    "    top2_values, top2_indices = torch.topk(original_logits, 2)\n",
    "    top1_idx = top2_indices[0].item()\n",
    "    top2_idx = top2_indices[1].item()\n",
    "    p_top1 = original_probs[top1_idx].item()\n",
    "    p_top2 = original_probs[top2_idx].item() # INeeficient part suca removed by using topk\n",
    "    \n",
    "    # Get original top-3 predictions for logging\n",
    "    original_top3 = get_top_k_predictions(original_logits, tokenizer, k=3)\n",
    "    \n",
    "    # Compute analytical estimate\n",
    "    estimated_alpha = estimate_required_alpha(z, W, p_top1, p_top2)\n",
    "    \n",
    "    # Compute gradient for special node identification\n",
    "    gradient = compute_swap_gradient(z, W, top1_idx, top2_idx, norm_layer, bias)\n",
    "    \n",
    "    # Identify the special node\n",
    "    special_node_idx, special_node_score = identify_special_node(gradient, W)\n",
    "    \n",
    "    print(f\"  Original top-1: '{tokenizer.decode([top1_idx])}' (p={p_top1:.4f})\")\n",
    "    print(f\"  Original top-2: '{tokenizer.decode([top2_idx])}' (p={p_top2:.4f})\")\n",
    "    print(f\"  Special node: idx={special_node_idx}, score={special_node_score:.4f}\")\n",
    "    print(f\"  Estimated Alpha_total: {estimated_alpha:.2f}\")\n",
    "    \n",
    "    # Run BASELINE attack (can use any neuron, including special node)\n",
    "    print(f\"\\n  Running BASELINE attack (no constraints)...\")\n",
    "    if use_adaptive_epsilon:\n",
    "        baseline_result = find_min_neurons_with_adaptive_epsilon(\n",
    "            z=z, W=W, norm_layer=norm_layer, bias=bias,\n",
    "            max_neurons=max_neurons, exclude_neurons=None,\n",
    "            special_node_idx=special_node_idx, epsilon_values=epsilon_values\n",
    "        )\n",
    "    else:\n",
    "        baseline_result = find_min_neurons_for_swap(\n",
    "            z=z, W=W, epsilon=epsilon_values[0] if epsilon_values else 0.1,\n",
    "            norm_layer=norm_layer, bias=bias, max_neurons=max_neurons,\n",
    "            exclude_neurons=None, special_node_idx=special_node_idx\n",
    "        )\n",
    "        baseline_result['epsilon_used'] = epsilon_values[0] if epsilon_values else 0.1\n",
    "    \n",
    "    # Compute distances for baseline\n",
    "    baseline_distances = compute_all_distances(\n",
    "        baseline_result['original_logits'],\n",
    "        baseline_result['final_logits']\n",
    "    )\n",
    "    \n",
    "    # Get final top-3 for baseline\n",
    "    baseline_top3 = get_top_k_predictions(baseline_result['final_logits'], tokenizer, k=3)\n",
    "    \n",
    "    print(f\"  BASELINE: success={baseline_result['success']}, neurons={baseline_result['num_neurons']}, \"\n",
    "          f\"epsilon={baseline_result.get('epsilon_used', 'N/A')}, special_used={baseline_result.get('special_node_used', False)}\")\n",
    "    \n",
    "    # Run CONSTRAINED attack (must avoid special node)\n",
    "    print(f\"\\n  Running CONSTRAINED attack (avoiding special node {special_node_idx})...\")\n",
    "    if use_adaptive_epsilon:\n",
    "        constrained_result = find_min_neurons_with_adaptive_epsilon(\n",
    "            z=z, W=W, norm_layer=norm_layer, bias=bias,\n",
    "            max_neurons=max_neurons, exclude_neurons=[special_node_idx],\n",
    "            special_node_idx=special_node_idx, epsilon_values=epsilon_values\n",
    "        )\n",
    "    else:\n",
    "        constrained_result = find_min_neurons_for_swap(\n",
    "            z=z, W=W, epsilon=epsilon_values[0] if epsilon_values else 0.1,\n",
    "            norm_layer=norm_layer, bias=bias, max_neurons=max_neurons,\n",
    "            exclude_neurons=[special_node_idx], special_node_idx=special_node_idx\n",
    "        )\n",
    "        constrained_result['epsilon_used'] = epsilon_values[0] if epsilon_values else 0.1\n",
    "    \n",
    "    # Compute distances for constrained\n",
    "    constrained_distances = compute_all_distances(\n",
    "        constrained_result['original_logits'],\n",
    "        constrained_result['final_logits']\n",
    "    )\n",
    "    \n",
    "    # Get final top-3 for constrained\n",
    "    constrained_top3 = get_top_k_predictions(constrained_result['final_logits'], tokenizer, k=3)\n",
    "    \n",
    "    print(f\"  CONSTRAINED: success={constrained_result['success']}, neurons={constrained_result['num_neurons']}, \"\n",
    "          f\"epsilon={constrained_result.get('epsilon_used', 'N/A')}, special_avoided={not constrained_result.get('special_node_used', True)}\")\n",
    "    \n",
    "    # Build comparison record\n",
    "    record = {\n",
    "        'input_id': input_id,\n",
    "        'allowed_neurons': max_neurons,\n",
    "        #'total_neurons': hidden_size,\n",
    "        #'estimated_alpha': estimated_alpha,\n",
    "        \n",
    "        # Special node info\n",
    "        'special_node_idx': special_node_idx,\n",
    "        'special_node_score': special_node_score,\n",
    "        #'special_node_rank_baseline': baseline_result.get('special_node_rank', -1),\n",
    "        #'special_node_rank_constrained': constrained_result.get('special_node_rank', -1),\n",
    "        \n",
    "        # Baseline attack results\n",
    "        'baseline_success': baseline_result['success'],\n",
    "        'baseline_num_neurons': baseline_result['num_neurons'],\n",
    "        'baseline_epsilon': baseline_result.get('epsilon_used', 0.0),\n",
    "        'baseline_special_used': baseline_result.get('special_node_used', False),\n",
    "        'baseline_total_magnitude': baseline_result.get('total_perturbation_magnitude', 0.0),\n",
    "        'baseline_max_perturbation': baseline_result.get('max_single_perturbation', 0.0),\n",
    "        **{f'baseline_{k}': v for k, v in baseline_distances.items()},\n",
    "        **{f'baseline_final_{k}': v for k, v in baseline_top3.items()},\n",
    "        \n",
    "        # Constrained attack results\n",
    "        'constrained_success': constrained_result['success'],\n",
    "        'constrained_num_neurons': constrained_result['num_neurons'],\n",
    "        'constrained_epsilon': constrained_result.get('epsilon_used', 0.0),\n",
    "        'constrained_special_avoided': not constrained_result.get('special_node_used', True),\n",
    "        'constrained_total_magnitude': constrained_result.get('total_perturbation_magnitude', 0.0),\n",
    "        'constrained_max_perturbation': constrained_result.get('max_single_perturbation', 0.0),\n",
    "        **{f'constrained_{k}': v for k, v in constrained_distances.items()},\n",
    "        **{f'constrained_final_{k}': v for k, v in constrained_top3.items()},\n",
    "        \n",
    "        # Original predictions (same for both)\n",
    "        **{f'orig_{k}': v for k, v in original_top3.items()},\n",
    "        \n",
    "        # Comparison metrics\n",
    "        'neurons_diff': constrained_result['num_neurons'] - baseline_result['num_neurons'],\n",
    "        'epsilon_diff': constrained_result.get('epsilon_used', 0.0) - baseline_result.get('epsilon_used', 0.0),\n",
    "        'magnitude_diff': constrained_result.get('total_perturbation_magnitude', 0.0) - baseline_result.get('total_perturbation_magnitude', 0.0),\n",
    "    }\n",
    "    \n",
    "    # Save to CSV\n",
    "    df = pd.DataFrame([record])\n",
    "    file_exists = os.path.exists(filename)\n",
    "    df.to_csv(filename, mode='a', header=not file_exists, index=False)\n",
    "    \n",
    "    return {\n",
    "        'baseline': baseline_result,\n",
    "        'constrained': constrained_result,\n",
    "        'special_node_idx': special_node_idx,\n",
    "        'special_node_score': special_node_score,\n",
    "        'record': record,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f4f5086",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_swap_attack_workflow_with_special_node(\n",
    "    model: \"LlamaForCausalLM\",\n",
    "    tokenizer: \"LlamaTokenizer\",\n",
    "    string_input: List,  # [input_id, input_text]\n",
    "    filename: str = \"gradient_swap_attack_special_node_results.csv\",\n",
    "    use_adaptive_epsilon: bool = True,\n",
    "    epsilon_values: Optional[List[float]] = None,\n",
    "    max_neurons_list: Optional[int] = None,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Run gradient-based swap attack with special node monitoring.\n",
    "    Compares baseline vs constrained attacks.\n",
    "    \"\"\"\n",
    "    input_id, input_text = string_input\n",
    "    sample_input = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs_on_device = {k: v.to(model.device) for k, v in sample_input.items()}\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"Input ID: {input_id}\")\n",
    "    print(f\"Input: '{tokenizer.decode(inputs_on_device['input_ids'][0])}'\")\n",
    "    print(f\"Mode: {'Adaptive Epsilon' if use_adaptive_epsilon else 'Fixed Epsilon'}\")\n",
    "    if epsilon_values:\n",
    "        print(f\"Epsilon values: {epsilon_values}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Capture Pre-RMSNorm Activations\n",
    "    original_activations = run_model_and_capture_activations(model, inputs=inputs_on_device)\n",
    "    \n",
    "    # Get pre-norm activations (input to final RMSNorm)\n",
    "    try:\n",
    "        pre_norm_activations = original_activations['final_norm']['input']\n",
    "        if pre_norm_activations is None:\n",
    "            print(\"WARNING: Using final_norm output as approximation for pre-norm activations\")\n",
    "            pre_norm_activations = original_activations['final_norm']['output']\n",
    "        pre_norm_activations = pre_norm_activations.to(model.device).float()\n",
    "    except KeyError:\n",
    "        print(\"ERROR: Could not find 'final_norm' in activations.\")\n",
    "        return None\n",
    "    \n",
    "    hidden_size = pre_norm_activations.shape[2]\n",
    "    for max_neurons in max_neurons_list:\n",
    "        # Run the Special Node Attack\n",
    "        result = run_gradient_swap_attack_with_special_node(\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            pre_norm_activations=pre_norm_activations,\n",
    "            input_id=input_id,\n",
    "            filename=filename,\n",
    "            use_adaptive_epsilon=use_adaptive_epsilon,\n",
    "            epsilon_values=epsilon_values,\n",
    "            max_neurons=max_neurons,\n",
    "        )\n",
    "    \n",
    "    # Clean up\n",
    "    del original_activations, pre_norm_activations\n",
    "    clear_activations()\n",
    "    \n",
    "    # Print comparison summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"COMPARISON SUMMARY\")\n",
    "    print(f\"  Special Node: idx={result['special_node_idx']}, score={result['special_node_score']:.4f}\")\n",
    "    print(f\"\\n  BASELINE (unrestricted):\")\n",
    "    print(f\"    Success: {result['baseline']['success']}\")\n",
    "    print(f\"    Neurons: {result['baseline']['num_neurons']} / {hidden_size}\")\n",
    "    print(f\"    Epsilon: {result['baseline'].get('epsilon_used', 'N/A')}\")\n",
    "    print(f\"    Special node used: {result['baseline'].get('special_node_used', False)}\")\n",
    "    print(f\"\\n  CONSTRAINED (avoiding special node):\")\n",
    "    print(f\"    Success: {result['constrained']['success']}\")\n",
    "    print(f\"    Neurons: {result['constrained']['num_neurons']} / {hidden_size}\")\n",
    "    print(f\"    Epsilon: {result['constrained'].get('epsilon_used', 'N/A')}\")\n",
    "    print(f\"    Special node avoided: {not result['constrained'].get('special_node_used', True)}\")\n",
    "    print(f\"\\n  DIFFERENCE (constrained - baseline):\")\n",
    "    print(f\"    Neurons: {result['record']['neurons_diff']:+d}\")\n",
    "    print(f\"    Epsilon: {result['record']['epsilon_diff']:+.2f}\")\n",
    "    print(f\"    Total magnitude: {result['record']['magnitude_diff']:+.4f}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45979da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "sample_texts = [\n",
    "    [1,\"The capital of France is\"],\n",
    "    [2,\"The largest mammal on Earth is\"],\n",
    "    [3,\"The process of photosynthesis occurs in\"],\n",
    "    [4,\"The speed of light in a vacuum is\"],\n",
    "    [5,\"The chemical symbol for gold is\"],\n",
    "    [6,\"The human body has how many bones\"],\n",
    "    [7,\"The Great Wall of China was built to\"],\n",
    "    [8,\"Water boils at what temperature\"],\n",
    "    [9,\"The smallest unit of matter is\"],\n",
    "    [10,\"Shakespeare wrote the play\"],\n",
    "    [11,\"The currency of Japan is\"],\n",
    "    [12,\"Mount Everest is located in\"],\n",
    "    [13,\"The inventor of the telephone was\"],\n",
    "    [14,\"DNA stands for\"],\n",
    "    [15,\"The largest ocean on Earth is\"],\n",
    "    [16,\"The planet closest to the Sun is\"],\n",
    "    [17,\"Gravity was discovered by\"],\n",
    "    [18,\"The Amazon rainforest is primarily located in\"],\n",
    "    [19,\"The freezing point of water is\"],\n",
    "    [20,\"The most abundant gas in Earth's atmosphere is\"],\n",
    "    [21,\"The Mona Lisa was painted by\"],\n",
    "    [22,\"The longest river in the world is\"],\n",
    "    [23,\"Photosynthesis converts carbon dioxide and water into\"],\n",
    "    [24,\"The study of earthquakes is called\"],\n",
    "    [25,\"The first person to walk on the moon was\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e725dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SPECIAL NODE MONITORING EXPERIMENTS\n",
      "================================================================================\n",
      "Adaptive epsilon: True\n",
      "Epsilon progression: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "Output file: ./gradient_swap_attack_special_node_results.csv\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 1/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 1\n",
      "Input: '<s> The capital of France is'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=7, epsilon=10.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=10.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=14, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=14, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=14, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=14, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=37, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=37, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=37, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=37, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=37, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=37, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=37, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=37, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=79, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=80, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=79, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=80, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'Paris' (p=0.8931)\n",
      "  Original top-2: 'a' (p=0.0345)\n",
      "  Special node: idx=3556, score=0.0408\n",
      "  Estimated Alpha_total: 2.52\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=79, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=80, epsilon=1.0, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=3556, score=0.0408\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 79 / 4096\n",
      "    Epsilon: 1.0\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 80 / 4096\n",
      "    Epsilon: 1.0\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +1\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +1.0000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 2/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 2\n",
      "Input: '<s> The largest mammal on Earth is'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=8, epsilon=15.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=8, epsilon=15.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=12, epsilon=10.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=12, epsilon=10.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=23, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=23, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=23, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=23, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=23, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=23, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=55, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=55, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=55, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=55, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.9200)\n",
      "  Original top-2: 'not' (p=0.0289)\n",
      "  Special node: idx=2617, score=0.0132\n",
      "  Estimated Alpha_total: 2.42\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 2617)...\n",
      "  CONSTRAINED: success=True, neurons=55, epsilon=2.0, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=2617, score=0.0132\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 55 / 4096\n",
      "    Epsilon: 2.0\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 55 / 4096\n",
      "    Epsilon: 2.0\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +0\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +0.0000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 3/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 3\n",
      "Input: '<s> The process of photosynthesis occurs in'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=5, epsilon=10.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=10.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=12, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=11, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=22, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=22, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=22, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=22, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=41, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=41, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=41, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=41, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=41, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=41, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=41, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=41, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=83, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=83, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'the' (p=0.7385)\n",
      "  Original top-2: 'special' (p=0.0972)\n",
      "  Special node: idx=1573, score=0.1018\n",
      "  Estimated Alpha_total: 1.14\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=83, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1573)...\n",
      "  CONSTRAINED: success=True, neurons=83, epsilon=0.5, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=1573, score=0.1018\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 83 / 4096\n",
      "    Epsilon: 0.5\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 83 / 4096\n",
      "    Epsilon: 0.5\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +0\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +0.0000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 4/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 4\n",
      "Input: '<s> The speed of light in a vacuum is'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=6, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=6, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=6, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=6, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=6, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=59, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=6, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=59, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=62, epsilon=0.1, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=59, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=62, epsilon=0.1, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=59, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=62, epsilon=0.1, special_avoided=True\n",
      "  Original top-1: 'approximately' (p=0.4901)\n",
      "  Original top-2: '' (p=0.3251)\n",
      "  Special node: idx=1839, score=0.7574\n",
      "  Estimated Alpha_total: 0.33\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=59, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1839)...\n",
      "  CONSTRAINED: success=True, neurons=62, epsilon=0.1, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=1839, score=0.7574\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 59 / 4096\n",
      "    Epsilon: 0.1\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 62 / 4096\n",
      "    Epsilon: 0.1\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +3\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +0.3000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 5/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 5\n",
      "Input: '<s> The chemical symbol for gold is'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=10, epsilon=10.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=10, epsilon=10.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=20, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=20, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=20, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=20, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=20, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=20, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=20, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=20, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=56, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=56, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=56, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=56, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: 'Au' (p=0.9913)\n",
      "  Original top-2: 'A' (p=0.0016)\n",
      "  Special node: idx=3556, score=0.0039\n",
      "  Estimated Alpha_total: 4.20\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=55, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 3556)...\n",
      "  CONSTRAINED: success=True, neurons=56, epsilon=2.0, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=3556, score=0.0039\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 55 / 4096\n",
      "    Epsilon: 2.0\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 56 / 4096\n",
      "    Epsilon: 2.0\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +1\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +2.0000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 6/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 6\n",
      "Input: '<s> The human body has how many bones'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=7, epsilon=10.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=8, epsilon=10.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=14, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=14, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=38, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=38, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=38, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=38, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=38, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=38, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=38, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=38, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=38, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=38, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=84, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=85, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9063)\n",
      "  Original top-2: 'in' (p=0.0346)\n",
      "  Special node: idx=1360, score=0.0345\n",
      "  Estimated Alpha_total: 2.04\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=84, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=85, epsilon=1.0, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=1360, score=0.0345\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 84 / 4096\n",
      "    Epsilon: 1.0\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 85 / 4096\n",
      "    Epsilon: 1.0\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +1\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +1.0000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 7/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 7\n",
      "Input: '<s> The Great Wall of China was built to'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=8, epsilon=1.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=7, epsilon=1.0, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=15, epsilon=0.5, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=15, epsilon=0.5, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=87, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=87, epsilon=0.1, special_avoided=True\n",
      "  Original top-1: 'protect' (p=0.5323)\n",
      "  Original top-2: 'keep' (p=0.3652)\n",
      "  Special node: idx=1415, score=0.0904\n",
      "  Estimated Alpha_total: 0.31\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=87, epsilon=0.1, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1415)...\n",
      "  CONSTRAINED: success=True, neurons=87, epsilon=0.1, special_avoided=True\n",
      "\n",
      "================================================================================\n",
      "COMPARISON SUMMARY\n",
      "  Special Node: idx=1415, score=0.0904\n",
      "\n",
      "  BASELINE (unrestricted):\n",
      "    Success: True\n",
      "    Neurons: 87 / 4096\n",
      "    Epsilon: 0.1\n",
      "    Special node used: True\n",
      "\n",
      "  CONSTRAINED (avoiding special node):\n",
      "    Success: True\n",
      "    Neurons: 87 / 4096\n",
      "    Epsilon: 0.1\n",
      "    Special node avoided: True\n",
      "\n",
      "  DIFFERENCE (constrained - baseline):\n",
      "    Neurons: +0\n",
      "    Epsilon: +0.00\n",
      "    Total magnitude: +0.0000\n",
      "================================================================================\n",
      "\n",
      ">>>> Prompt 8/25 <<<<\n",
      "\n",
      "================================================================================\n",
      "Input ID: 8\n",
      "Input: '<s> Water boils at what temperature'\n",
      "Mode: Adaptive Epsilon\n",
      "Epsilon values: [0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 15.0, 20.0, 40.0, 50.0, 100.0]\n",
      "================================================================================\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=9, epsilon=10.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=9, epsilon=10.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=17, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=17, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=17, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=17, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=17, epsilon=5.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=17, epsilon=5.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=42, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=42, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=42, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=42, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n",
      "  BASELINE: success=True, neurons=42, epsilon=2.0, special_used=True\n",
      "\n",
      "  Running CONSTRAINED attack (avoiding special node 1360)...\n",
      "  CONSTRAINED: success=True, neurons=42, epsilon=2.0, special_avoided=True\n",
      "  Original top-1: '?' (p=0.9294)\n",
      "  Original top-2: 'and' (p=0.0234)\n",
      "  Special node: idx=1360, score=0.0168\n",
      "  Estimated Alpha_total: 2.17\n",
      "\n",
      "  Running BASELINE attack (no constraints)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, prompt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(sample_texts):\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m>>>> Prompt \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(sample_texts)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m <<<<\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_swap_attack_workflow_with_special_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstring_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOUTPUT_FILE_SPECIAL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_adaptive_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUSE_ADAPTIVE_EPSILON\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPSILON_VALUES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_neurons_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_neurons_list\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         all_special_results[prompt[\u001b[38;5;241m0\u001b[39m]] \u001b[38;5;241m=\u001b[39m result\n",
      "Cell \u001b[0;32mIn[19], line 43\u001b[0m, in \u001b[0;36mrun_swap_attack_workflow_with_special_node\u001b[0;34m(model, tokenizer, string_input, filename, use_adaptive_epsilon, epsilon_values, max_neurons_list)\u001b[0m\n\u001b[1;32m     40\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m pre_norm_activations\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m max_neurons \u001b[38;5;129;01min\u001b[39;00m max_neurons_list:\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Run the Special Node Attack\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mrun_gradient_swap_attack_with_special_node\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpre_norm_activations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_norm_activations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_adaptive_epsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_adaptive_epsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_neurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_neurons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Clean up\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m original_activations, pre_norm_activations\n",
      "Cell \u001b[0;32mIn[18], line 76\u001b[0m, in \u001b[0;36mrun_gradient_swap_attack_with_special_node\u001b[0;34m(model, tokenizer, pre_norm_activations, input_id, filename, use_adaptive_epsilon, max_neurons, epsilon_values)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m  Running BASELINE attack (no constraints)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_adaptive_epsilon:\n\u001b[0;32m---> 76\u001b[0m     baseline_result \u001b[38;5;241m=\u001b[39m \u001b[43mfind_min_neurons_with_adaptive_epsilon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_neurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_neurons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_neurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspecial_node_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecial_node_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon_values\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     82\u001b[0m     baseline_result \u001b[38;5;241m=\u001b[39m find_min_neurons_for_swap(\n\u001b[1;32m     83\u001b[0m         z\u001b[38;5;241m=\u001b[39mz, W\u001b[38;5;241m=\u001b[39mW, epsilon\u001b[38;5;241m=\u001b[39mepsilon_values[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m epsilon_values \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.1\u001b[39m,\n\u001b[1;32m     84\u001b[0m         norm_layer\u001b[38;5;241m=\u001b[39mnorm_layer, bias\u001b[38;5;241m=\u001b[39mbias, max_neurons\u001b[38;5;241m=\u001b[39mmax_neurons,\n\u001b[1;32m     85\u001b[0m         exclude_neurons\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, special_node_idx\u001b[38;5;241m=\u001b[39mspecial_node_idx\n\u001b[1;32m     86\u001b[0m     )\n",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m, in \u001b[0;36mfind_min_neurons_with_adaptive_epsilon\u001b[0;34m(z, W, norm_layer, bias, max_neurons, exclude_neurons, special_node_idx, epsilon_values)\u001b[0m\n\u001b[1;32m     22\u001b[0m best_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epsilon \u001b[38;5;129;01min\u001b[39;00m epsilon_values:\n\u001b[0;32m---> 25\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfind_min_neurons_for_swap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mW\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepsilon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepsilon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnorm_layer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm_layer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbias\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_neurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_neurons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_neurons\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_neurons\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspecial_node_idx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspecial_node_idx\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsilon_used\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m epsilon\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;66;03m# Compute total perturbation magnitude\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[13], line 19\u001b[0m, in \u001b[0;36mfind_min_neurons_for_swap\u001b[0;34m(z, W, epsilon, norm_layer, bias, max_neurons, exclude_neurons, special_node_idx)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Compute original probabilities and find top-1, top-2\u001b[39;00m\n\u001b[1;32m     18\u001b[0m z_norm \u001b[38;5;241m=\u001b[39m norm_layer(z)\n\u001b[0;32m---> 19\u001b[0m original_logits \u001b[38;5;241m=\u001b[39m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m original_probs \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(original_logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m top2_values, top2_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtopk(original_logits, \u001b[38;5;241m2\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# =============================================================================\n",
    "# Run Special Node Monitoring Experiments\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration for Special Node Experiments\n",
    "USE_ADAPTIVE_EPSILON = True  # Increase epsilon until output changes\n",
    "EPSILON_VALUES = [i*0.1 for i in range(1,1000,1)]  # Try these epsilon values\n",
    "OUTPUT_FILE_SPECIAL = \"./gradient_swap_attack_special_node_results.csv\"\n",
    "max_neurons_list = [ i for i in range(10,300,10)]\n",
    "# Store results\n",
    "all_special_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SPECIAL NODE MONITORING EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Adaptive epsilon: {USE_ADAPTIVE_EPSILON}\")\n",
    "print(f\"Epsilon progression: {EPSILON_VALUES}\")\n",
    "print(f\"Output file: {OUTPUT_FILE_SPECIAL}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Loop through each prompt\n",
    "for i, prompt in enumerate(sample_texts):\n",
    "    print(f\"\\n>>>> Prompt {i+1}/{len(sample_texts)} <<<<\")\n",
    "    \n",
    "    result = run_swap_attack_workflow_with_special_node(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        string_input=prompt,\n",
    "        filename=OUTPUT_FILE_SPECIAL,\n",
    "        use_adaptive_epsilon=USE_ADAPTIVE_EPSILON,\n",
    "        epsilon_values=EPSILON_VALUES,\n",
    "        max_neurons_list=max_neurons_list\n",
    "    )\n",
    "    \n",
    "    if result is not None:\n",
    "        all_special_results[prompt[0]] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e2b398",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\\n\" + \"=\"*80)\n",
    "print(\"<<<< ALL SPECIAL NODE EXPERIMENTS COMPLETE >>>>\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Results saved to '{OUTPUT_FILE_SPECIAL}'\")\n",
    "\n",
    "\n",
    "# Overall summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"OVERALL SUMMARY - SPECIAL NODE EXPERIMENTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if all_special_results:\n",
    "    # Baseline stats\n",
    "    baseline_successes = sum(1 for r in all_special_results.values() if r['baseline']['success'])\n",
    "    constrained_successes = sum(1 for r in all_special_results.values() if r['constrained']['success'])\n",
    "    total = len(all_special_results)\n",
    "    \n",
    "    print(f\"\\nSuccess Rates:\")\n",
    "    print(f\"  Baseline (unrestricted): {baseline_successes}/{total} ({baseline_successes/total*100:.1f}%)\")\n",
    "    print(f\"  Constrained (avoiding special node): {constrained_successes}/{total} ({constrained_successes/total*100:.1f}%)\")\n",
    "    \n",
    "    # Average neurons\n",
    "    avg_baseline_neurons = sum(r['baseline']['num_neurons'] for r in all_special_results.values()) / total\n",
    "    avg_constrained_neurons = sum(r['constrained']['num_neurons'] for r in all_special_results.values()) / total\n",
    "    avg_diff_neurons = avg_constrained_neurons - avg_baseline_neurons\n",
    "    \n",
    "    print(f\"\\nAverage Neurons Perturbed:\")\n",
    "    print(f\"  Baseline: {avg_baseline_neurons:.1f}\")\n",
    "    print(f\"  Constrained: {avg_constrained_neurons:.1f}\")\n",
    "    print(f\"  Difference: {avg_diff_neurons:+.1f} ({(avg_diff_neurons/avg_baseline_neurons)*100:+.1f}%)\")\n",
    "    \n",
    "    # Average epsilon\n",
    "    avg_baseline_epsilon = sum(r['baseline'].get('epsilon_used', 0) for r in all_special_results.values()) / total\n",
    "    avg_constrained_epsilon = sum(r['constrained'].get('epsilon_used', 0) for r in all_special_results.values()) / total\n",
    "    avg_diff_epsilon = avg_constrained_epsilon - avg_baseline_epsilon\n",
    "    \n",
    "    print(f\"\\nAverage Epsilon Used:\")\n",
    "    print(f\"  Baseline: {avg_baseline_epsilon:.2f}\")\n",
    "    print(f\"  Constrained: {avg_constrained_epsilon:.2f}\")\n",
    "    print(f\"  Difference: {avg_diff_epsilon:+.2f}\")\n",
    "    \n",
    "    # Average total magnitude\n",
    "    avg_baseline_mag = sum(r['baseline'].get('total_perturbation_magnitude', 0) for r in all_special_results.values()) / total\n",
    "    avg_constrained_mag = sum(r['constrained'].get('total_perturbation_magnitude', 0) for r in all_special_results.values()) / total\n",
    "    avg_diff_mag = avg_constrained_mag - avg_baseline_mag\n",
    "    \n",
    "    print(f\"\\nAverage Total Perturbation Magnitude:\")\n",
    "    print(f\"  Baseline: {avg_baseline_mag:.4f}\")\n",
    "    print(f\"  Constrained: {avg_constrained_mag:.4f}\")\n",
    "    print(f\"  Difference: {avg_diff_mag:+.4f} ({(avg_diff_mag/avg_baseline_mag)*100:+.1f}%)\")\n",
    "    \n",
    "    # Special node usage stats\n",
    "    special_used_count = sum(1 for r in all_special_results.values() if r['baseline'].get('special_node_used', False))\n",
    "    print(f\"\\nSpecial Node Usage in Baseline:\")\n",
    "    print(f\"  Used: {special_used_count}/{total} ({special_used_count/total*100:.1f}%)\")\n",
    "    print(f\"  Not used: {total - special_used_count}/{total} ({(total - special_used_count)/total*100:.1f}%)\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
