{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e10562b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import os\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8863042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_1_PATH = \"meta-llama/Llama-2-7b-chat-hf\" \n",
    "MODEL_2_PATH = \"meta-llama/Llama-2-7b-hf\"       \n",
    "\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3911279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.58s/it]\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:49<00:00, 24.82s/it]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_1_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model_1 = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_1_PATH,\n",
    "    torch_dtype=torch.float32, \n",
    "    device_map=DEVICE\n",
    ")\n",
    "\n",
    "model_2 = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_2_PATH,\n",
    "    torch_dtype=torch.float32, \n",
    "    device_map=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2ea8373",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model_1.to(DEVICE)\n",
    "model_2 = model_2.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbdd67eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_weights(model, move_to_cpu=False,layer_range=None):\n",
    "    weights = {}\n",
    "    \n",
    "    # Embedding weights\n",
    "    embed_weight = model.model.embed_tokens.weight\n",
    "    weights['embed_tokens'] = embed_weight.detach().cpu() if move_to_cpu else embed_weight.detach()\n",
    "    \n",
    "    # Layer-specific weights\n",
    "    if layer_range is None:\n",
    "        layer_range = range(len(model.model.layers))\n",
    "    \n",
    "    for i in layer_range:\n",
    "        if i >= len(model.model.layers):\n",
    "            continue\n",
    "            \n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        \n",
    "        # Self-attention weights\n",
    "        weights[f\"{layer_prefix}_q_proj\"] = layer.self_attn.q_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.q_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_k_proj\"] = layer.self_attn.k_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.k_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_v_proj\"] = layer.self_attn.v_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.v_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_o_proj\"] = layer.self_attn.o_proj.weight.detach().cpu() if move_to_cpu else layer.self_attn.o_proj.weight.detach()\n",
    "        \n",
    "        # MLP weights\n",
    "        weights[f\"{layer_prefix}_gate_proj\"] = layer.mlp.gate_proj.weight.detach().cpu() if move_to_cpu else layer.mlp.gate_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_up_proj\"] = layer.mlp.up_proj.weight.detach().cpu() if move_to_cpu else layer.mlp.up_proj.weight.detach()\n",
    "        weights[f\"{layer_prefix}_down_proj\"] = layer.mlp.down_proj.weight.detach().cpu() if move_to_cpu else layer.mlp.down_proj.weight.detach()\n",
    "        \n",
    "        # Layer norm weights\n",
    "        weights[f\"{layer_prefix}_input_layernorm\"] = layer.input_layernorm.weight.detach().cpu() if move_to_cpu else layer.input_layernorm.weight.detach()\n",
    "        weights[f\"{layer_prefix}_post_attention_layernorm\"] = layer.post_attention_layernorm.weight.detach().cpu() if move_to_cpu else layer.post_attention_layernorm.weight.detach()\n",
    "    \n",
    "    # Final layer norm and LM head\n",
    "    weights['final_norm'] = model.model.norm.weight.detach().cpu() if move_to_cpu else model.model.norm.weight.detach()\n",
    "    weights['lm_head'] = model.lm_head.weight.detach().cpu() if move_to_cpu else model.lm_head.weight.detach()\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def calculate_weight_differences(weights_1, weights_2):\n",
    "    differences = {}\n",
    "    \n",
    "    common_keys = set(weights_1.keys()) & set(weights_2.keys())\n",
    "    print(f\"Comparing {len(common_keys)} weight matrices...\")\n",
    "    \n",
    "    for i, key in enumerate(common_keys):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing {i+1}/{len(common_keys)}: {key}\")\n",
    "            \n",
    "        w1 = weights_1[key]\n",
    "        w2 = weights_2[key]\n",
    "        \n",
    "        if w1.shape != w2.shape:\n",
    "            print(f\"Warning: Shape mismatch for {key}: {w1.shape} vs {w2.shape}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate difference matrix\n",
    "        diff_matrix = w1 - w2\n",
    "        \n",
    "        # Calculate various norms and statistics\n",
    "        frobenius_norm = torch.norm(diff_matrix, p='fro').item()\n",
    "        frobenius_norm_relative = frobenius_norm / (torch.norm(w1, p='fro').item() + 1e-10)\n",
    "        \n",
    "        spectral_norm = torch.norm(diff_matrix, p=2).item()\n",
    "        spectral_norm_relative = spectral_norm / (torch.norm(w1, p=2).item() + 1e-10)\n",
    "        \n",
    "        # Element-wise statistics\n",
    "        abs_diff = torch.abs(diff_matrix)\n",
    "        mean_abs_diff = torch.mean(abs_diff).item()\n",
    "        max_abs_diff = torch.max(abs_diff).item()\n",
    "        std_diff = torch.std(diff_matrix).item()\n",
    "        \n",
    "        # Percentage of significantly different weights (threshold = 1e-6)\n",
    "        significant_diff_ratio = (abs_diff > 1e-6).float().mean().item()\n",
    "        \n",
    "        # Cosine similarity\n",
    "        w1_flat = w1.flatten()\n",
    "        w2_flat = w2.flatten()\n",
    "        cosine_sim = F.cosine_similarity(w1_flat.unsqueeze(0), w2_flat.unsqueeze(0)).item()\n",
    "        \n",
    "        differences[key] = {\n",
    "            'frobenius_norm': frobenius_norm,\n",
    "            'frobenius_norm_relative': frobenius_norm_relative,\n",
    "            'spectral_norm': spectral_norm,\n",
    "            'spectral_norm_relative': spectral_norm_relative,\n",
    "            'mean_abs_difference': mean_abs_diff,\n",
    "            'max_abs_difference': max_abs_diff,\n",
    "            'std_difference': std_diff,\n",
    "            'significant_diff_ratio': significant_diff_ratio,\n",
    "            'cosine_similarity': cosine_sim,\n",
    "            'weight_shape': w1.shape,\n",
    "            'total_parameters': w1.numel()\n",
    "        }\n",
    "    \n",
    "    return differences\n",
    "\n",
    "def analyze_weight_patterns(weight_differences):\n",
    "    analysis = {\n",
    "        'by_component_type': defaultdict(list),\n",
    "        'by_layer_depth': defaultdict(list),\n",
    "        'summary_stats': {}\n",
    "    }\n",
    "    \n",
    "    # Group by component type\n",
    "    for layer_name, diff_data in weight_differences.items():\n",
    "        if any(x in layer_name for x in ['q_proj', 'k_proj', 'v_proj', 'o_proj']):\n",
    "            component_type = 'attention'\n",
    "        elif any(x in layer_name for x in ['gate_proj', 'up_proj', 'down_proj']):\n",
    "            component_type = 'mlp'\n",
    "        elif 'layernorm' in layer_name or 'norm' in layer_name:\n",
    "            component_type = 'normalization'\n",
    "        elif 'embed' in layer_name:\n",
    "            component_type = 'embedding'\n",
    "        elif 'lm_head' in layer_name:\n",
    "            component_type = 'output'\n",
    "        else:\n",
    "            component_type = 'other'\n",
    "        \n",
    "        analysis['by_component_type'][component_type].append({\n",
    "            'layer_name': layer_name,\n",
    "            'frobenius_norm': diff_data['frobenius_norm'],\n",
    "            'frobenius_norm_relative': diff_data['frobenius_norm_relative'],\n",
    "            'significant_diff_ratio': diff_data['significant_diff_ratio'],\n",
    "            'cosine_similarity': diff_data['cosine_similarity']\n",
    "        })\n",
    "    \n",
    "    # Group by layer depth\n",
    "    for layer_name, diff_data in weight_differences.items():\n",
    "        if 'layer_' in layer_name:\n",
    "            try:\n",
    "                layer_num = int(layer_name.split('_')[1])\n",
    "                analysis['by_layer_depth'][layer_num].append({\n",
    "                    'layer_name': layer_name,\n",
    "                    'frobenius_norm': diff_data['frobenius_norm'],\n",
    "                    'frobenius_norm_relative': diff_data['frobenius_norm_relative'],\n",
    "                    'cosine_similarity': diff_data['cosine_similarity']\n",
    "                })\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    all_frobenius = [data['frobenius_norm'] for data in weight_differences.values()]\n",
    "    all_frobenius_rel = [data['frobenius_norm_relative'] for data in weight_differences.values()]\n",
    "    all_significant_ratios = [data['significant_diff_ratio'] for data in weight_differences.values()]\n",
    "    all_cosine_sims = [data['cosine_similarity'] for data in weight_differences.values()]\n",
    "    \n",
    "    analysis['summary_stats'] = {\n",
    "        'total_layers_compared': len(weight_differences),\n",
    "        'mean_frobenius_norm': np.mean(all_frobenius),\n",
    "        'std_frobenius_norm': np.std(all_frobenius),\n",
    "        'max_frobenius_norm': np.max(all_frobenius),\n",
    "        'min_frobenius_norm': np.min(all_frobenius),\n",
    "        'mean_frobenius_norm_relative': np.mean(all_frobenius_rel),\n",
    "        'mean_significant_diff_ratio': np.mean(all_significant_ratios),\n",
    "        'mean_cosine_similarity': np.mean(all_cosine_sims),\n",
    "        'min_cosine_similarity': np.min(all_cosine_sims),\n",
    "        'total_parameters_compared': sum(data['total_parameters'] for data in weight_differences.values())\n",
    "    }\n",
    "    \n",
    "    return analysis\n",
    "\n",
    "def print_weight_analysis_summary(analysis):\n",
    "    print(\"=\"*70)\n",
    "    print(\"LLAMA MODEL WEIGHT DIFFERENCE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Overall statistics\n",
    "    stats = analysis['summary_stats']\n",
    "    print(f\"\\n📊 OVERALL STATISTICS:\")\n",
    "    print(f\"  • Total layers compared: {stats['total_layers_compared']}\")\n",
    "    print(f\"  • Total parameters compared: {stats['total_parameters_compared']:,}\")\n",
    "    print(f\"  • Mean Frobenius norm: {stats['mean_frobenius_norm']:.2e}\")\n",
    "    print(f\"  • Mean relative Frobenius norm: {stats['mean_frobenius_norm_relative']:.8f}\")\n",
    "    print(f\"  • Max Frobenius norm: {stats['max_frobenius_norm']:.2e}\")\n",
    "    print(f\"  • Min Frobenius norm: {stats['min_frobenius_norm']:.2e}\")\n",
    "    print(f\"  • Mean cosine similarity: {stats['mean_cosine_similarity']:.8f}\")\n",
    "    print(f\"  • Min cosine similarity: {stats['min_cosine_similarity']:.8f}\")\n",
    "    print(f\"  • Mean significant difference ratio: {stats['mean_significant_diff_ratio']:.4f}\")\n",
    "    \n",
    "    # Component type analysis\n",
    "    print(f\"\\n🔧 BY COMPONENT TYPE:\")\n",
    "    for comp_type, comp_data in analysis['by_component_type'].items():\n",
    "        frob_norms = [item['frobenius_norm_relative'] for item in comp_data]\n",
    "        cosine_sims = [item['cosine_similarity'] for item in comp_data]\n",
    "        sig_ratios = [item['significant_diff_ratio'] for item in comp_data]\n",
    "        \n",
    "        print(f\"  {comp_type.upper()}:\")\n",
    "        print(f\"    - Count: {len(comp_data)} layers\")\n",
    "        print(f\"    - Mean relative Frobenius: {np.mean(frob_norms):.8f} ± {np.std(frob_norms):.8f}\")\n",
    "        print(f\"    - Mean cosine similarity: {np.mean(cosine_sims):.8f} ± {np.std(cosine_sims):.8f}\")\n",
    "        print(f\"    - Mean sig. diff ratio: {np.mean(sig_ratios):.4f}\")\n",
    "    \n",
    "    # Layer depth analysis (if available)\n",
    "    if analysis['by_layer_depth']:\n",
    "        print(f\"\\n📈 BY LAYER DEPTH:\")\n",
    "        for depth in sorted(analysis['by_layer_depth'].keys())[:10]:  # Show first 10 layers\n",
    "            depth_data = analysis['by_layer_depth'][depth]\n",
    "            frob_norms = [item['frobenius_norm_relative'] for item in depth_data]\n",
    "            cosine_sims = [item['cosine_similarity'] for item in depth_data]\n",
    "            \n",
    "            print(f\"  Layer {depth}: Frob={np.mean(frob_norms):.6f}, Cosine={np.mean(cosine_sims):.6f}\")\n",
    "    \n",
    "    print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec280794",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_1 = get_model_weights(model_1)\n",
    "weights_2 = get_model_weights(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "566bf7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing 291 weight matrices...\n",
      "Processing 1/291: layer_22_down_proj\n",
      "Processing 11/291: layer_15_post_attention_layernorm\n",
      "Processing 21/291: layer_27_gate_proj\n",
      "Processing 31/291: layer_31_post_attention_layernorm\n",
      "Processing 41/291: layer_3_q_proj\n",
      "Processing 51/291: layer_17_up_proj\n",
      "Processing 61/291: layer_14_up_proj\n",
      "Processing 71/291: layer_15_gate_proj\n",
      "Processing 81/291: layer_17_post_attention_layernorm\n",
      "Processing 91/291: layer_8_down_proj\n",
      "Processing 101/291: layer_24_input_layernorm\n",
      "Processing 111/291: layer_21_input_layernorm\n",
      "Processing 121/291: layer_28_v_proj\n",
      "Processing 131/291: layer_6_v_proj\n",
      "Processing 141/291: layer_29_v_proj\n",
      "Processing 151/291: layer_20_q_proj\n",
      "Processing 161/291: layer_12_o_proj\n",
      "Processing 171/291: layer_12_gate_proj\n",
      "Processing 181/291: layer_20_up_proj\n",
      "Processing 191/291: layer_19_q_proj\n",
      "Processing 201/291: layer_22_post_attention_layernorm\n",
      "Processing 211/291: final_norm\n",
      "Processing 221/291: layer_14_input_layernorm\n",
      "Processing 231/291: layer_26_k_proj\n",
      "Processing 241/291: layer_8_o_proj\n",
      "Processing 251/291: layer_11_gate_proj\n",
      "Processing 261/291: layer_18_up_proj\n",
      "Processing 271/291: layer_31_input_layernorm\n",
      "Processing 281/291: layer_30_input_layernorm\n",
      "Processing 291/291: layer_25_gate_proj\n"
     ]
    }
   ],
   "source": [
    "weight_differences = calculate_weight_differences(weights_1, weights_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff68a2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = analyze_weight_patterns(weight_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06f8f2a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LLAMA MODEL WEIGHT DIFFERENCE ANALYSIS SUMMARY\n",
      "======================================================================\n",
      "\n",
      "📊 OVERALL STATISTICS:\n",
      "  • Total layers compared: 291\n",
      "  • Total parameters compared: 6,738,415,616\n",
      "  • Mean Frobenius norm: 5.00e+00\n",
      "  • Mean relative Frobenius norm: 0.05240598\n",
      "  • Max Frobenius norm: 2.33e+01\n",
      "  • Min Frobenius norm: 6.37e-02\n",
      "  • Mean cosine similarity: 1.00115807\n",
      "  • Min cosine similarity: 0.99230218\n",
      "  • Mean significant difference ratio: 0.9642\n",
      "\n",
      "🔧 BY COMPONENT TYPE:\n",
      "  MLP:\n",
      "    - Count: 96 layers\n",
      "    - Mean relative Frobenius: 0.06610288 ± 0.00257659\n",
      "    - Mean cosine similarity: 1.00398319 ± 0.00041742\n",
      "    - Mean sig. diff ratio: 0.9729\n",
      "  ATTENTION:\n",
      "    - Count: 128 layers\n",
      "    - Mean relative Frobenius: 0.06287519 ± 0.01413015\n",
      "    - Mean cosine similarity: 0.99922307 ± 0.00117901\n",
      "    - Mean sig. diff ratio: 0.9713\n",
      "  NORMALIZATION:\n",
      "    - Count: 65 layers\n",
      "    - Mean relative Frobenius: 0.01038052 ± 0.00265356\n",
      "    - Mean cosine similarity: 0.99998514 ± 0.00004352\n",
      "    - Mean sig. diff ratio: 0.9371\n",
      "  EMBEDDING:\n",
      "    - Count: 1 layers\n",
      "    - Mean relative Frobenius: 0.05791559 ± 0.00000000\n",
      "    - Mean cosine similarity: 1.02927232 ± 0.00000000\n",
      "    - Mean sig. diff ratio: 0.9617\n",
      "  OUTPUT:\n",
      "    - Count: 1 layers\n",
      "    - Mean relative Frobenius: 0.12358926 ± 0.00000000\n",
      "    - Mean cosine similarity: 1.02575266 ± 0.00000000\n",
      "    - Mean sig. diff ratio: 0.9832\n",
      "\n",
      "📈 BY LAYER DEPTH:\n",
      "  Layer 0: Frob=0.061750, Cosine=1.000780\n",
      "  Layer 1: Frob=0.057145, Cosine=1.000603\n",
      "  Layer 2: Frob=0.048795, Cosine=1.001271\n",
      "  Layer 3: Frob=0.051349, Cosine=1.001073\n",
      "  Layer 4: Frob=0.050610, Cosine=1.001082\n",
      "  Layer 5: Frob=0.049889, Cosine=1.001132\n",
      "  Layer 6: Frob=0.052620, Cosine=1.001073\n",
      "  Layer 7: Frob=0.052589, Cosine=1.001031\n",
      "  Layer 8: Frob=0.052245, Cosine=1.001056\n",
      "  Layer 9: Frob=0.051850, Cosine=1.001013\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print_weight_analysis_summary(analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a3bf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations_model_1 = {}\n",
    "activations_model_2 = {}\n",
    "current_hooks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "854f9fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_activations():\n",
    "    global activations_model_1, activations_model_2\n",
    "    activations_model_1.clear()\n",
    "    activations_model_2.clear()\n",
    "\n",
    "def remove_all_hooks():\n",
    "    global current_hooks\n",
    "    for hook in current_hooks:\n",
    "        hook.remove()\n",
    "    current_hooks.clear()\n",
    "\n",
    "def get_activation_hook(name, model_name):\n",
    "    def hook(module, input, output):\n",
    "        try:\n",
    "            # Handle output\n",
    "            if isinstance(output, tuple):\n",
    "                activation = output[0] if output[0] is not None else None\n",
    "            else:\n",
    "                activation = output\n",
    "            \n",
    "            # Handle input - check for None values\n",
    "            input_tensor = None\n",
    "            if input is not None:\n",
    "                if isinstance(input, tuple) and len(input) > 0:\n",
    "                    input_tensor = input[0] if input[0] is not None else None\n",
    "                else:\n",
    "                    input_tensor = input if input is not None else None\n",
    "            \n",
    "            # Create activation data with None checks\n",
    "            activation_data = {\n",
    "                'output': activation.detach().cpu() if activation is not None else None,\n",
    "                'input': input_tensor.detach().cpu() if input_tensor is not None else None,\n",
    "                'weight': module.weight.detach().cpu() if hasattr(module, 'weight') and module.weight is not None else None,\n",
    "                'bias': module.bias.detach().cpu() if hasattr(module, 'bias') and module.bias is not None else None\n",
    "            }\n",
    "            \n",
    "            if model_name == \"Model_1\":\n",
    "                activations_model_1[name] = activation_data\n",
    "            else:\n",
    "                activations_model_2[name] = activation_data\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error in hook {name}: {e}\")\n",
    "            # Store None data to prevent missing keys\n",
    "            activation_data = {\n",
    "                'output': None,\n",
    "                'input': None, \n",
    "                'weight': None,\n",
    "                'bias': None\n",
    "            }\n",
    "            \n",
    "            if model_name == \"Model_1\":\n",
    "                activations_model_1[name] = activation_data\n",
    "            else:\n",
    "                activations_model_2[name] = activation_data\n",
    "            \n",
    "    return hook\n",
    "\n",
    "def register_llama_hooks(model, model_name, layer_range=None):\n",
    "    global current_hooks\n",
    "    hooks = []\n",
    "    layer_info = {}\n",
    "    \n",
    "    # Determine layer range\n",
    "    if layer_range is None:\n",
    "        layer_range = range(len(model.model.layers))\n",
    "    \n",
    "    for i in layer_range:\n",
    "        if i >= len(model.model.layers):\n",
    "            continue\n",
    "            \n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        \n",
    "        # 1. Self-Attention Components\n",
    "        # Query, Key, Value projections\n",
    "        hooks.append(layer.self_attn.q_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_attention_q\", model_name)\n",
    "        ))\n",
    "        hooks.append(layer.self_attn.k_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_attention_k\", model_name)\n",
    "        ))\n",
    "        hooks.append(layer.self_attn.v_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_attention_v\", model_name)\n",
    "        ))\n",
    "        \n",
    "        # Output projection\n",
    "        hooks.append(layer.self_attn.o_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_attention_output\", model_name)\n",
    "        ))\n",
    "        \n",
    "        # 2. MLP Components  \n",
    "        hooks.append(layer.mlp.gate_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_mlp_gate\", model_name)\n",
    "        ))\n",
    "        hooks.append(layer.mlp.up_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_mlp_up\", model_name)\n",
    "        ))\n",
    "        hooks.append(layer.mlp.down_proj.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_mlp_down\", model_name)\n",
    "        ))\n",
    "        \n",
    "        # 3. Layer Norms\n",
    "        hooks.append(layer.input_layernorm.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_input_norm\", model_name)\n",
    "        ))\n",
    "        hooks.append(layer.post_attention_layernorm.register_forward_hook(\n",
    "            get_activation_hook(f\"{layer_prefix}_post_attn_norm\", model_name)\n",
    "        ))\n",
    "        \n",
    "        # Store layer info\n",
    "        layer_info[layer_prefix] = {\n",
    "            'layer_idx': i,\n",
    "            'components': ['attention_q', 'attention_k', 'attention_v', \n",
    "                         'attention_output', 'mlp_gate', 'mlp_up', 'mlp_down',\n",
    "                         'input_norm', 'post_attn_norm']\n",
    "        }\n",
    "    \n",
    "    # Final layer norm and LM head (optional)\n",
    "    hooks.append(model.model.norm.register_forward_hook(\n",
    "        get_activation_hook(\"final_norm\", model_name)\n",
    "    ))\n",
    "    hooks.append(model.lm_head.register_forward_hook(\n",
    "        get_activation_hook(\"lm_head\", model_name)\n",
    "    ))\n",
    "    \n",
    "    current_hooks.extend(hooks)\n",
    "    return hooks, layer_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf4d8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_neurons_per_layer(activations, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    selected_neurons = {}\n",
    "    \n",
    "    for layer_name, layer_data in activations.items():\n",
    "        if not isinstance(layer_data, dict):\n",
    "            continue\n",
    "            \n",
    "        activation = layer_data.get('output')\n",
    "        \n",
    "        if activation is None:\n",
    "            print(f\"Skipping {layer_name}: No activation data\")\n",
    "            continue\n",
    "        \n",
    "        # Handle different activation shapes\n",
    "        if len(activation.shape) == 3:  # [batch, seq_len, hidden_size]\n",
    "            batch_size, seq_len, hidden_size = activation.shape\n",
    "            \n",
    "            if hidden_size == 0:\n",
    "                continue\n",
    "            \n",
    "            neuron_idx = np.random.randint(0, hidden_size)\n",
    "            \n",
    "            selected_neurons[layer_name] = {\n",
    "                'neuron_index': neuron_idx,\n",
    "                'sequence_length': seq_len,\n",
    "                'hidden_size': hidden_size,\n",
    "                'activation_shape': activation.shape\n",
    "            }\n",
    "            \n",
    "    return selected_neurons\n",
    "    \n",
    "def get_component_type(layer_name):\n",
    "    if 'attention' in layer_name:\n",
    "        return 'attention'\n",
    "    elif 'mlp' in layer_name:\n",
    "        return 'mlp'\n",
    "    elif 'norm' in layer_name:\n",
    "        return 'normalization'\n",
    "    elif 'lm_head' in layer_name:\n",
    "        return 'output'\n",
    "    else:\n",
    "        return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_neuron_outputs(layer_name, neuron_idx, input_tensor,\n",
    "                            weights_1, weights_2, \n",
    "                            actual_output_1, actual_output_2):\n",
    "    results = {\n",
    "        'neuron_index': neuron_idx,\n",
    "        'calculations': [],\n",
    "        'layer_type': get_component_type(layer_name)\n",
    "    }\n",
    "    \n",
    "    # Skip if essential data is missing\n",
    "    if input_tensor is None or weights_1 is None or weights_2 is None:\n",
    "        return results\n",
    "    \n",
    "    # Get weights and biases\n",
    "    w1 = weights_1.get('weight')\n",
    "    w2 = weights_2.get('weight')\n",
    "    b1 = weights_1.get('bias')\n",
    "    b2 = weights_2.get('bias')\n",
    "    \n",
    "    if w1 is None or w2 is None:\n",
    "        return results\n",
    "    \n",
    "    # Handle layer normalization differently (1D weights)\n",
    "    if 'norm' in layer_name:\n",
    "        # Layer norm: output = weight * normalized_input + bias\n",
    "        # For layer norm, we can't select individual neurons the same way\n",
    "        # Instead, we'll look at the scaling factor for the selected dimension\n",
    "        for token_idx in range(input_tensor.shape[1]):\n",
    "            try:\n",
    "                token_input = input_tensor[0, token_idx, :]  # [hidden_size]\n",
    "                \n",
    "                # For layer norm, weight is 1D, so we use it as element-wise multiplication\n",
    "                if neuron_idx < w1.shape[0] and neuron_idx < w2.shape[0]:\n",
    "                    # Get the scaling factor for this dimension\n",
    "                    scale_1 = w1[neuron_idx].item()\n",
    "                    scale_2 = w2[neuron_idx].item()\n",
    "                    \n",
    "                    # Get the normalized input value for this dimension\n",
    "                    input_val = token_input[neuron_idx].item()\n",
    "                    \n",
    "                    # Calculate scaled outputs\n",
    "                    calc_1 = scale_1 * input_val\n",
    "                    calc_2 = scale_2 * input_val\n",
    "                    \n",
    "                    if b1 is not None and neuron_idx < b1.shape[0]:\n",
    "                        calc_1 += b1[neuron_idx].item()\n",
    "                    if b2 is not None and neuron_idx < b2.shape[0]:\n",
    "                        calc_2 += b2[neuron_idx].item()\n",
    "                    \n",
    "                    # Get actual outputs\n",
    "                    actual_1 = actual_output_1[0, token_idx, neuron_idx] if actual_output_1 is not None else None\n",
    "                    actual_2 = actual_output_2[0, token_idx, neuron_idx] if actual_output_2 is not None else None\n",
    "                    \n",
    "                    results['calculations'].append({\n",
    "                        'token_position': token_idx,\n",
    "                        'model_1_calculated': calc_1,\n",
    "                        'model_2_calculated': calc_2,\n",
    "                        'difference': calc_1 - calc_2,\n",
    "                        'model_1_actual': actual_1.item() if actual_1 is not None else None,\n",
    "                        'model_2_actual': actual_2.item() if actual_2 is not None else None,\n",
    "                        'weight_diff': scale_1 - scale_2\n",
    "                    })\n",
    "                    \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    else:\n",
    "        # Handle regular linear layers (2D weights)\n",
    "        for token_idx in range(input_tensor.shape[1]):\n",
    "            try:\n",
    "                token_input = input_tensor[0, token_idx, :]  # [hidden_size]\n",
    "                \n",
    "                # Check bounds\n",
    "                if neuron_idx >= w1.shape[0] or neuron_idx >= w2.shape[0]:\n",
    "                    continue\n",
    "                \n",
    "                # Model 1 calculation: input @ w1.T + b1\n",
    "                calc_1 = torch.matmul(token_input, w1[neuron_idx, :])\n",
    "                if b1 is not None and neuron_idx < b1.shape[0]:\n",
    "                    calc_1 += b1[neuron_idx]\n",
    "                \n",
    "                # Model 2 calculation: input @ w2.T + b2  \n",
    "                calc_2 = torch.matmul(token_input, w2[neuron_idx, :])\n",
    "                if b2 is not None and neuron_idx < b2.shape[0]:\n",
    "                    calc_2 += b2[neuron_idx]\n",
    "                \n",
    "                # Apply activation function for MLP gate/up projections\n",
    "                if 'mlp_gate' in layer_name or 'mlp_up' in layer_name:\n",
    "                    calc_1 = F.silu(calc_1)\n",
    "                    calc_2 = F.silu(calc_2)\n",
    "                \n",
    "                # Get actual outputs\n",
    "                actual_1 = actual_output_1[0, token_idx, neuron_idx] if actual_output_1 is not None else None\n",
    "                actual_2 = actual_output_2[0, token_idx, neuron_idx] if actual_output_2 is not None else None\n",
    "                \n",
    "                results['calculations'].append({\n",
    "                    'token_position': token_idx,\n",
    "                    'model_1_calculated': calc_1.item(),\n",
    "                    'model_2_calculated': calc_2.item(),\n",
    "                    'difference': (calc_1 - calc_2).item(),\n",
    "                    'model_1_actual': actual_1.item() if actual_1 is not None else None,\n",
    "                    'model_2_actual': actual_2.item() if actual_2 is not None else None\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                continue\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e23253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_neuron_calculations(model_1_activations, model_2_activations, \n",
    "                                selected_neurons):\n",
    "    comparison_results = {}\n",
    "    \n",
    "    for layer_name, neuron_info in selected_neurons.items():\n",
    "        neuron_idx = neuron_info['neuron_index']\n",
    "        \n",
    "        # Get current layer data\n",
    "        layer_1_data = model_1_activations.get(layer_name, {})\n",
    "        layer_2_data = model_2_activations.get(layer_name, {})\n",
    "        \n",
    "        # Skip if missing data\n",
    "        if not isinstance(layer_1_data, dict) or not isinstance(layer_2_data, dict):\n",
    "            continue\n",
    "            \n",
    "        # Get the input to this layer (from Model 1)\n",
    "        model_1_input = layer_1_data.get('input')\n",
    "        \n",
    "        if model_1_input is None:\n",
    "            continue\n",
    "        \n",
    "        # Get weights from both models\n",
    "        weights_1 = layer_1_data  # Contains weight and bias\n",
    "        weights_2 = layer_2_data  # Contains weight and bias\n",
    "        \n",
    "        # Calculate outputs for the selected neuron\n",
    "        results = calculate_neuron_outputs(\n",
    "            layer_name, neuron_idx, model_1_input,\n",
    "            weights_1, weights_2,\n",
    "            layer_1_data.get('output'), layer_2_data.get('output')\n",
    "        )\n",
    "        \n",
    "        if results and results['calculations']:\n",
    "            comparison_results[layer_name] = results\n",
    "            \n",
    "    return comparison_results\n",
    "\n",
    "def run_comparison(text_input, seed=42):\n",
    "    print(f\"Processing: {text_input[:50]}...\")\n",
    "    \n",
    "    # Clear previous data\n",
    "    clear_activations()\n",
    "    remove_all_hooks()\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text_input, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "    \n",
    "    print(f\"Input tokens: {inputs['input_ids'].shape[1]}\")\n",
    "    \n",
    "    try:\n",
    "        # Register hooks for all layers\n",
    "        print(\"Registering hooks...\")\n",
    "        hooks_1, layers_1 = register_llama_hooks(model_1, \"Model_1\")\n",
    "        hooks_2, layers_2 = register_llama_hooks(model_2, \"Model_2\")\n",
    "        \n",
    "        # Run both models\n",
    "        print(\"Running models...\")\n",
    "        with torch.no_grad():\n",
    "            outputs_1 = model_1(**inputs)\n",
    "            outputs_2 = model_2(**inputs)\n",
    "        \n",
    "        print(f\"Captured {len(activations_model_1)} activations from Model 1\")\n",
    "        print(f\"Captured {len(activations_model_2)} activations from Model 2\")\n",
    "        \n",
    "        # Select random neurons (one per layer)\n",
    "        print(\"Selecting random neurons...\")\n",
    "        selected_neurons = select_random_neurons_per_layer(activations_model_1, seed=seed)\n",
    "        \n",
    "        print(f\"Selected neurons from {len(selected_neurons)} layers\")\n",
    "        \n",
    "        # Compare activations\n",
    "        print(\"Comparing activations...\")\n",
    "        comparison_results = compare_neuron_calculations(\n",
    "            activations_model_1,\n",
    "            activations_model_2,\n",
    "            selected_neurons\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_text': text_input,\n",
    "            'tokenized_input': inputs,\n",
    "            'model_1_output': outputs_1.logits,\n",
    "            'model_2_output': outputs_2.logits,\n",
    "            'layer_comparisons': comparison_results,\n",
    "            'selected_neurons': selected_neurons\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error in run_comparison: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return {\n",
    "            'input_text': text_input,\n",
    "            'error': str(e),\n",
    "            'layer_comparisons': {},\n",
    "            'selected_neurons': {}\n",
    "        }\n",
    "    \n",
    "    finally:\n",
    "        # Always cleanup hooks\n",
    "        remove_all_hooks()\n",
    "\n",
    "def save_detailed_results(comparison_results, filename=\"detailed_activation_comparison.csv\"):\n",
    "    rows = []\n",
    "    \n",
    "    for layer_name, layer_data in comparison_results['layer_comparisons'].items():\n",
    "        if 'calculations' in layer_data:\n",
    "            for calc in layer_data['calculations']:\n",
    "                row = {\n",
    "                    'input_text': comparison_results['input_text'][:100],\n",
    "                    'layer_name': layer_name,\n",
    "                    'layer_type': layer_data['layer_type'],\n",
    "                    'neuron_index': layer_data['neuron_index'],\n",
    "                    'token_position': calc['token_position'],\n",
    "                    'model_1_calculated': calc['model_1_calculated'],\n",
    "                    'model_2_calculated': calc['model_2_calculated'],\n",
    "                    'difference': calc['difference'],\n",
    "                    'abs_difference': abs(calc['difference']),\n",
    "                    'model_1_actual': calc.get('model_1_actual'),\n",
    "                    'model_2_actual': calc.get('model_2_actual')\n",
    "                }\n",
    "                rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # Save to CSV\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, index=False)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbfda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TEXTS = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"Artificial intelligence is transforming the world of technology.\",\n",
    "    \"In a hole in the ground there lived a hobbit.\",\n",
    "    \"To be or not to be, that is the question Shakespeare posed.\",\n",
    "    \"Machine learning models require large datasets for training.\",\n",
    "    \"The mitochondria is the powerhouse of the cell in biology.\",\n",
    "    \"Climate change is causing unprecedented shifts in global weather patterns.\",\n",
    "    \"Mozart composed his first symphony at the age of eight years old.\",\n",
    "    \"The stock market experienced significant volatility during the pandemic crisis.\",\n",
    "    \"Quantum physics reveals the strange behavior of particles at subatomic levels.\",\n",
    "    \"Professional chefs recommend using fresh herbs to enhance flavor profiles.\",\n",
    "    \"Ancient Egyptian pyramids were built using sophisticated engineering techniques.\",\n",
    "    \"Regular exercise and proper nutrition are essential for maintaining good health.\",\n",
    "    \"The International Space Station orbits Earth approximately every ninety minutes.\",\n",
    "    \"Cryptocurrency markets operate twenty-four hours a day across global exchanges.\",\n",
    "    \"Vincent van Gogh painted Starry Night while staying at an asylum.\",\n",
    "    \"Professional athletes must maintain strict training regimens throughout their careers.\",\n",
    "    \"The Amazon rainforest produces twenty percent of the world's oxygen supply.\",\n",
    "    \"Modern architecture emphasizes clean lines and functional design principles.\",\n",
    "    \"Forensic scientists use DNA analysis to solve complex criminal investigations.\",\n",
    "    \"Traditional Japanese tea ceremonies follow centuries-old ritualistic practices.\",\n",
    "    \"Marine biologists study coral reef ecosystems threatened by ocean acidification.\",\n",
    "    \"The Renaissance period marked a cultural rebirth in European art and science.\",\n",
    "    \"Cybersecurity experts work tirelessly to protect digital infrastructure from threats.\",\n",
    "    \"Sustainable agriculture practices help preserve soil quality for future generations.\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb31afe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing text 1/5 ===\n",
      "Processing: The quick brown fox jumps over the lazy dog....\n",
      "Input tokens: 13\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_0.png\n",
      "Completed text 1\n",
      "\n",
      "=== Processing text 2/5 ===\n",
      "Processing: Artificial intelligence is transforming the world ...\n",
      "Input tokens: 13\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_1.png\n",
      "Completed text 2\n",
      "\n",
      "=== Processing text 3/5 ===\n",
      "Processing: In a hole in the ground there lived a hobbit....\n",
      "Input tokens: 14\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_2.png\n",
      "Completed text 3\n",
      "\n",
      "=== Processing text 4/5 ===\n",
      "Processing: To be or not to be, that is the question Shakespea...\n",
      "Input tokens: 16\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_3.png\n",
      "Completed text 4\n",
      "\n",
      "=== Processing text 5/5 ===\n",
      "Processing: Machine learning models require large datasets for...\n",
      "Input tokens: 10\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "Visualization saved to neuron_comparison_text_4.png\n",
      "Completed text 5\n"
     ]
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for i, text in enumerate(TEST_TEXTS):\n",
    "    print(f\"\\n=== Processing text {i+1}/{len(TEST_TEXTS)} ===\")\n",
    "    \n",
    "    try:\n",
    "        # Use different seed for each text to get variety\n",
    "        result = run_comparison(text, seed=42+i)\n",
    "        \n",
    "        all_results.append(result)\n",
    "        \n",
    "        # Save detailed results\n",
    "        save_detailed_results(result, filename=\"all_layers_activation_comparison.csv\")\n",
    "        \n",
    "        print(f\"Completed text {i+1}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing text {i+1}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d90a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary visualization saved to activation_summary_all_layers.png\n",
      "\n",
      "=== SUMMARY STATISTICS (ALL LAYERS) ===\n",
      "\n",
      "Top 10 layers by average difference:\n",
      "  lm_head: 0.910089 ± 0.295044\n",
      "  layer_31_mlp_down: 0.101140 ± 0.032076\n",
      "  layer_30_attention_v: 0.073980 ± 0.050429\n",
      "  layer_30_mlp_down: 0.072233 ± 0.035467\n",
      "  layer_28_attention_k: 0.069618 ± 0.032996\n",
      "  layer_31_attention_k: 0.068672 ± 0.016603\n",
      "  layer_25_attention_q: 0.061632 ± 0.036315\n",
      "  layer_31_attention_q: 0.059968 ± 0.030755\n",
      "  layer_24_attention_q: 0.055806 ± 0.027219\n",
      "  layer_26_attention_q: 0.052486 ± 0.014143\n",
      "\n",
      "Average differences by component type:\n",
      "  normalization: 0.001776 ± 0.002798\n",
      "  attention: 0.026334 ± 0.021456\n",
      "  mlp: 0.011337 ± 0.014316\n",
      "  output: 0.910089 ± 0.295044\n",
      "\n",
      "Overall statistics:\n",
      "  Total comparisons: 19140\n",
      "  Mean absolute difference: 0.019002\n",
      "  Std deviation: 0.071256\n",
      "  Max difference: 3.069078\n",
      "  Min difference: 0.000000\n",
      "  Median difference: 0.005303\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Print summary statistics\n",
    "if all_results:\n",
    "    print(\"\\n=== SUMMARY STATISTICS (ALL LAYERS) ===\")\n",
    "    \n",
    "    all_layer_stats = defaultdict(list)\n",
    "    all_component_stats = defaultdict(list)\n",
    "    \n",
    "    for result in all_results:\n",
    "        for layer_name, layer_data in result['layer_comparisons'].items():\n",
    "            if 'calculations' in layer_data:\n",
    "                diffs = [abs(calc['difference']) for calc in layer_data['calculations']]\n",
    "                if diffs:\n",
    "                    mean_diff = np.mean(diffs)\n",
    "                    all_layer_stats[layer_name].append(mean_diff)\n",
    "                    all_component_stats[layer_data['layer_type']].append(mean_diff)\n",
    "    \n",
    "    print(\"\\nTop 10 layers by average difference:\")\n",
    "    layer_avg_diffs = [(layer, np.mean(diffs)) for layer, diffs in all_layer_stats.items()]\n",
    "    layer_avg_diffs.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    for layer, avg_diff in layer_avg_diffs[:10]:\n",
    "        std_diff = np.std(all_layer_stats[layer])\n",
    "        print(f\"  {layer}: {avg_diff:.6f} ± {std_diff:.6f}\")\n",
    "    \n",
    "    print(\"\\nAverage differences by component type:\")\n",
    "    for component, diffs in all_component_stats.items():\n",
    "        print(f\"  {component}: {np.mean(diffs):.6f} ± {np.std(diffs):.6f}\")\n",
    "    \n",
    "    # Calculate overall statistics\n",
    "    all_differences = []\n",
    "    for result in all_results:\n",
    "        for layer_name, layer_data in result['layer_comparisons'].items():\n",
    "            if 'calculations' in layer_data:\n",
    "                all_differences.extend([abs(calc['difference']) \n",
    "                                      for calc in layer_data['calculations']])\n",
    "    \n",
    "    if all_differences:\n",
    "        print(f\"\\nOverall statistics:\")\n",
    "        print(f\"  Total comparisons: {len(all_differences)}\")\n",
    "        print(f\"  Mean absolute difference: {np.mean(all_differences):.6f}\")\n",
    "        print(f\"  Std deviation: {np.std(all_differences):.6f}\")\n",
    "        print(f\"  Max difference: {np.max(all_differences):.6f}\")\n",
    "        print(f\"  Min difference: {np.min(all_differences):.6f}\")\n",
    "        print(f\"  Median difference: {np.median(all_differences):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa40340e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RUNNING ANALYSIS WITH DIFFERENCE TRACKING\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "Processing Query 1/5\n",
      "Text: The quick brown fox jumps over the lazy dog....\n",
      "======================================================================\n",
      "Processing: The quick brown fox jumps over the lazy dog....\n",
      "Input tokens: 13\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "\n",
      "Input text: The quick brown fox jumps over the lazy dog.\n",
      "\n",
      "============================================================\n",
      "Model 1 Predictions            | Model 2 Predictions           \n",
      "============================================================\n",
      "1. '\n",
      "' (0.456)                    | 1. '\n",
      "' (0.302)\n",
      "2. 'The' (0.043)                  | 2. 'The' (0.107)\n",
      "3. '' (0.039)                     | 3. '' (0.030)\n",
      "4. 'This' (0.023)                 | 4. 'This' (0.028)\n",
      "5. 'It' (0.016)                   | 5. 'I' (0.020)\n",
      "\n",
      "KL Divergence (Model1 || Model2): 0.3582\n",
      "\n",
      "==================================================\n",
      "QUERY 1 DIFFERENCE SUMMARY\n",
      "==================================================\n",
      "Total Absolute Difference: 69.58\n",
      "Number of Layers Analyzed: 290\n",
      "Number of Tokens: 13\n",
      "Average Difference per Layer: 0.24\n",
      "Average Difference per Token: 5.35\n",
      "\n",
      "Top 5 Layers with Highest Differences:\n",
      "  lm_head: 10.31\n",
      "  layer_31_mlp_down: 1.49\n",
      "  layer_30_attention_v: 1.25\n",
      "  layer_31_attention_k: 1.24\n",
      "  layer_24_attention_q: 1.16\n",
      "\n",
      "Completed Query 1\n",
      "\n",
      "======================================================================\n",
      "Processing Query 2/5\n",
      "Text: Artificial intelligence is transforming the world of technol...\n",
      "======================================================================\n",
      "Processing: Artificial intelligence is transforming the world ...\n",
      "Input tokens: 13\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "\n",
      "Input text: Artificial intelligence is transforming the world of technology.\n",
      "\n",
      "============================================================\n",
      "Model 1 Predictions            | Model 2 Predictions           \n",
      "============================================================\n",
      "1. 'Here' (0.643)                 | 1. 'It' (0.094)\n",
      "2. 'It' (0.056)                   | 2. 'The' (0.072)\n",
      "3. 'However' (0.034)              | 3. '\n",
      "' (0.065)\n",
      "4. 'In' (0.033)                   | 4. 'Art' (0.051)\n",
      "5. 'With' (0.031)                 | 5. 'In' (0.049)\n",
      "\n",
      "KL Divergence (Model1 || Model2): 2.3150\n",
      "\n",
      "==================================================\n",
      "QUERY 2 DIFFERENCE SUMMARY\n",
      "==================================================\n",
      "Total Absolute Difference: 73.78\n",
      "Number of Layers Analyzed: 290\n",
      "Number of Tokens: 13\n",
      "Average Difference per Layer: 0.25\n",
      "Average Difference per Token: 5.68\n",
      "\n",
      "Top 5 Layers with Highest Differences:\n",
      "  lm_head: 11.44\n",
      "  layer_18_attention_q: 1.46\n",
      "  layer_31_mlp_down: 1.40\n",
      "  layer_25_attention_q: 1.36\n",
      "  layer_30_mlp_down: 1.06\n",
      "\n",
      "Completed Query 2\n",
      "\n",
      "======================================================================\n",
      "Processing Query 3/5\n",
      "Text: In a hole in the ground there lived a hobbit....\n",
      "======================================================================\n",
      "Processing: In a hole in the ground there lived a hobbit....\n",
      "Input tokens: 14\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "\n",
      "Input text: In a hole in the ground there lived a hobbit.\n",
      "\n",
      "============================================================\n",
      "Model 1 Predictions            | Model 2 Predictions           \n",
      "============================================================\n",
      "1. '\n",
      "' (0.182)                    | 1. '\n",
      "' (0.153)\n",
      "2. 'Not' (0.182)                  | 2. 'Tol' (0.075)\n",
      "3. 'Tol' (0.046)                  | 3. 'Hob' (0.052)\n",
      "4. 'Not' (0.045)                  | 4. 'A' (0.036)\n",
      "5. 'There' (0.043)                | 5. 'He' (0.030)\n",
      "\n",
      "KL Divergence (Model1 || Model2): 0.8663\n",
      "\n",
      "==================================================\n",
      "QUERY 3 DIFFERENCE SUMMARY\n",
      "==================================================\n",
      "Total Absolute Difference: 70.06\n",
      "Number of Layers Analyzed: 290\n",
      "Number of Tokens: 14\n",
      "Average Difference per Layer: 0.24\n",
      "Average Difference per Token: 5.00\n",
      "\n",
      "Top 5 Layers with Highest Differences:\n",
      "  lm_head: 7.44\n",
      "  layer_30_attention_v: 2.27\n",
      "  layer_31_mlp_down: 1.94\n",
      "  layer_27_attention_q: 1.20\n",
      "  layer_24_attention_q: 1.18\n",
      "\n",
      "Completed Query 3\n",
      "\n",
      "======================================================================\n",
      "Processing Query 4/5\n",
      "Text: To be or not to be, that is the question Shakespeare posed....\n",
      "======================================================================\n",
      "Processing: To be or not to be, that is the question Shakespea...\n",
      "Input tokens: 16\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "\n",
      "Input text: To be or not to be, that is the question Shakespeare posed.\n",
      "\n",
      "============================================================\n",
      "Model 1 Predictions            | Model 2 Predictions           \n",
      "============================================================\n",
      "1. '\n",
      "' (0.192)                    | 1. '\n",
      "' (0.246)\n",
      "2. 'Here' (0.109)                 | 2. 'The' (0.061)\n",
      "3. 'In' (0.065)                   | 3. 'It' (0.045)\n",
      "4. 'But' (0.057)                  | 4. 'In' (0.038)\n",
      "5. 'Is' (0.052)                   | 5. 'And' (0.026)\n",
      "\n",
      "KL Divergence (Model1 || Model2): 0.5378\n",
      "\n",
      "==================================================\n",
      "QUERY 4 DIFFERENCE SUMMARY\n",
      "==================================================\n",
      "Total Absolute Difference: 96.96\n",
      "Number of Layers Analyzed: 290\n",
      "Number of Tokens: 16\n",
      "Average Difference per Layer: 0.33\n",
      "Average Difference per Token: 6.06\n",
      "\n",
      "Top 5 Layers with Highest Differences:\n",
      "  lm_head: 22.99\n",
      "  layer_31_attention_q: 1.84\n",
      "  layer_31_mlp_down: 1.65\n",
      "  layer_28_attention_q: 1.45\n",
      "  layer_22_attention_q: 1.31\n",
      "\n",
      "Completed Query 4\n",
      "\n",
      "======================================================================\n",
      "Processing Query 5/5\n",
      "Text: Machine learning models require large datasets for training....\n",
      "======================================================================\n",
      "Processing: Machine learning models require large datasets for...\n",
      "Input tokens: 10\n",
      "Registering hooks...\n",
      "Running models...\n",
      "Captured 290 activations from Model 1\n",
      "Captured 290 activations from Model 2\n",
      "Selecting random neurons...\n",
      "Selected neurons from 290 layers\n",
      "Comparing activations...\n",
      "\n",
      "Input text: Machine learning models require large datasets for training.\n",
      "\n",
      "============================================================\n",
      "Model 1 Predictions            | Model 2 Predictions           \n",
      "============================================================\n",
      "1. 'Here' (0.237)                 | 1. 'Machine' (0.170)\n",
      "2. 'In' (0.105)                   | 2. 'They' (0.069)\n",
      "3. 'However' (0.079)              | 3. 'The' (0.059)\n",
      "4. 'This' (0.074)                 | 4. 'This' (0.050)\n",
      "5. 'They' (0.071)                 | 5. '\n",
      "' (0.046)\n",
      "\n",
      "KL Divergence (Model1 || Model2): 1.1488\n",
      "\n",
      "==================================================\n",
      "QUERY 5 DIFFERENCE SUMMARY\n",
      "==================================================\n",
      "Total Absolute Difference: 53.32\n",
      "Number of Layers Analyzed: 290\n",
      "Number of Tokens: 10\n",
      "Average Difference per Layer: 0.18\n",
      "Average Difference per Token: 5.33\n",
      "\n",
      "Top 5 Layers with Highest Differences:\n",
      "  lm_head: 9.09\n",
      "  layer_30_mlp_down: 1.33\n",
      "  layer_28_attention_k: 1.30\n",
      "  layer_25_attention_q: 1.01\n",
      "  layer_18_attention_k: 0.85\n",
      "\n",
      "Completed Query 5\n",
      "Difference summary visualization saved to difference_summary.png\n",
      "\n",
      "======================================================================\n",
      "FINAL SUMMARY TABLE WITH DIFFERENCES\n",
      "======================================================================\n",
      " Query                                        Text Total_Diff Avg_Layer_Diff KL_Div Top1_Match\n",
      "     1 The quick brown fox jumps over the lazy ...      69.58           0.24 0.3582          ✓\n",
      "     2 Artificial intelligence is transforming ...      73.78           0.25 2.3150          ✗\n",
      "     3 In a hole in the ground there lived a ho...      70.06           0.24 0.8663          ✓\n",
      "     4 To be or not to be, that is the question...      96.96           0.33 0.5378          ✓\n",
      "     5 Machine learning models require large da...      53.32           0.18 1.1488          ✗\n",
      "\n",
      "Correlation plot saved to activation_output_correlation.png\n",
      "Correlation coefficient: -0.214\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_differences(result):\n",
    "    total_diff = 0\n",
    "    layer_diffs = {}\n",
    "    token_diffs = {}\n",
    "    \n",
    "    for layer_name, layer_data in result['layer_comparisons'].items():\n",
    "        if 'calculations' not in layer_data or not layer_data['calculations']:\n",
    "            continue\n",
    "        \n",
    "        layer_sum = 0\n",
    "        for calc in layer_data['calculations']:\n",
    "            diff = abs(calc['difference'])\n",
    "            layer_sum += diff\n",
    "            \n",
    "            # Track per-token differences\n",
    "            token_pos = calc['token_position']\n",
    "            if token_pos not in token_diffs:\n",
    "                token_diffs[token_pos] = 0\n",
    "            token_diffs[token_pos] += diff\n",
    "        \n",
    "        layer_diffs[layer_name] = layer_sum\n",
    "        total_diff += layer_sum\n",
    "    \n",
    "    return {\n",
    "        'total_difference': total_diff,\n",
    "        'layer_differences': layer_diffs,\n",
    "        'token_differences': token_diffs,\n",
    "        'num_layers': len(layer_diffs),\n",
    "        'num_tokens': len(token_diffs)\n",
    "    }\n",
    "\n",
    "def decode_and_compare_outputs(result, tokenizer, top_k=5):\n",
    "    input_ids = result['tokenized_input']['input_ids']\n",
    "    logits_1 = result['model_1_output']\n",
    "    logits_2 = result['model_2_output']\n",
    "    \n",
    "    # Get predictions for the last token (next token prediction)\n",
    "    last_token_logits_1 = logits_1[0, -1, :]  # [vocab_size]\n",
    "    last_token_logits_2 = logits_2[0, -1, :]  # [vocab_size]\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    probs_1 = torch.softmax(last_token_logits_1, dim=-1)\n",
    "    probs_2 = torch.softmax(last_token_logits_2, dim=-1)\n",
    "    \n",
    "    top_probs_1, top_indices_1 = torch.topk(probs_1, top_k)\n",
    "    top_probs_2, top_indices_2 = torch.topk(probs_2, top_k)\n",
    "    \n",
    "    # Decode tokens\n",
    "    input_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"\\nInput text: {input_text}\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"{'Model 1 Predictions':<30} | {'Model 2 Predictions':<30}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for i in range(top_k):\n",
    "        token_1 = tokenizer.decode(top_indices_1[i])\n",
    "        prob_1 = top_probs_1[i].item()\n",
    "        \n",
    "        token_2 = tokenizer.decode(top_indices_2[i])\n",
    "        prob_2 = top_probs_2[i].item()\n",
    "        \n",
    "        print(f\"{i+1}. '{token_1}' ({prob_1:.3f}){' '*(20-len(token_1))} | \"\n",
    "              f\"{i+1}. '{token_2}' ({prob_2:.3f})\")\n",
    "    \n",
    "    # Calculate Jensen-Shannon divergence between distributions\n",
    "    def jensen_shannon_divergence(p, q):\n",
    "        \"\"\"Calculate Jensen-Shannon divergence between two probability distributions.\"\"\"\n",
    "        # Add small epsilon for numerical stability\n",
    "        p = p + 1e-10\n",
    "        q = q + 1e-10\n",
    "        \n",
    "        # Calculate the average distribution M = (P + Q) / 2\n",
    "        m = (p + q) / 2\n",
    "        \n",
    "        # Calculate KL divergences: KL(P||M) and KL(Q||M)\n",
    "        kl_pm = torch.nn.functional.kl_div(torch.log(m), p, reduction='sum')\n",
    "        kl_qm = torch.nn.functional.kl_div(torch.log(m), q, reduction='sum')\n",
    "        \n",
    "        # Jensen-Shannon divergence = (KL(P||M) + KL(Q||M)) / 2\n",
    "        js_div = (kl_pm + kl_qm) / 2\n",
    "        \n",
    "        return js_div.item()\n",
    "    \n",
    "    js_div = jensen_shannon_divergence(probs_1, probs_2)\n",
    "    \n",
    "    print(f\"\\nJensen-Shannon Divergence: {js_div:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'top_tokens_model_1': [tokenizer.decode(idx) for idx in top_indices_1],\n",
    "        'top_probs_model_1': top_probs_1.tolist(),\n",
    "        'top_tokens_model_2': [tokenizer.decode(idx) for idx in top_indices_2],\n",
    "        'top_probs_model_2': top_probs_2.tolist(),\n",
    "        'jensen_shannon_divergence': js_div\n",
    "    }\n",
    "\n",
    "def visualize_difference_summary(all_results, save_path='difference_summary.png'):\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    fig.suptitle('Sum of Activation Differences Analysis', fontsize=16)\n",
    "    \n",
    "    # 1. Total differences per query\n",
    "    ax = axes[0, 0]\n",
    "    total_diffs = []\n",
    "    query_labels = []\n",
    "    \n",
    "    for i, result in enumerate(all_results):\n",
    "        diff_analysis = calculate_total_differences(result)\n",
    "        total_diffs.append(diff_analysis['total_difference'])\n",
    "        query_labels.append(f\"Query {i+1}\")\n",
    "    \n",
    "    bars = ax.bar(query_labels, total_diffs, color='darkblue', alpha=0.7)\n",
    "    ax.set_ylabel('Total Absolute Difference')\n",
    "    ax.set_title('Total Activation Differences per Query')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, value in zip(bars, total_diffs):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{value:.1f}', ha='center', va='bottom')\n",
    "    \n",
    "    # 2. Average difference per layer\n",
    "    ax = axes[0, 1]\n",
    "    avg_diffs_per_layer = []\n",
    "    \n",
    "    for result in all_results:\n",
    "        diff_analysis = calculate_total_differences(result)\n",
    "        if diff_analysis['num_layers'] > 0:\n",
    "            avg_diff = diff_analysis['total_difference'] / diff_analysis['num_layers']\n",
    "            avg_diffs_per_layer.append(avg_diff)\n",
    "    \n",
    "    ax.plot(range(len(avg_diffs_per_layer)), avg_diffs_per_layer, 'ro-', markersize=8)\n",
    "    ax.set_xlabel('Query Index')\n",
    "    ax.set_ylabel('Average Difference per Layer')\n",
    "    ax.set_title('Average Layer Difference by Query')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Difference distribution across layers (for first query)\n",
    "    ax = axes[0, 2]\n",
    "    if all_results:\n",
    "        first_result = all_results[0]\n",
    "        diff_analysis = calculate_total_differences(first_result)\n",
    "        \n",
    "        # Get layer types and their differences\n",
    "        layer_types = {'norm': 0, 'mlp': 0, 'attn': 0, 'other': 0}\n",
    "        for layer_name, diff in diff_analysis['layer_differences'].items():\n",
    "            if 'norm' in layer_name:\n",
    "                layer_types['norm'] += diff\n",
    "            elif 'mlp' in layer_name:\n",
    "                layer_types['mlp'] += diff\n",
    "            elif 'attn' in layer_name:\n",
    "                layer_types['attn'] += diff\n",
    "            else:\n",
    "                layer_types['other'] += diff\n",
    "        \n",
    "        # Create pie chart\n",
    "        non_zero_types = {k: v for k, v in layer_types.items() if v > 0}\n",
    "        if non_zero_types:\n",
    "            ax.pie(non_zero_types.values(), labels=non_zero_types.keys(), \n",
    "                   autopct='%1.1f%%', startangle=90)\n",
    "            ax.set_title('Difference Distribution by Layer Type\\n(Query 1)')\n",
    "    \n",
    "    # 4. Token-wise differences (averaged across queries)\n",
    "    ax = axes[1, 0]\n",
    "    max_tokens = max(len(calculate_total_differences(r)['token_differences']) \n",
    "                     for r in all_results)\n",
    "    \n",
    "    avg_token_diffs = []\n",
    "    for token_pos in range(max_tokens):\n",
    "        token_sum = 0\n",
    "        count = 0\n",
    "        for result in all_results:\n",
    "            diff_analysis = calculate_total_differences(result)\n",
    "            if token_pos in diff_analysis['token_differences']:\n",
    "                token_sum += diff_analysis['token_differences'][token_pos]\n",
    "                count += 1\n",
    "        if count > 0:\n",
    "            avg_token_diffs.append(token_sum / count)\n",
    "        else:\n",
    "            avg_token_diffs.append(0)\n",
    "    \n",
    "    ax.bar(range(len(avg_token_diffs)), avg_token_diffs, color='green', alpha=0.7)\n",
    "    ax.set_xlabel('Token Position')\n",
    "    ax.set_ylabel('Average Absolute Difference')\n",
    "    ax.set_title('Average Difference by Token Position')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 5. Cumulative differences\n",
    "    ax = axes[1, 1]\n",
    "    for i, result in enumerate(all_results):\n",
    "        diff_analysis = calculate_total_differences(result)\n",
    "        \n",
    "        # Sort layers by name for consistent ordering\n",
    "        sorted_layers = sorted(diff_analysis['layer_differences'].items())\n",
    "        layer_names = [l[0] for l in sorted_layers]\n",
    "        layer_diffs = [l[1] for l in sorted_layers]\n",
    "        \n",
    "        # Calculate cumulative sum\n",
    "        cumulative = np.cumsum(layer_diffs)\n",
    "        \n",
    "        # Plot every 10th layer to avoid overcrowding\n",
    "        x_points = list(range(0, len(cumulative), 10))\n",
    "        y_points = [cumulative[i] for i in x_points]\n",
    "        \n",
    "        ax.plot(x_points, y_points, '-o', label=f'Query {i+1}', \n",
    "                markersize=4, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Layer Index (every 10th)')\n",
    "    ax.set_ylabel('Cumulative Difference')\n",
    "    ax.set_title('Cumulative Differences Across Layers')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 6. Summary statistics table\n",
    "    ax = axes[1, 2]\n",
    "    ax.axis('off')\n",
    "    \n",
    "    summary_text = \"Summary Statistics\\n\" + \"=\"*30 + \"\\n\\n\"\n",
    "    \n",
    "    for i, result in enumerate(all_results[:5]):  # Show first 5\n",
    "        diff_analysis = calculate_total_differences(result)\n",
    "        text_preview = result['input_text'][:30] + \"...\"\n",
    "        \n",
    "        summary_text += f\"Query {i+1}: {text_preview}\\n\"\n",
    "        summary_text += f\"  Total Diff: {diff_analysis['total_difference']:.2f}\\n\"\n",
    "        summary_text += f\"  Layers: {diff_analysis['num_layers']}\\n\"\n",
    "        summary_text += f\"  Avg/Layer: {diff_analysis['total_difference']/diff_analysis['num_layers']:.2f}\\n\\n\"\n",
    "    \n",
    "    ax.text(0.05, 0.95, summary_text, transform=ax.transAxes,\n",
    "            fontsize=9, verticalalignment='top', fontfamily='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"Difference summary visualization saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c571d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis with difference tracking\n",
    "all_results = []\n",
    "difference_summaries = []\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING ANALYSIS WITH DIFFERENCE TRACKING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for i, text in enumerate(TEST_TEXTS):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"Processing Query {i+1}/{len(TEST_TEXTS)}\")\n",
    "    print(f\"Text: {text[:60]}...\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    try:\n",
    "        # Run comparison\n",
    "        result = run_comparison(text, seed=42+i)\n",
    "        \n",
    "        # Calculate differences\n",
    "        diff_analysis = calculate_total_differences(result)\n",
    "        \n",
    "        # Add output comparison\n",
    "        output_comp = decode_and_compare_outputs(result, tokenizer, top_k=5)\n",
    "        result['output_comparison'] = output_comp\n",
    "        result['difference_analysis'] = diff_analysis\n",
    "        \n",
    "        all_results.append(result)\n",
    "        difference_summaries.append(diff_analysis)\n",
    "        \n",
    "        # Print summary for this query\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"QUERY {i+1} DIFFERENCE SUMMARY\")\n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"Total Absolute Difference: {diff_analysis['total_difference']:.2f}\")\n",
    "        print(f\"Number of Layers Analyzed: {diff_analysis['num_layers']}\")\n",
    "        print(f\"Number of Tokens: {diff_analysis['num_tokens']}\")\n",
    "        print(f\"Average Difference per Layer: {diff_analysis['total_difference']/diff_analysis['num_layers']:.2f}\")\n",
    "        print(f\"Average Difference per Token: {diff_analysis['total_difference']/diff_analysis['num_tokens']:.2f}\")\n",
    "        \n",
    "        # Show top 5 layers with highest differences\n",
    "        sorted_layers = sorted(diff_analysis['layer_differences'].items(), \n",
    "                             key=lambda x: x[1], reverse=True)[:5]\n",
    "        print(f\"\\nTop 5 Layers with Highest Differences:\")\n",
    "        for layer_name, diff in sorted_layers:\n",
    "            print(f\"  {layer_name}: {diff:.2f}\")\n",
    "        \n",
    "        print(f\"\\nCompleted Query {i+1}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing query {i+1}: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        continue\n",
    "\n",
    "\n",
    "# Create visualizations\n",
    "if all_results:\n",
    "    visualize_difference_summary(all_results, save_path='difference_summary.png')\n",
    "\n",
    "\n",
    "# Create a detailed comparison table with differences\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL SUMMARY TABLE WITH DIFFERENCES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_data = []\n",
    "\n",
    "for i, result in enumerate(all_results):\n",
    "    if 'difference_analysis' in result and 'output_comparison' in result:\n",
    "        diff = result['difference_analysis']\n",
    "        out = result['output_comparison']\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Query': i+1,\n",
    "            'Text': result['input_text'][:40] + '...',\n",
    "            'Total_Diff': f\"{diff['total_difference']:.2f}\",\n",
    "            'Avg_Layer_Diff': f\"{diff['total_difference']/diff['num_layers']:.2f}\",\n",
    "            'KL_Div': f\"{out['kl_divergence']:.4f}\",\n",
    "            'Top1_Match': '✓' if out['top_tokens_model_1'][0] == out['top_tokens_model_2'][0] else '✗'\n",
    "        })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(df_summary.to_string(index=False))\n",
    "\n",
    "# Plot correlation between activation differences and output differences\n",
    "if len(all_results) > 1:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "    \n",
    "    activation_diffs = [r['difference_analysis']['total_difference'] for r in all_results \n",
    "                       if 'difference_analysis' in r]\n",
    "    kl_divs = [r['output_comparison']['kl_divergence'] for r in all_results \n",
    "               if 'output_comparison' in r]\n",
    "    \n",
    "    if len(activation_diffs) == len(kl_divs):\n",
    "        ax.scatter(activation_diffs, kl_divs, s=100, alpha=0.7, c='purple')\n",
    "        \n",
    "        # Add labels for each point\n",
    "        for i, (x, y) in enumerate(zip(activation_diffs, kl_divs)):\n",
    "            ax.annotate(f'Q{i+1}', (x, y), xytext=(5, 5), \n",
    "                       textcoords='offset points', fontsize=9)\n",
    "        \n",
    "        # Add trend line\n",
    "        z = np.polyfit(activation_diffs, kl_divs, 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax.plot(activation_diffs, p(activation_diffs), \"r--\", alpha=0.8, \n",
    "                label=f'Trend: y={z[0]:.4f}x+{z[1]:.4f}')\n",
    "        \n",
    "        ax.set_xlabel('Total Activation Difference')\n",
    "        ax.set_ylabel('KL Divergence')\n",
    "        ax.set_title('Correlation: Activation Differences vs Output Differences')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Calculate correlation\n",
    "        correlation = np.corrcoef(activation_diffs, kl_divs)[0, 1]\n",
    "        ax.text(0.05, 0.95, f'Correlation: {correlation:.3f}', \n",
    "                transform=ax.transAxes, fontsize=12, \n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('activation_output_correlation.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(f\"\\nCorrelation plot saved to activation_output_correlation.png\")\n",
    "        print(f\"Correlation coefficient: {correlation:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
