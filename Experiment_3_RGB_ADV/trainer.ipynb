{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import random\n",
    "from model_structure import get_preprocessing_transforms,BCNN, train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 15,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 60\n",
    "INPUT_SIZE = 224\n",
    "model_number = 1\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 16,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms\n",
    "train_transform, val_transform = get_preprocessing_transforms(INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
=======
   "execution_count": 17,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data set directory\n",
    "train_dir = f'data4model_{model_number}/train/'\n",
    "val_dir = f'data4model_{model_number}/test/'"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 18,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(\n",
    "        root=train_dir,\n",
    "        transform=train_transform\n",
    "    )\n",
    "    \n",
    "val_dataset = datasets.ImageFolder(\n",
    "        root=val_dir,\n",
    "        transform=val_transform\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 16,
=======
   "execution_count": 19,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 20,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BCNN(input_channels=3).to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 21,
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]             896\n",
      "              ReLU-2         [-1, 32, 224, 224]               0\n",
      "         MaxPool2d-3         [-1, 32, 112, 112]               0\n",
      "         Dropout2d-4         [-1, 32, 112, 112]               0\n",
      "            Conv2d-5         [-1, 64, 112, 112]          18,496\n",
      "              ReLU-6         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-7           [-1, 64, 56, 56]               0\n",
      "         Dropout2d-8           [-1, 64, 56, 56]               0\n",
      "            Conv2d-9          [-1, 128, 56, 56]          73,856\n",
      "             ReLU-10          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 128, 28, 28]               0\n",
      "        Dropout2d-12          [-1, 128, 28, 28]               0\n",
      "          Flatten-13               [-1, 100352]               0\n",
      "           Linear-14                  [-1, 512]      51,380,736\n",
      "             ReLU-15                  [-1, 512]               0\n",
      "          Dropout-16                  [-1, 512]               0\n",
      "           Linear-17                    [-1, 2]           1,026\n",
      "          Softmax-18                    [-1, 2]               0\n",
      "================================================================\n",
      "Total params: 51,475,010\n",
      "Trainable params: 51,475,010\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 54.37\n",
      "Params size (MB): 196.36\n",
      "Estimated Total Size (MB): 251.31\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (3, INPUT_SIZE, INPUT_SIZE))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 2])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tracker \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_number\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\hskay\\OneDrive\\Documents\\GitHub\\ML_ZK\\Experiment_3_RGB_ADV\\model_structure.py:191\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, criterion, optimizer, num_epochs, device, model_number)\u001b[0m\n\u001b[0;32m    189\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m    190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m--> 191\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    193\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m    194\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\loss.py:697\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 697\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\functional.py:3545\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[1;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   3543\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[0;32m   3544\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[1;32m-> 3545\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3546\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3547\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3548\u001b[0m     )\n\u001b[0;32m   3550\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3551\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[1;31mValueError\u001b[0m: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 2])) is deprecated. Please ensure they have the same size."
=======
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/60]\n",
      "Training Loss: 0.7288, Validation Loss: 0.6780\n",
      "Training Acc: 0.5163, Validation Acc: 0.5000\n",
      "Training F1: 0.5297, Validation F1: 0.6667\n",
      "Epoch [2/60]\n",
      "Training Loss: 0.6742, Validation Loss: 0.6381\n",
      "Training Acc: 0.6000, Validation Acc: 0.7250\n",
      "Training F1: 0.5940, Validation F1: 0.6893\n",
      "Epoch [3/60]\n",
      "Training Loss: 0.6370, Validation Loss: 0.5844\n",
      "Training Acc: 0.6390, Validation Acc: 0.6050\n",
      "Training F1: 0.6225, Validation F1: 0.7148\n",
      "Epoch [4/60]\n",
      "Training Loss: 0.5960, Validation Loss: 0.4830\n",
      "Training Acc: 0.6973, Validation Acc: 0.7400\n",
      "Training F1: 0.6878, Validation F1: 0.7524\n",
      "Epoch [5/60]\n",
      "Training Loss: 0.5667, Validation Loss: 0.4754\n",
      "Training Acc: 0.7180, Validation Acc: 0.7750\n",
      "Training F1: 0.7105, Validation F1: 0.7541\n",
      "Epoch [6/60]\n",
      "Training Loss: 0.5338, Validation Loss: 0.4865\n",
      "Training Acc: 0.7393, Validation Acc: 0.7800\n",
      "Training F1: 0.7316, Validation F1: 0.7732\n",
      "Epoch [7/60]\n",
      "Training Loss: 0.5218, Validation Loss: 0.3946\n",
      "Training Acc: 0.7517, Validation Acc: 0.8150\n",
      "Training F1: 0.7479, Validation F1: 0.8122\n",
      "Epoch [8/60]\n",
      "Training Loss: 0.4825, Validation Loss: 0.3918\n",
      "Training Acc: 0.7697, Validation Acc: 0.8100\n",
      "Training F1: 0.7676, Validation F1: 0.8333\n",
      "Epoch [9/60]\n",
      "Training Loss: 0.4799, Validation Loss: 0.3800\n",
      "Training Acc: 0.7777, Validation Acc: 0.8000\n",
      "Training F1: 0.7767, Validation F1: 0.7959\n",
      "Epoch [10/60]\n",
      "Training Loss: 0.4656, Validation Loss: 0.3966\n",
      "Training Acc: 0.7810, Validation Acc: 0.8150\n",
      "Training F1: 0.7787, Validation F1: 0.8103\n",
      "Epoch [11/60]\n",
      "Training Loss: 0.4643, Validation Loss: 0.3490\n",
      "Training Acc: 0.7940, Validation Acc: 0.8500\n",
      "Training F1: 0.7941, Validation F1: 0.8387\n",
      "Epoch [12/60]\n",
      "Training Loss: 0.4573, Validation Loss: 0.3735\n",
      "Training Acc: 0.7780, Validation Acc: 0.8100\n",
      "Training F1: 0.7767, Validation F1: 0.8288\n",
      "Epoch [13/60]\n",
      "Training Loss: 0.4474, Validation Loss: 0.3394\n",
      "Training Acc: 0.7980, Validation Acc: 0.8600\n",
      "Training F1: 0.7985, Validation F1: 0.8614\n",
      "Epoch [14/60]\n",
      "Training Loss: 0.4332, Validation Loss: 0.3161\n",
      "Training Acc: 0.8017, Validation Acc: 0.8750\n",
      "Training F1: 0.8024, Validation F1: 0.8768\n",
      "Epoch [15/60]\n",
      "Training Loss: 0.4120, Validation Loss: 0.3031\n",
      "Training Acc: 0.8187, Validation Acc: 0.8600\n",
      "Training F1: 0.8178, Validation F1: 0.8692\n",
      "Epoch [16/60]\n",
      "Training Loss: 0.4103, Validation Loss: 0.3150\n",
      "Training Acc: 0.8180, Validation Acc: 0.8850\n",
      "Training F1: 0.8186, Validation F1: 0.8900\n",
      "Epoch [17/60]\n",
      "Training Loss: 0.4018, Validation Loss: 0.3050\n",
      "Training Acc: 0.8210, Validation Acc: 0.8700\n",
      "Training F1: 0.8200, Validation F1: 0.8738\n",
      "Epoch [18/60]\n",
      "Training Loss: 0.3948, Validation Loss: 0.3008\n",
      "Training Acc: 0.8213, Validation Acc: 0.8650\n",
      "Training F1: 0.8205, Validation F1: 0.8756\n",
      "Epoch [19/60]\n",
      "Training Loss: 0.4022, Validation Loss: 0.2862\n",
      "Training Acc: 0.8183, Validation Acc: 0.8650\n",
      "Training F1: 0.8185, Validation F1: 0.8643\n",
      "Epoch [20/60]\n",
      "Training Loss: 0.3938, Validation Loss: 0.2917\n",
      "Training Acc: 0.8250, Validation Acc: 0.8750\n",
      "Training F1: 0.8227, Validation F1: 0.8804\n",
      "Epoch [21/60]\n",
      "Training Loss: 0.3705, Validation Loss: 0.2939\n",
      "Training Acc: 0.8407, Validation Acc: 0.8750\n",
      "Training F1: 0.8415, Validation F1: 0.8718\n",
      "Epoch [22/60]\n",
      "Training Loss: 0.3687, Validation Loss: 0.2685\n",
      "Training Acc: 0.8417, Validation Acc: 0.8800\n",
      "Training F1: 0.8398, Validation F1: 0.8776\n",
      "Epoch [23/60]\n",
      "Training Loss: 0.3660, Validation Loss: 0.2820\n",
      "Training Acc: 0.8413, Validation Acc: 0.8700\n",
      "Training F1: 0.8401, Validation F1: 0.8750\n",
      "Epoch [24/60]\n",
      "Training Loss: 0.3850, Validation Loss: 0.2778\n",
      "Training Acc: 0.8347, Validation Acc: 0.8650\n",
      "Training F1: 0.8343, Validation F1: 0.8615\n",
      "Epoch [25/60]\n",
      "Training Loss: 0.3492, Validation Loss: 0.2544\n",
      "Training Acc: 0.8493, Validation Acc: 0.8900\n",
      "Training F1: 0.8486, Validation F1: 0.8942\n",
      "Epoch [26/60]\n",
      "Training Loss: 0.3509, Validation Loss: 0.2603\n",
      "Training Acc: 0.8487, Validation Acc: 0.9050\n",
      "Training F1: 0.8472, Validation F1: 0.9091\n",
      "Epoch [27/60]\n",
      "Training Loss: 0.3372, Validation Loss: 0.2544\n",
      "Training Acc: 0.8580, Validation Acc: 0.8800\n",
      "Training F1: 0.8576, Validation F1: 0.8857\n",
      "Epoch [28/60]\n",
      "Training Loss: 0.3494, Validation Loss: 0.2908\n",
      "Training Acc: 0.8527, Validation Acc: 0.8800\n",
      "Training F1: 0.8514, Validation F1: 0.8889\n",
      "Epoch [29/60]\n",
      "Training Loss: 0.3300, Validation Loss: 0.2481\n",
      "Training Acc: 0.8577, Validation Acc: 0.8850\n",
      "Training F1: 0.8564, Validation F1: 0.8889\n",
      "Epoch [30/60]\n",
      "Training Loss: 0.3167, Validation Loss: 0.2562\n",
      "Training Acc: 0.8647, Validation Acc: 0.8750\n",
      "Training F1: 0.8642, Validation F1: 0.8858\n",
      "Epoch [31/60]\n",
      "Training Loss: 0.3172, Validation Loss: 0.2562\n",
      "Training Acc: 0.8690, Validation Acc: 0.8900\n",
      "Training F1: 0.8677, Validation F1: 0.8972\n",
      "Epoch [32/60]\n",
      "Training Loss: 0.3156, Validation Loss: 0.2504\n",
      "Training Acc: 0.8630, Validation Acc: 0.8950\n",
      "Training F1: 0.8620, Validation F1: 0.9005\n",
      "Epoch [33/60]\n",
      "Training Loss: 0.3230, Validation Loss: 0.2522\n",
      "Training Acc: 0.8657, Validation Acc: 0.8800\n",
      "Training F1: 0.8644, Validation F1: 0.8868\n",
      "Epoch [34/60]\n",
      "Training Loss: 0.3188, Validation Loss: 0.2812\n",
      "Training Acc: 0.8657, Validation Acc: 0.8750\n",
      "Training F1: 0.8648, Validation F1: 0.8858\n",
      "Epoch [35/60]\n",
      "Training Loss: 0.3169, Validation Loss: 0.2472\n",
      "Training Acc: 0.8607, Validation Acc: 0.8900\n",
      "Training F1: 0.8597, Validation F1: 0.8952\n",
      "Epoch [36/60]\n",
      "Training Loss: 0.3093, Validation Loss: 0.2474\n",
      "Training Acc: 0.8693, Validation Acc: 0.8850\n",
      "Training F1: 0.8693, Validation F1: 0.8910\n",
      "Epoch [37/60]\n",
      "Training Loss: 0.2866, Validation Loss: 0.2402\n",
      "Training Acc: 0.8803, Validation Acc: 0.8950\n",
      "Training F1: 0.8802, Validation F1: 0.9005\n",
      "Epoch [38/60]\n",
      "Training Loss: 0.2923, Validation Loss: 0.2537\n",
      "Training Acc: 0.8780, Validation Acc: 0.8700\n",
      "Training F1: 0.8778, Validation F1: 0.8796\n",
      "Epoch [39/60]\n",
      "Training Loss: 0.3010, Validation Loss: 0.2452\n",
      "Training Acc: 0.8710, Validation Acc: 0.9000\n",
      "Training F1: 0.8704, Validation F1: 0.9010\n",
      "Epoch [40/60]\n",
      "Training Loss: 0.2779, Validation Loss: 0.2388\n",
      "Training Acc: 0.8827, Validation Acc: 0.8950\n",
      "Training F1: 0.8824, Validation F1: 0.8995\n",
      "Epoch [41/60]\n",
      "Training Loss: 0.2721, Validation Loss: 0.2631\n",
      "Training Acc: 0.8897, Validation Acc: 0.8900\n",
      "Training F1: 0.8893, Validation F1: 0.8932\n",
      "Epoch [42/60]\n",
      "Training Loss: 0.2867, Validation Loss: 0.2432\n",
      "Training Acc: 0.8860, Validation Acc: 0.8800\n",
      "Training F1: 0.8856, Validation F1: 0.8868\n",
      "Epoch [43/60]\n",
      "Training Loss: 0.2688, Validation Loss: 0.2435\n",
      "Training Acc: 0.8860, Validation Acc: 0.8950\n",
      "Training F1: 0.8850, Validation F1: 0.9014\n",
      "Epoch [44/60]\n",
      "Training Loss: 0.2688, Validation Loss: 0.2398\n",
      "Training Acc: 0.8890, Validation Acc: 0.8750\n",
      "Training F1: 0.8878, Validation F1: 0.8815\n",
      "Epoch [45/60]\n",
      "Training Loss: 0.2602, Validation Loss: 0.2432\n",
      "Training Acc: 0.8913, Validation Acc: 0.8900\n",
      "Training F1: 0.8911, Validation F1: 0.8878\n",
      "Epoch [46/60]\n",
      "Training Loss: 0.2663, Validation Loss: 0.2613\n",
      "Training Acc: 0.8920, Validation Acc: 0.8800\n",
      "Training F1: 0.8914, Validation F1: 0.8879\n",
      "Epoch [47/60]\n",
      "Training Loss: 0.2479, Validation Loss: 0.2310\n",
      "Training Acc: 0.9013, Validation Acc: 0.8750\n",
      "Training F1: 0.9010, Validation F1: 0.8768\n",
      "Epoch [48/60]\n",
      "Training Loss: 0.2399, Validation Loss: 0.2888\n",
      "Training Acc: 0.9083, Validation Acc: 0.8600\n",
      "Training F1: 0.9079, Validation F1: 0.8727\n",
      "Epoch [49/60]\n",
      "Training Loss: 0.2467, Validation Loss: 0.2615\n",
      "Training Acc: 0.8977, Validation Acc: 0.8650\n",
      "Training F1: 0.8972, Validation F1: 0.8732\n",
      "Epoch [50/60]\n",
      "Training Loss: 0.2415, Validation Loss: 0.2481\n",
      "Training Acc: 0.9040, Validation Acc: 0.8700\n",
      "Training F1: 0.9037, Validation F1: 0.8774\n",
      "Epoch [51/60]\n",
      "Training Loss: 0.2551, Validation Loss: 0.2301\n",
      "Training Acc: 0.9047, Validation Acc: 0.8850\n",
      "Training F1: 0.9042, Validation F1: 0.8878\n",
      "Epoch [52/60]\n",
      "Training Loss: 0.2366, Validation Loss: 0.2223\n",
      "Training Acc: 0.9057, Validation Acc: 0.8900\n",
      "Training F1: 0.9049, Validation F1: 0.8932\n",
      "Epoch [53/60]\n",
      "Training Loss: 0.2314, Validation Loss: 0.2282\n",
      "Training Acc: 0.9070, Validation Acc: 0.9050\n",
      "Training F1: 0.9064, Validation F1: 0.9082\n",
      "Epoch [54/60]\n",
      "Training Loss: 0.2298, Validation Loss: 0.2730\n",
      "Training Acc: 0.9077, Validation Acc: 0.8800\n",
      "Training F1: 0.9069, Validation F1: 0.8909\n",
      "Epoch [55/60]\n",
      "Training Loss: 0.2272, Validation Loss: 0.2249\n",
      "Training Acc: 0.9110, Validation Acc: 0.9000\n",
      "Training F1: 0.9110, Validation F1: 0.9038\n",
      "Epoch [56/60]\n",
      "Training Loss: 0.2113, Validation Loss: 0.2272\n",
      "Training Acc: 0.9123, Validation Acc: 0.8900\n",
      "Training F1: 0.9115, Validation F1: 0.8952\n",
      "Epoch [57/60]\n",
      "Training Loss: 0.2206, Validation Loss: 0.2547\n",
      "Training Acc: 0.9133, Validation Acc: 0.8800\n",
      "Training F1: 0.9128, Validation F1: 0.8879\n",
      "Epoch [58/60]\n",
      "Training Loss: 0.2096, Validation Loss: 0.2314\n",
      "Training Acc: 0.9203, Validation Acc: 0.8800\n",
      "Training F1: 0.9197, Validation F1: 0.8857\n",
      "Epoch [59/60]\n",
      "Training Loss: 0.2289, Validation Loss: 0.2242\n",
      "Training Acc: 0.9083, Validation Acc: 0.8800\n",
      "Training F1: 0.9076, Validation F1: 0.8857\n",
      "Epoch [60/60]\n",
      "Training Loss: 0.2057, Validation Loss: 0.2515\n",
      "Training Acc: 0.9160, Validation Acc: 0.8700\n",
      "Training F1: 0.9157, Validation F1: 0.8660\n"
>>>>>>> c5c136d9379f8c7e7e1cc7ca6164d7c080095ab2
     ]
    }
   ],
   "source": [
    "tracker = train_model(model, train_loader, val_loader, criterion, optimizer, NUM_EPOCHS, DEVICE, model_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
