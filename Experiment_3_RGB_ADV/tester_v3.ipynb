{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from adjustText import adjust_text\n",
    "import random\n",
    "from model_structure import get_preprocessing_transforms,BCNN, train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "DEVICE =torch.device('cuda' if torch.cuda.is_available() else 'cpu')#torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    # Get transforms\n",
    "    train_transform, val_transform = get_preprocessing_transforms(INPUT_SIZE)\n",
    "\n",
    "    test_data_1_dir = 'data4model_1/test/'\n",
    "    test_data_2_dir = 'data4model_2/test/'\n",
    "    train_data_1_dir = 'data4model_1/train/'\n",
    "    train_data_2_dir = 'data4model_2/train/'\n",
    "\n",
    "    # Load data set\n",
    "    dataset_test_1 = datasets.ImageFolder(test_data_1_dir,transform=val_transform)\n",
    "    dataset_train_1 = datasets.ImageFolder(train_data_1_dir,transform=train_transform)\n",
    "    dataset_test_2 = datasets.ImageFolder(test_data_2_dir,transform=val_transform)\n",
    "    dataset_train_2 = datasets.ImageFolder(train_data_2_dir,transform=train_transform)\n",
    "\n",
    "    test_loader_1 = DataLoader(dataset_test_1, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    train_loader_1 = DataLoader(dataset_train_1, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    test_loader_2 = DataLoader(dataset_test_2, shuffle=False, batch_size=BATCH_SIZE)\n",
    "    train_loader_2 = DataLoader(dataset_train_2, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "    return {\"Model_1:Train\": train_loader_1,\n",
    "            \"Model_1:Test\": test_loader_1,\n",
    "            \"Model_2:Train\": train_loader_2,\n",
    "            \"Model_2:Test\": test_loader_2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_dir = 'best_model_1.pth'\n",
    "model_2_dir = 'best_model_2.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskay\\AppData\\Local\\Temp\\ipykernel_23008\\1438434258.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_1_dir, map_location=torch.device(DEVICE))\n",
      "C:\\Users\\hskay\\AppData\\Local\\Temp\\ipykernel_23008\\1438434258.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_2_dir, map_location=torch.device(DEVICE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout2d(p=0.25, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout2d(p=0.25, inplace=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=100352, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "    (5): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model_1 = BCNN().to(DEVICE)\n",
    "weights = torch.load(model_1_dir, map_location=torch.device(DEVICE))\n",
    "model_1.load_state_dict(weights)\n",
    "model_1.eval()\n",
    "\n",
    "model_2 = BCNN().to(DEVICE)\n",
    "weights = torch.load(model_2_dir, map_location=torch.device(DEVICE))\n",
    "model_2.load_state_dict(weights)\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataSets = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1:Train\n",
      "Accuracy:  0.9156666666666666\n",
      "F1 Score:  0.915356306457009\n",
      "confusion Matrix: \n",
      " [[1379  121]\n",
      " [ 132 1368]]\n",
      "\n",
      "\n",
      "Model_1:Test\n",
      "Accuracy:  0.7262644728823888\n",
      "F1 Score:  0.741422979507253\n",
      "confusion Matrix: \n",
      " [[2739 1361]\n",
      " [ 885 3220]]\n",
      "\n",
      "\n",
      "Model_2:Train\n",
      "Accuracy:  0.897\n",
      "F1 Score:  0.8952897322941376\n",
      "confusion Matrix: \n",
      " [[1370  130]\n",
      " [ 179 1321]]\n",
      "\n",
      "\n",
      "Model_2:Test\n",
      "Accuracy:  0.905\n",
      "F1 Score:  0.9090909090909091\n",
      "confusion Matrix: \n",
      " [[86 14]\n",
      " [ 5 95]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for key in dataSets:\n",
    "    print(key)\n",
    "    if \"Model_1\" in key:\n",
    "        model = model_1\n",
    "    else:\n",
    "        model = model_2\n",
    "    \n",
    "    results = evaluate_model(model.to(DEVICE), dataSets[key], DEVICE)\n",
    "    print(\"Accuracy: \", results[0])\n",
    "    print(\"F1 Score: \", results[1])\n",
    "    print(\"confusion Matrix: \\n\",results[3])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_values = {\"Model_1\":{},\n",
    "                        \"Model_2\":{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_activation(name,model_name):\n",
    "    def hook(model, input, output):\n",
    "        activation_values[model_name][name] = output.detach()\n",
    "    return hook\n",
    "\n",
    "def register_hooks(model,model_name):\n",
    "    hooks = []\n",
    "    layer_info = {}\n",
    "    counter = 0\n",
    "    for name, layer in model.named_modules():\n",
    "        #if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "            # Register hook for the full layer output\n",
    "            hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            \n",
    "            if isinstance(layer, nn.Linear) and False:\n",
    "                layer_info[name] = {'type': f'{counter}-linear',}\n",
    "                hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            elif isinstance(layer, nn.Conv2d) and False:\n",
    "                layer_info[name] = {'type': f'{counter}-conv'}\n",
    "                hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            elif isinstance(layer, nn.ReLU):\n",
    "                 layer_info[name] = {'type': f'{counter}-relu'}\n",
    "                 hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            # elif isinstance(layer, nn.MaxPool2d):\n",
    "            #     layer_info[name] = {'type': f'{counter}-maxpool'}\n",
    "            # elif isinstance(layer, nn.Dropout):\n",
    "            #     layer_info[name] = {'type': f'{counter}-dropout'}\n",
    "            # elif isinstance(layer, nn.Flatten):\n",
    "            #     layer_info[name] = {'type': f'{counter}-flatten'}\n",
    "            elif isinstance(layer, nn.Sigmoid):\n",
    "                layer_info[name] = {'type': f'{counter}-sigmoid'}\n",
    "            # else:\n",
    "            #     layer_info[name] = {'type': f'{counter}-other'}\n",
    "            counter += 1\n",
    "    return hooks, layer_info\n",
    "\n",
    "\n",
    "def analyze_positive_activations(activations1, activations2,layers1,layers2, pic_index, model1_name=\"Model 1\", model2_name=\"Model 2\",\n",
    "                                     image=None,  \n",
    "                                    pred1=None,  \n",
    "                                    pred2=None):\n",
    "    def get_layer_stats(activations, layers):\n",
    "        layer_stats = {}\n",
    "        for layer_name, layer_data in layers.items():\n",
    "            activation = activations[layer_name]\n",
    "            flattened = activation.view(activation.shape[0], -1)\n",
    "            positive_activations = flattened[flattened > 0]\n",
    "            \n",
    "            stats = {\n",
    "                'count': len(positive_activations),\n",
    "                'total_neurons': flattened.numel(),\n",
    "                'percentage_active': (len(positive_activations) / flattened.numel()) * 100,\n",
    "                'mean': positive_activations.mean().item() if len(positive_activations) > 0 else 0,\n",
    "                'sum': positive_activations.sum().item(),\n",
    "                'max': positive_activations.max().item() if len(positive_activations) > 0 else 0,\n",
    "                'min': positive_activations.min().item() if len(positive_activations) > 0 else 0,\n",
    "                'variance': positive_activations.var().item() if len(positive_activations) > 0 else 0\n",
    "            }\n",
    "            layer_stats[layer_name.split(\".\")[0]+\" \"+layers[layer_name][\"type\"]] = stats\n",
    "        return layer_stats\n",
    "\n",
    "    # Get stats for both models\n",
    "    stats1 = get_layer_stats(activations1,layers1)\n",
    "    stats2 = get_layer_stats(activations2,layers2)\n",
    "\n",
    "    # Create combined DataFrame\n",
    "    combined_stats = {}\n",
    "    for layer_name in stats1.keys():\n",
    "        combined_stats[layer_name] = {\n",
    "            f'data_index':pic_index,\n",
    "            f'count_{model1_name}': stats1[layer_name]['count'],\n",
    "            f'count_{model2_name}': stats2[layer_name]['count'],\n",
    "            f'total_neurons_{model1_name}': stats1[layer_name]['total_neurons'],\n",
    "            f'total_neurons_{model2_name}': stats2[layer_name]['total_neurons'],\n",
    "            f'percentage_active_{model1_name}': stats1[layer_name]['percentage_active'],\n",
    "            f'percentage_active_{model2_name}': stats2[layer_name]['percentage_active'],\n",
    "            f'mean_{model1_name}': stats1[layer_name]['mean'],\n",
    "            f'mean_{model2_name}': stats2[layer_name]['mean'],\n",
    "            f'sum_{model1_name}': stats1[layer_name]['sum'],\n",
    "            f'sum_{model2_name}': stats2[layer_name]['sum'],\n",
    "            f'max_{model1_name}': stats1[layer_name]['max'],\n",
    "            f'max_{model2_name}': stats2[layer_name]['max'],\n",
    "            f'min_{model1_name}': stats1[layer_name]['min'],\n",
    "            f'min_{model2_name}': stats2[layer_name]['min'],\n",
    "            f'variance_{model1_name}': stats1[layer_name]['variance'],\n",
    "            f'variance_{model2_name}': stats2[layer_name]['variance']\n",
    "        }\n",
    "\n",
    "    df_combined = pd.DataFrame.from_dict(combined_stats, orient='index')\n",
    "    \n",
    "    # # Print combined statistics\n",
    "    # print(\"\\nCombined Analysis for Both Models:\")\n",
    "    # print(\"=\" * 80)\n",
    "    # print(df_combined)\n",
    "    \n",
    "    # # Create comparison visualizations (same as before)\n",
    "    # fig, axes = plt.subplots(3, 2, figsize=(20, 20))\n",
    "\n",
    "    # # Plot 0 and -1: Image and Predictions\n",
    "    # axes[0, 0].imshow(image.permute(1, 2, 0))\n",
    "    # axes[0, 0].set_title('Image')\n",
    "\n",
    "    # axes[0, 1].bar(['Model 1', 'Model 2'], \n",
    "    #         [pred1.item(), pred2.item()])\n",
    "    # axes[0, 1].set_title('Predictions')\n",
    "    \n",
    "    # # Plot 1: Percentage of active neurons comparison\n",
    "    # ax1 = axes[1, 0]\n",
    "    # x = np.arange(len(df_combined))\n",
    "    # width = 0.35\n",
    "    # ax1.bar(x - width/2, df_combined[f'percentage_active_{model1_name}'], width, label=model1_name)\n",
    "    # ax1.bar(x + width/2, df_combined[f'percentage_active_{model2_name}'], width, label=model2_name)\n",
    "    # ax1.set_xticks(x)\n",
    "    # ax1.set_xticklabels(df_combined.index, rotation=45, ha='right')\n",
    "    # ax1.set_title('Percentage of Active Neurons by Layer')\n",
    "    # ax1.set_ylabel('Percentage (%)')\n",
    "    # ax1.legend()\n",
    "\n",
    "    # # Plot 2: Mean activation value comparison\n",
    "    # ax2 = axes[1, 1]\n",
    "    # ax2.bar(x - width/2, df_combined[f'mean_{model1_name}'], width/2, label=model1_name)\n",
    "    # ax2.bar(x, df_combined[f'mean_{model2_name}'], width/2, label=model2_name)\n",
    "    # ax2.bar(x + width/2, abs(df_combined[f'mean_{model1_name}']-df_combined[f'mean_{model2_name}']), width/2, label=f'{model2_name} - {model1_name}')\n",
    "    # ax2.set_xticks(x)\n",
    "    # ax2.set_xticklabels(df_combined.index, rotation=45, ha='right')\n",
    "    # ax2.set_title('Mean Activation Value by Layer')\n",
    "    # ax2.set_ylabel('Mean Value')\n",
    "    # ax2.legend()\n",
    "\n",
    "    # # Plot 3: Total activation sum comparison\n",
    "    # ax3 = axes[2, 0]\n",
    "    # ax3.bar(x - width/2, df_combined[f'sum_{model1_name}'], width/2, label=model1_name)\n",
    "    # ax3.bar(x, df_combined[f'sum_{model2_name}'], width/2, label=model2_name)\n",
    "    # ax3.bar(x + width/2, abs(df_combined[f'sum_{model2_name}'] - df_combined[f'sum_{model1_name}']), width/2, label=f'{model2_name} - {model1_name}')\n",
    "    # ax3.set_xticks(x)\n",
    "    # ax3.set_xticklabels(df_combined.index, rotation=45, ha='right')\n",
    "    # ax3.set_title('Sum of Activations by Layer')\n",
    "    # ax3.set_ylabel('Sum') \n",
    "    # def forward(x):\n",
    "    #     return x**(1/2)\n",
    "    # def inverse(x):\n",
    "    #     return x**2\n",
    "\n",
    "    # ax3.set_yscale('function', functions=(forward, inverse))\n",
    "    # ax3.legend()\n",
    "\n",
    "    # # Plot 4: Count of active neurons comparison\n",
    "    # ax4 = axes[2, 1]\n",
    "    # ax4.bar(x - width/2, df_combined[f'count_{model1_name}'], width, label=model1_name)\n",
    "    # ax4.bar(x + width/2, df_combined[f'count_{model2_name}'], width, label=model2_name)\n",
    "    # ax4.set_xticks(x)\n",
    "    # ax4.set_xticklabels(df_combined.index, rotation=45, ha='right')\n",
    "    # ax4.set_title('Count of Active Neurons by Layer')\n",
    "    # ax4.set_ylabel('Count')\n",
    "    # ax4.set_yscale('function', functions=(forward, inverse))\n",
    "    # ax4.legend()\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # # plt.savefig(f'models_activation_analysis_comparison{pic_index}.png')\n",
    "    # plt.show()\n",
    "\n",
    "    return df_combined\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = [(img, idx) for idx, (img, label) in enumerate(dataSets[\"Model_1:Test\"].dataset) \n",
    "#             if label == 0 ]\n",
    "# image, pic_index = random.choice(images)\n",
    "# with torch.no_grad():\n",
    "#     pred1 = model_1(image.unsqueeze(0).to(DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataSets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel_1:Test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m all_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, pic_index \u001b[38;5;129;01min\u001b[39;00m images:\n",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m----> 2\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataSets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mModel_1:Test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m      5\u001b[0m all_dfs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image, pic_index \u001b[38;5;129;01min\u001b[39;00m images:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:245\u001b[0m, in \u001b[0;36mDatasetFolder.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;124;03m    index (int): Index\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;124;03m    tuple: (sample, target) where target is class_index of the target class.\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    244\u001b[0m path, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msamples[index]\n\u001b[1;32m--> 245\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    247\u001b[0m     sample \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(sample)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:284\u001b[0m, in \u001b[0;36mdefault_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m accimage_loader(path)\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpil_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datasets\\folder.py:262\u001b[0m, in \u001b[0;36mpil_loader\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpil_loader\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image\u001b[38;5;241m.\u001b[39mImage:\n\u001b[0;32m    261\u001b[0m     \u001b[38;5;66;03m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    263\u001b[0m         img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m    264\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    images = [(img, idx) for idx, (img, label) in enumerate(dataSets[\"Model_1:Test\"].dataset) \n",
    "                if label == 0 and model_1(img.unsqueeze(0).to(DEVICE)).to(\"cpu\").numpy()[0,0] < 0.5]\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for image, pic_index in images:\n",
    "    activation_values = {\"Model_1\":{},\n",
    "                        \"Model_2\":{}}\n",
    "\n",
    "    hooks1, layers1 = register_hooks(model_1, \"Model_1\")\n",
    "    hooks2, layers2 = register_hooks(model_2, \"Model_2\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred1 = model_1(image.unsqueeze(0).to(DEVICE))\n",
    "        pred2 = model_2(image.unsqueeze(0).to(DEVICE))\n",
    "        \n",
    "\n",
    "    df_combined = analyze_positive_activations(\n",
    "        activation_values[\"Model_1\"], \n",
    "        activation_values[\"Model_2\"],\n",
    "        layers1,\n",
    "        layers2,\n",
    "        pic_index,\n",
    "        \"Model_1\",\n",
    "        \"Model_2\",\n",
    "        image,\n",
    "        pred1,\n",
    "        pred2\n",
    "    )\n",
    "\n",
    "    # Add image index as a column\n",
    "    df_combined['image_index'] = pic_index\n",
    "    \n",
    "    # Add to list\n",
    "    all_dfs.append(df_combined)\n",
    "    print(\"pic_index: \", pic_index)\n",
    "\n",
    "    # Remove hooks\n",
    "    for hook in hooks1 + hooks2:\n",
    "        hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined statistics for all images:\n",
      "               layer_name  data_index  count_Model_1  count_Model_2  \\\n",
      "0         features 3-relu         100         100227         110856   \n",
      "1         features 7-relu         100          97621         168206   \n",
      "2        features 11-relu         100           4551          20787   \n",
      "3      classifier 17-relu         100             49             71   \n",
      "4   classifier 20-sigmoid         100              1              1   \n",
      "5         features 3-relu         101         218946         248225   \n",
      "6         features 7-relu         101          85727         159765   \n",
      "7        features 11-relu         101           6032          10318   \n",
      "8      classifier 17-relu         101             59             79   \n",
      "9   classifier 20-sigmoid         101              1              1   \n",
      "10        features 3-relu         102         100963         133453   \n",
      "11        features 7-relu         102         109995         185482   \n",
      "12       features 11-relu         102           3363          15345   \n",
      "13     classifier 17-relu         102             65             72   \n",
      "14  classifier 20-sigmoid         102              1              1   \n",
      "15        features 3-relu         103          95625         109061   \n",
      "16        features 7-relu         103         104676         154122   \n",
      "17       features 11-relu         103           4192          24571   \n",
      "18     classifier 17-relu         103             98             79   \n",
      "19  classifier 20-sigmoid         103              1              1   \n",
      "20        features 3-relu         104         170512         167602   \n",
      "21        features 7-relu         104          57001         193731   \n",
      "22       features 11-relu         104           9320           7176   \n",
      "23     classifier 17-relu         104             29             47   \n",
      "24  classifier 20-sigmoid         104              1              1   \n",
      "25        features 3-relu         105         131016         140520   \n",
      "26        features 7-relu         105          87476         164411   \n",
      "27       features 11-relu         105           8346          13154   \n",
      "28     classifier 17-relu         105             49             59   \n",
      "29  classifier 20-sigmoid         105              1              1   \n",
      "30        features 3-relu         106         135902         194413   \n",
      "31        features 7-relu         106          87171         191543   \n",
      "32       features 11-relu         106           6380           9479   \n",
      "33     classifier 17-relu         106             33             56   \n",
      "34  classifier 20-sigmoid         106              1              1   \n",
      "35        features 3-relu         107          50385          49412   \n",
      "36        features 7-relu         107          85486         178082   \n",
      "37       features 11-relu         107           3738          27610   \n",
      "38     classifier 17-relu         107             71             62   \n",
      "39  classifier 20-sigmoid         107              1              1   \n",
      "40        features 3-relu         108         249858         313024   \n",
      "41        features 7-relu         108          99086         139127   \n",
      "42       features 11-relu         108           3927          17679   \n",
      "43     classifier 17-relu         108             91             46   \n",
      "44  classifier 20-sigmoid         108              1              1   \n",
      "45        features 3-relu         109         151239         166575   \n",
      "46        features 7-relu         109          84113         166302   \n",
      "47       features 11-relu         109           5194          17829   \n",
      "48     classifier 17-relu         109             50             67   \n",
      "49  classifier 20-sigmoid         109              1              1   \n",
      "\n",
      "    total_neurons_Model_1  total_neurons_Model_2  percentage_active_Model_1  \\\n",
      "0                 1605632                1605632                   6.242215   \n",
      "1                  802816                 802816                  12.159822   \n",
      "2                  401408                 401408                   1.133759   \n",
      "3                     512                    512                   9.570312   \n",
      "4                       1                      1                 100.000000   \n",
      "5                 1605632                1605632                  13.636126   \n",
      "6                  802816                 802816                  10.678287   \n",
      "7                  401408                 401408                   1.502710   \n",
      "8                     512                    512                  11.523438   \n",
      "9                       1                      1                 100.000000   \n",
      "10                1605632                1605632                   6.288054   \n",
      "11                 802816                 802816                  13.701147   \n",
      "12                 401408                 401408                   0.837801   \n",
      "13                    512                    512                  12.695312   \n",
      "14                      1                      1                 100.000000   \n",
      "15                1605632                1605632                   5.955599   \n",
      "16                 802816                 802816                  13.038604   \n",
      "17                 401408                 401408                   1.044324   \n",
      "18                    512                    512                  19.140625   \n",
      "19                      1                      1                 100.000000   \n",
      "20                1605632                1605632                  10.619619   \n",
      "21                 802816                 802816                   7.100133   \n",
      "22                 401408                 401408                   2.321827   \n",
      "23                    512                    512                   5.664062   \n",
      "24                      1                      1                 100.000000   \n",
      "25                1605632                1605632                   8.159778   \n",
      "26                 802816                 802816                  10.896146   \n",
      "27                 401408                 401408                   2.079181   \n",
      "28                    512                    512                   9.570312   \n",
      "29                      1                      1                 100.000000   \n",
      "30                1605632                1605632                   8.464081   \n",
      "31                 802816                 802816                  10.858154   \n",
      "32                 401408                 401408                   1.589405   \n",
      "33                    512                    512                   6.445312   \n",
      "34                      1                      1                 100.000000   \n",
      "35                1605632                1605632                   3.138017   \n",
      "36                 802816                 802816                  10.648268   \n",
      "37                 401408                 401408                   0.931222   \n",
      "38                    512                    512                  13.867188   \n",
      "39                      1                      1                 100.000000   \n",
      "40                1605632                1605632                  15.561349   \n",
      "41                 802816                 802816                  12.342305   \n",
      "42                 401408                 401408                   0.978306   \n",
      "43                    512                    512                  17.773438   \n",
      "44                      1                      1                 100.000000   \n",
      "45                1605632                1605632                   9.419282   \n",
      "46                 802816                 802816                  10.477245   \n",
      "47                 401408                 401408                   1.293945   \n",
      "48                    512                    512                   9.765625   \n",
      "49                      1                      1                 100.000000   \n",
      "\n",
      "    percentage_active_Model_2  mean_Model_1  mean_Model_2   sum_Model_1  \\\n",
      "0                    6.904197      0.076936      0.063825   7711.104980   \n",
      "1                   20.951999      0.041509      0.023537   4052.122559   \n",
      "2                    5.178522      0.065294      0.043157    297.154266   \n",
      "3                   13.867188      0.967488      1.243517     47.406887   \n",
      "4                  100.000000      0.729624      0.900112      0.729624   \n",
      "5                   15.459645      0.084242      0.067308  18444.455078   \n",
      "6                   19.900575      0.094632      0.044334   8112.503906   \n",
      "7                    2.570452      0.100333      0.070009    605.207886   \n",
      "8                   15.429688      2.043582      1.867561    120.571358   \n",
      "9                  100.000000      0.979608      0.988019      0.979608   \n",
      "10                   8.311556      0.079084      0.062081   7984.551270   \n",
      "11                  23.103924      0.048292      0.019727   5311.889648   \n",
      "12                   3.822794      0.060010      0.034336    201.812317   \n",
      "13                  14.062500      0.602101      1.182186     39.136536   \n",
      "14                 100.000000      0.664565      0.952411      0.664565   \n",
      "15                   6.792403      0.111139      0.070520  10627.660156   \n",
      "16                  19.197674      0.056767      0.028876   5942.164062   \n",
      "17                   6.121203      0.105411      0.047052    441.881775   \n",
      "18                  15.429688      1.610653      2.799513    157.843994   \n",
      "19                 100.000000      0.936540      0.999321      0.936540   \n",
      "20                  10.438382      0.097897      0.070241  16692.671875   \n",
      "21                  24.131432      0.077063      0.050775   4392.672363   \n",
      "22                   1.787707      0.079468      0.054446    740.642578   \n",
      "23                   9.179688      1.869498      0.548954     54.215454   \n",
      "24                 100.000000      0.637411      0.674276      0.637411   \n",
      "25                   8.751694      0.123582      0.090091  16191.167969   \n",
      "26                  20.479288      0.078973      0.044161   6908.262207   \n",
      "27                   3.276965      0.168719      0.072822   1408.125366   \n",
      "28                  11.523438      3.098729      1.925741    151.837723   \n",
      "29                 100.000000      0.834430      0.965413      0.834430   \n",
      "30                  12.108192      0.058730      0.050648   7981.461914   \n",
      "31                  23.858892      0.039451      0.036812   3439.002441   \n",
      "32                   2.361438      0.066287      0.045815    422.913391   \n",
      "33                  10.937500      1.058072      0.810752     34.916378   \n",
      "34                 100.000000      0.721769      0.530288      0.721769   \n",
      "35                   3.077417      0.064536      0.038000   3251.666992   \n",
      "36                  22.182169      0.027871      0.015044   2382.539551   \n",
      "37                   6.878288      0.035172      0.032345    131.474182   \n",
      "38                  12.109375      0.405022      1.275887     28.756542   \n",
      "39                 100.000000      0.197445      0.094427      0.197445   \n",
      "40                  19.495376      0.071142      0.060220  17775.412109   \n",
      "41                  17.329874      0.090401      0.032154   8957.474609   \n",
      "42                   4.404247      0.074905      0.043637    294.151245   \n",
      "43                   8.984375      0.937704      0.983232     85.331047   \n",
      "44                 100.000000      0.784842      0.808247      0.784842   \n",
      "45                  10.374420      0.065043      0.053820   9837.032227   \n",
      "46                  20.714834      0.055585      0.024923   4675.384766   \n",
      "47                   4.441616      0.051444      0.039319    267.200745   \n",
      "48                  13.085938      0.807791      1.061621     40.389526   \n",
      "49                 100.000000      0.440319      0.906718      0.440319   \n",
      "\n",
      "     sum_Model_2  max_Model_1  max_Model_2   min_Model_1   min_Model_2  \\\n",
      "0    7075.402344     1.019363     0.943715  1.486580e-06  3.919106e-07   \n",
      "1    3959.036865     0.778687     0.704316  9.367925e-08  4.902585e-08   \n",
      "2     897.100647     1.091150     0.600277  2.709734e-05  5.958530e-06   \n",
      "3      88.289703     3.716904     4.270189  1.440167e-02  4.998005e-02   \n",
      "4       0.900112     0.729624     0.900112  7.296243e-01  9.001120e-01   \n",
      "5   16707.535156     0.903476     0.695969  1.047105e-06  3.616636e-07   \n",
      "6    7083.049316     1.219112     0.792106  5.798486e-07  9.510678e-08   \n",
      "7     722.348938     2.108356     0.884469  1.501775e-05  1.121181e-05   \n",
      "8     147.537338     6.027674     5.598275  1.226306e-01  7.149670e-04   \n",
      "9       0.988019     0.979608     0.988019  9.796077e-01  9.880186e-01   \n",
      "10   8284.830078     1.002445     0.665885  1.744119e-06  8.287349e-08   \n",
      "11   3658.966553     0.796717     0.517239  1.298689e-08  3.837483e-08   \n",
      "12    526.878906     1.163049     0.549088  9.765414e-06  8.170263e-08   \n",
      "13     85.117416     1.988674     3.123100  2.777241e-03  4.245397e-02   \n",
      "14      0.952411     0.664565     0.952411  6.645654e-01  9.524108e-01   \n",
      "15   7691.027344     1.053969     1.004584  2.380604e-07  1.486981e-07   \n",
      "16   4450.490234     1.250802     0.953843  5.462038e-07  1.677394e-07   \n",
      "17   1156.117432     2.949023     1.028466  5.884406e-05  3.711289e-06   \n",
      "18    221.161545     5.629078     6.134467  1.463415e-02  7.463340e-04   \n",
      "19      0.999321     0.936540     0.999321  9.365398e-01  9.993207e-01   \n",
      "20  11772.551758     1.013711     0.921725  6.933020e-07  3.964818e-07   \n",
      "21   9836.777344     1.391197     0.691086  7.166542e-10  1.149146e-07   \n",
      "22    390.704956     1.407145     0.769000  2.209000e-06  4.049838e-06   \n",
      "23     25.800838     5.633400     1.826810  1.823378e-01  1.850544e-03   \n",
      "24      0.674276     0.637411     0.674276  6.374106e-01  6.742756e-01   \n",
      "25  12659.595703     1.004473     0.807227  6.100136e-07  1.487464e-07   \n",
      "26   7260.484375     1.577503     0.975777  1.005959e-07  6.100408e-08   \n",
      "27    957.895508     1.804072     0.836477  6.288868e-06  2.147294e-06   \n",
      "28    113.618706    11.604504     5.162684  2.557101e-03  1.644208e-02   \n",
      "29      0.965413     0.834430     0.965413  8.344303e-01  9.654133e-01   \n",
      "30   9846.599609     0.782911     0.692615  3.922360e-07  6.386007e-07   \n",
      "31   7051.161621     0.976333     0.785093  2.632367e-07  5.552059e-08   \n",
      "32    434.280640     0.921561     0.626158  5.546309e-06  2.342553e-06   \n",
      "33     45.402126     2.891368     2.609561  9.894374e-03  3.637511e-02   \n",
      "34      0.530288     0.721769     0.530288  7.217687e-01  5.302878e-01   \n",
      "35   1877.669312     0.740726     0.634449  1.622829e-06  2.647976e-07   \n",
      "36   2679.049316     0.374680     0.414587  8.080461e-07  2.680014e-07   \n",
      "37    893.045776     0.632648     0.499656  6.358516e-06  1.824831e-05   \n",
      "38     79.104973     1.407875     4.778841  5.692139e-03  3.760485e-03   \n",
      "39      0.094427     0.197445     0.094427  1.974449e-01  9.442662e-02   \n",
      "40  18850.435547     0.747718     0.678673  3.642846e-07  4.304136e-08   \n",
      "41   4473.524414     0.888314     0.594695  1.078788e-07  5.923086e-07   \n",
      "42    771.452148     1.152880     0.615909  5.332875e-05  2.291981e-08   \n",
      "43     45.228676     3.605908     2.811920  6.980717e-03  6.657050e-03   \n",
      "44      0.808247     0.784842     0.808247  7.848417e-01  8.082474e-01   \n",
      "45   8965.142578     1.040610     0.703789  1.398395e-06  3.681808e-08   \n",
      "46   4144.723633     0.888998     0.613169  1.949062e-07  6.417989e-07   \n",
      "47    701.011841     1.677525     0.630315  1.735326e-05  8.662261e-07   \n",
      "48     71.128624     4.035129     4.362031  1.768898e-03  1.011407e-02   \n",
      "49      0.906718     0.440319     0.906718  4.403185e-01  9.067183e-01   \n",
      "\n",
      "    image_index  \n",
      "0           100  \n",
      "1           100  \n",
      "2           100  \n",
      "3           100  \n",
      "4           100  \n",
      "5           101  \n",
      "6           101  \n",
      "7           101  \n",
      "8           101  \n",
      "9           101  \n",
      "10          102  \n",
      "11          102  \n",
      "12          102  \n",
      "13          102  \n",
      "14          102  \n",
      "15          103  \n",
      "16          103  \n",
      "17          103  \n",
      "18          103  \n",
      "19          103  \n",
      "20          104  \n",
      "21          104  \n",
      "22          104  \n",
      "23          104  \n",
      "24          104  \n",
      "25          105  \n",
      "26          105  \n",
      "27          105  \n",
      "28          105  \n",
      "29          105  \n",
      "30          106  \n",
      "31          106  \n",
      "32          106  \n",
      "33          106  \n",
      "34          106  \n",
      "35          107  \n",
      "36          107  \n",
      "37          107  \n",
      "38          107  \n",
      "39          107  \n",
      "40          108  \n",
      "41          108  \n",
      "42          108  \n",
      "43          108  \n",
      "44          108  \n",
      "45          109  \n",
      "46          109  \n",
      "47          109  \n",
      "48          109  \n",
      "49          109  \n"
     ]
    }
   ],
   "source": [
    "# Concatenate all DataFrames \n",
    "combined_df = pd.concat(all_dfs, axis=0)\n",
    "\n",
    "# Reset index to include both layer name and image index\n",
    "combined_df = combined_df.reset_index()\n",
    "combined_df = combined_df.rename(columns={'index': 'layer_name'})\n",
    "\n",
    "combined_df.to_csv('model_comparison_stats.csv', index=False)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
