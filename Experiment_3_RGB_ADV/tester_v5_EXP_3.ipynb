{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from adjustText import adjust_text\n",
    "import random\n",
    "import os\n",
    "from model_structure import get_preprocessing_transforms,BCNN, train_model, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get transforms\n",
    "train_transform, val_transform = get_preprocessing_transforms(INPUT_SIZE)\n",
    "\n",
    "test_data_1_dir = 'data4model_1/test/'\n",
    "test_data_2_dir = 'data4model_2/test/'\n",
    "train_data_1_dir = 'data4model_1/train/'\n",
    "train_data_2_dir = 'data4model_2/train/'\n",
    "\n",
    "# Load data set\n",
    "dataset_test_1 = datasets.ImageFolder(test_data_1_dir,transform=val_transform)\n",
    "dataset_train_1 = datasets.ImageFolder(train_data_1_dir,transform=val_transform)\n",
    "dataset_test_2 = datasets.ImageFolder(test_data_2_dir,transform=val_transform)\n",
    "dataset_train_2 = datasets.ImageFolder(train_data_2_dir,transform=val_transform)\n",
    "additional_set = datasets.ImageFolder('data4model_1/for_extra_test/',transform=val_transform)\n",
    "\n",
    "\n",
    "\n",
    "additional_loader = DataLoader(additional_set, shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_loader_1 = DataLoader(dataset_test_1, shuffle=False, batch_size=BATCH_SIZE)\n",
    "train_loader_1 = DataLoader(dataset_train_1, shuffle=False, batch_size=BATCH_SIZE)\n",
    "test_loader_2 = DataLoader(dataset_test_2, shuffle=False, batch_size=BATCH_SIZE)\n",
    "train_loader_2 = DataLoader(dataset_train_2, shuffle=False, batch_size=BATCH_SIZE)\n",
    "\n",
    "dataSets =  {\"Model_1:Train\": train_loader_1,\n",
    "        \"Model_1:Test\": test_loader_1,\n",
    "        \"Model_2:Train\": train_loader_2,\n",
    "        \"Model_2:Test\": test_loader_2,\n",
    "        \"Model_1:additional_set\": additional_loader\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_dir = 'best_model_1.pth'\n",
    "model_2_dir = 'best_model_2.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hskay\\AppData\\Local\\Temp\\ipykernel_18232\\1438434258.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_1_dir, map_location=torch.device(DEVICE))\n",
      "C:\\Users\\hskay\\AppData\\Local\\Temp\\ipykernel_18232\\1438434258.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  weights = torch.load(model_2_dir, map_location=torch.device(DEVICE))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BCNN(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Dropout2d(p=0.25, inplace=False)\n",
       "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout2d(p=0.25, inplace=False)\n",
       "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (11): Dropout2d(p=0.25, inplace=False)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=100352, out_features=512, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model\n",
    "model_1 = BCNN().to(DEVICE)\n",
    "weights = torch.load(model_1_dir, map_location=torch.device(DEVICE))\n",
    "model_1.load_state_dict(weights)\n",
    "model_1.eval()\n",
    "\n",
    "model_2 = BCNN().to(DEVICE)\n",
    "weights = torch.load(model_2_dir, map_location=torch.device(DEVICE))\n",
    "model_2.load_state_dict(weights)\n",
    "model_2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model_1:Train\n",
      "Accuracy:  0.9283333333333333\n",
      "F1 Score:  0.9271926854046733\n",
      "confusion Matrix: \n",
      " [[1416   84]\n",
      " [ 131 1369]]\n",
      "\n",
      "\n",
      "Model_1:Test\n",
      "Accuracy:  0.87\n",
      "F1 Score:  0.8617021276595744\n",
      "confusion Matrix: \n",
      " [[93  7]\n",
      " [19 81]]\n",
      "\n",
      "\n",
      "Model_2:Train\n",
      "Accuracy:  0.9436666666666667\n",
      "F1 Score:  0.9452188006482982\n",
      "confusion Matrix: \n",
      " [[1373  127]\n",
      " [  42 1458]]\n",
      "\n",
      "\n",
      "Model_2:Test\n",
      "Accuracy:  0.89\n",
      "F1 Score:  0.8981481481481481\n",
      "confusion Matrix: \n",
      " [[81 19]\n",
      " [ 3 97]]\n",
      "\n",
      "\n",
      "Model_1:additional_set\n"
     ]
    }
   ],
   "source": [
    "for key in dataSets:\n",
    "    print(key)\n",
    "    if \"Model_1\" in key:\n",
    "        model = model_1\n",
    "    else:\n",
    "        model = model_2\n",
    "    \n",
    "    results = evaluate_model(model.to(DEVICE), dataSets[key], DEVICE)\n",
    "    print(\"Accuracy: \", results[0])\n",
    "    print(\"F1 Score: \", results[1])\n",
    "    print(\"confusion Matrix: \\n\",results[3])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_ROUND = 50  # Number of rounds to monitor\n",
    "activation_values = {\"Model_1\":{},\n",
    "                     \"Model_2\":{}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_hooks(model,model_name):\n",
    "    hooks = []\n",
    "    layer_info = {}\n",
    "    counter = 0\n",
    "\n",
    "    last_linear_name = None\n",
    "    for name, layer in model.named_modules():\n",
    "        if isinstance(layer, nn.Linear):\n",
    "            last_linear_name = name\n",
    "    \n",
    "    global last_layer_name\n",
    "    last_layer_name = last_linear_name\n",
    "\n",
    "    for name, layer in model.named_modules():\n",
    "        #if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
    "            # Register hook for the full layer output\n",
    "            #hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            \n",
    "            if isinstance(layer, nn.Linear):\n",
    "                layer_info[name] = {'type': f'{counter:02}-linear',}\n",
    "                if name == last_linear_name:\n",
    "                    layer_info[f\"{name}_softmax\"] = {'type': f'{counter:02}-softmax'}\n",
    "                hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            elif isinstance(layer, nn.Conv2d):\n",
    "                layer_info[name] = {'type': f'{counter:02}-conv'}\n",
    "                hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            # elif isinstance(layer, nn.ReLU):\n",
    "            #      layer_info[name] = {'type': f'{counter:02}-relu'}\n",
    "            #      hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "            elif isinstance(layer, nn.MaxPool2d):\n",
    "                 hooks.append(layer.register_forward_hook(get_activation(name,model_name)))\n",
    "                 layer_info[name] = {'type': f'{counter:02}-maxpool'}\n",
    "            # elif isinstance(layer, nn.Dropout):\n",
    "            #     layer_info[name] = {'type': f'{counter}-dropout'}\n",
    "            elif isinstance(layer, nn.Flatten):\n",
    "                 layer_info[name] = {'type': f'{counter}-flatten'}\n",
    "            # elif isinstance(layer, nn.BatchNorm2d):\n",
    "            #     layer_info[name] = {'type': f'{counter}-batchnorm'}\n",
    "            # elif isinstance(layer, nn.AdaptiveAvgPool2d):\n",
    "            #     layer_info[name] = {'type': f'{counter}-adaptiveavgpool'}\n",
    "            # elif isinstance(layer, nn.Softmax):\n",
    "            #     layer_info[name] = {'type': f'{counter}-softmax'}\n",
    "            # else:\n",
    "            #     layer_info[name] = {'type': f'{counter}-other'}\n",
    "            counter += 1\n",
    "\n",
    "    return hooks, layer_info\n",
    "\n",
    "def get_activation(name, model_name):\n",
    "    def hook(module, input, output):\n",
    "        output_relu = torch.nn.functional.relu(output)\n",
    "        if name == last_layer_name:\n",
    "            activation_values[model_name][name] = {\n",
    "                'output': output_relu.detach(),\n",
    "                'input': input[0].detach(),  # Capturing input\n",
    "                'weight': module.weight.detach() if hasattr(module, 'weight') else None\n",
    "            }\n",
    "            activation_values[model_name][f\"{name}_softmax\"] = torch.nn.functional.softmax(output_relu.detach(), dim=1)\n",
    "        else:\n",
    "            activation_values[model_name][name] = {\n",
    "                'output': output_relu.detach(),\n",
    "                'input': input[0].detach(),  # Capturing input\n",
    "                'weight': module.weight.detach() if hasattr(module, 'weight') else None\n",
    "            }\n",
    "    return hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_random_neuron_indices(activations, layer_info, n_neurons=1):\n",
    "    indices = {}\n",
    "    all_activated_indices = {}\n",
    "    previous_layer_contributions = {}\n",
    "    \n",
    "    # sorted_layers = sorted(layer_info.keys())\n",
    "    \n",
    "    for layer_name in layer_info:\n",
    "        # WILL DELETE\n",
    "        if layer_name not in activations:\n",
    "            continue\n",
    "            \n",
    "        layer_data = activations[layer_name]\n",
    "        if isinstance(layer_data, dict): \n",
    "            activation = layer_data['output']\n",
    "            input_data = layer_data['input']\n",
    "            weights = layer_data['weight']\n",
    "            \n",
    "        # original shape\n",
    "        original_shape = activation.shape\n",
    "        \n",
    "        flattened = activation.view(activation.shape[0], -1)\n",
    "        positive_indices = np.where(flattened.cpu().numpy().squeeze() > 0)[0]\n",
    "        \n",
    "        # all activated indices/inputs whatever it is  for this layer\n",
    "        all_activated_indices[layer_name] = positive_indices\n",
    "        \n",
    "\n",
    "        # debug\n",
    "        if len(positive_indices) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Select random neurons from activated ones\n",
    "        selected_indices = np.random.choice(\n",
    "            positive_indices,\n",
    "            size=min(n_neurons, len(positive_indices)), # good to think about this\n",
    "            replace=False # no replace\n",
    "        )\n",
    "        \n",
    "        # calculate contributions from previous layer if weights exist eleminate sacma salak seyler\n",
    "        if weights is not None and input_data is not None:\n",
    "            contributions = {}\n",
    "            for selected_idx in selected_indices:\n",
    "                # For convolutional layers ([B, 32, 224, 224])\n",
    "                if len(weights.shape) == 4:  \n",
    "                    # converting flattened index back to feature map coordinates\n",
    "                    if len(original_shape) == 4:  # batch, channels, height, width\n",
    "                        batch_size, channels, height, width = original_shape\n",
    "\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        channel = selected_idx // (height * width)\n",
    "                        pos_in_channel = selected_idx % (height * width)\n",
    "                        h_idx = pos_in_channel // width\n",
    "                        w_idx = pos_in_channel % width\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        \n",
    "                        # besure channel is within bounds\n",
    "                        if channel >= weights.shape[0]:\n",
    "                            continue\n",
    "                        \n",
    "                        # Get weights for this output channel\n",
    "                        channel_weights = weights[channel]\n",
    "                        \n",
    "                        # simplified calculate contribution\n",
    "                        contribution = torch.tensor(0.0)\n",
    "                        if input_data.shape[2] > h_idx and input_data.shape[3] > w_idx:\n",
    "                            contribution = input_data[0, :, h_idx, w_idx].sum() * channel_weights.sum()\n",
    "                    else:\n",
    "                        # skiped if shape doesnt match expectations\n",
    "                        #print(f\"Skipping layer {layer_name} due to unexpected shape: {original_shape}\")\n",
    "                        continue\n",
    "                        \n",
    "                # for linear layers\n",
    "                else:  \n",
    "                    # for linear layers, the flattened index needs to be mapped to output dimension\n",
    "                    output_dim = weights.shape[0]\n",
    "                    if selected_idx >= output_dim: # its random operation is wron\n",
    "                        # Skip if index is out of bounds\n",
    "                        #print(f\"Skipping layer {layer_name} due to out of bounds index: {selected_idx}\")\n",
    "                        continue\n",
    "                        \n",
    "                    neuron_weights = weights[selected_idx]\n",
    "                    contribution = (input_data * neuron_weights).sum()\n",
    "                \n",
    "                contributions[int(selected_idx)] = {\n",
    "                    'weights': weights[min(selected_idx, weights.shape[0]-1)].cpu().numpy(),\n",
    "                    'input_values': input_data.cpu().numpy(),\n",
    "                    'contribution': contribution.item() if isinstance(contribution, torch.Tensor) else contribution\n",
    "                }\n",
    "            \n",
    "            previous_layer_contributions[layer_name] = contributions\n",
    "        \n",
    "        indices[layer_name] = {\n",
    "            'neuron_idx': selected_indices,\n",
    "            'type': layer_info[layer_name]['type'],\n",
    "            'all_activated_indices': positive_indices,\n",
    "            'contributions': previous_layer_contributions.get(layer_name, None)\n",
    "        }\n",
    "    \n",
    "    return indices, all_activated_indices, previous_layer_contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_model_activations(activation_values_1, activation_values_2, indices1, indices2, layers1, layers2):\n",
    "    comparison_results = {}\n",
    "    \n",
    "    # Get the layer names from Model_1\n",
    "    for layer_name in layers1:\n",
    "        if layer_name not in activation_values_1 or layer_name not in activation_values_2:\n",
    "            continue\n",
    "            \n",
    "        data1 = activation_values_1[layer_name]\n",
    "        data2 = activation_values_2[layer_name]\n",
    "        \n",
    "        if not isinstance(data1, dict) or not isinstance(data2, dict):\n",
    "            continue\n",
    "            \n",
    "        input1 = data1['input']\n",
    "        weights2 = data2['weight']\n",
    "        #print(weights2)\n",
    "        #print(layer_name)\n",
    "        #print(type(weights2))\n",
    "        bias2 = data2.get('bias', None) #FOR SOFTMAX\n",
    "        output1 = data1['output']\n",
    "        \n",
    "        # Get selected neuron indices\n",
    "        if layer_name in indices1[0]:\n",
    "            selected_indices = indices1[0][layer_name]['neuron_idx']\n",
    "        else:\n",
    "            #print(\"Skipping layer\", layer_name)\n",
    "            continue\n",
    "            \n",
    "        # results for this layer\n",
    "        layer_results = {\n",
    "            'neuron_comparisons': [],\n",
    "            'mean_difference': 0.0,\n",
    "            'max_difference': 0.0,\n",
    "            'min_difference': float('inf')\n",
    "        }\n",
    "        \n",
    "        # Compare selected neurons\n",
    "        for idx in selected_indices:\n",
    "            if weights2 is not None:\n",
    "                # CONV\n",
    "                if len(weights2.shape) == 4:  # Convolutional layer\n",
    "                    \n",
    "                    batch_size, channels, height, width = output1.shape\n",
    "                    channel = idx // (height*width)\n",
    "                    pos_in_channel = idx%(height * width)\n",
    "                    h_idx = pos_in_channel//width\n",
    "                    w_idx = pos_in_channel%width\n",
    "                    \n",
    "                    if channel >= weights2.shape[0]:\n",
    "                        #print(f\"Skipping layer {layer_name} due to out of bounds channel: {channel}\")\n",
    "                        continue\n",
    "                        \n",
    "                    # Get actual activation from Model_1\n",
    "                    actual_activation = output1[0, channel, h_idx, w_idx].item()\n",
    "                    \n",
    "                    kernel_size = weights2.shape[2]\n",
    "                    padding = kernel_size // 2 \n",
    "                    \n",
    "                                            # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                    # Extract input patch\n",
    "                    in_h_start = max(0, h_idx - padding)\n",
    "                    in_w_start = max(0, w_idx - padding)\n",
    "                    in_h_end = min(input1.shape[2],h_idx+kernel_size-padding)\n",
    "                    in_w_end = min(input1.shape[3],w_idx+kernel_size-padding)\n",
    "                                            # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                                                # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                        # DONT TOUCH THIS PART\n",
    "                    input_patch = input1[0, :, in_h_start:in_h_end, in_w_start:in_w_end]\n",
    "                    weight_patch = weights2[channel]\n",
    "                    \n",
    "                    # Adjust weight patch size if needed\n",
    "                    if input_patch.shape != weight_patch.shape[1:]:\n",
    "                        bad_model_activation = torch.tensor(0.0)\n",
    "                    else:\n",
    "                        bad_model_activation = (input_patch * weight_patch).sum()\n",
    "                    \n",
    "                    # Add bias if exist\n",
    "                    if bias2 is not None:\n",
    "                        bad_model_activation += bias2[channel]\n",
    "                    \n",
    "                    # apply ReLU for any case\n",
    "                    if actual_activation > 0:\n",
    "                        bad_model_activation = max(0, bad_model_activation)\n",
    "                    \n",
    "                else:  # Linear layer\n",
    "                    #if index is out of bounds\n",
    "                    if idx >= weights2.shape[0]:\n",
    "                        continue\n",
    "                        \n",
    "                    # Get actual activation from Model_1 (flattened)\n",
    "                    flattened_output = output1.view(output1.shape[0], -1)\n",
    "                    actual_activation = flattened_output[0, idx].item()\n",
    "                    \n",
    "                    # Calculate expected activation using Model_2 weights\n",
    "                    neuron_weights = weights2[idx]\n",
    "                    bad_model_activation = (input1.flatten(start_dim=1) * neuron_weights).sum()\n",
    "                    \n",
    "                    # Add bias if available\n",
    "                    if bias2 is not None:\n",
    "                        bad_model_activation += bias2[idx]\n",
    "                    \n",
    "                    if actual_activation > 0:\n",
    "                        bad_model_activation = max(0, bad_model_activation)\n",
    "                \n",
    "                #converting to scalar if it is a tensor\n",
    "                if isinstance(bad_model_activation, torch.Tensor):\n",
    "                    bad_model_activation = bad_model_activation.item()\n",
    "                    \n",
    "                #calculate difference\n",
    "                difference = abs(actual_activation - bad_model_activation)\n",
    "                \n",
    "                #comparison for this neuron\n",
    "                neuron_comparison = {\n",
    "                    'neuron_idx': int(idx),\n",
    "                    'actual_activation': actual_activation,\n",
    "                    'bad_model_activation': bad_model_activation,\n",
    "                    'difference': difference,\n",
    "                    'percen_diff': (difference / (abs(actual_activation) + 1e-10)) * 100\n",
    "                }\n",
    "                \n",
    "                layer_results['neuron_comparisons'].append(neuron_comparison)\n",
    "                \n",
    "                #statistics\n",
    "                layer_results['mean_difference'] += difference\n",
    "                layer_results['max_difference'] = max(layer_results['max_difference'], difference)\n",
    "                layer_results['min_difference'] = min(layer_results['min_difference'], difference)\n",
    "            \n",
    "            #average difference\n",
    "            if len(layer_results['neuron_comparisons']) > 0:\n",
    "                layer_results['mean_difference'] /= len(layer_results['neuron_comparisons'])\n",
    "            else:\n",
    "                layer_results['mean_difference'] = float('nan')\n",
    "                layer_results['min_difference'] = float('nan')\n",
    "            \n",
    "            comparison_results[layer_name] = layer_results\n",
    "    return comparison_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_comparison_results_to_csv(comparison_results, input_id, round_id, filename=\"model_comparison_results.csv\"):\n",
    "    rows = []\n",
    "    for layer_name, layer_data in comparison_results.items():\n",
    "        mean_diff = layer_data['mean_difference']\n",
    "        max_diff = layer_data['max_difference']\n",
    "        min_diff = layer_data['min_difference']\n",
    "    \n",
    "        if np.isnan(mean_diff):\n",
    "            mean_diff = \"N/A\"\n",
    "        if np.isnan(min_diff):\n",
    "            min_diff = \"N/A\"\n",
    "    \n",
    "        if layer_data['neuron_comparisons']:\n",
    "            for neuron_data in layer_data['neuron_comparisons']:\n",
    "                row = {\n",
    "                    'input_id': input_id,\n",
    "                    'round_id': round_id,\n",
    "                    'layer_name': layer_name,\n",
    "                    'neuron_idx': neuron_data['neuron_idx'],\n",
    "                    'actual_activation': neuron_data['actual_activation'],\n",
    "                    'bad_model_activation': neuron_data['bad_model_activation'],\n",
    "                    'difference': neuron_data['difference'],\n",
    "                    'percent_difference': neuron_data['percen_diff'],\n",
    "                    'layer_mean_difference': mean_diff,\n",
    "                    'layer_max_difference': max_diff,\n",
    "                    'layer_min_difference': min_diff\n",
    "                }\n",
    "                rows.append(row)\n",
    "        else:\n",
    "            row = {\n",
    "                'input_id': input_id,\n",
    "                'round_id': round_id,\n",
    "                'layer_name': layer_name,\n",
    "                'neuron_idx': \"N/A\",\n",
    "                'actual_activation': \"N/A\",\n",
    "                'bad_model_activation': \"N/A\",\n",
    "                'difference': \"N/A\",\n",
    "                'percent_difference': \"N/A\",\n",
    "                'layer_mean_difference': mean_diff,\n",
    "                'layer_max_difference': max_diff,\n",
    "                'layer_min_difference': min_diff\n",
    "            }\n",
    "            rows.append(row)\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    file_exists = os.path.isfile(filename)\n",
    "    \n",
    "    if file_exists:\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "        #print(f\"Results appended to {filename}\")\n",
    "    else:\n",
    "        df.to_csv(filename, index=False)\n",
    "        #print(f\"Results saved to new file {filename}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = {\n",
    "    0: 'cat',\n",
    "    1: 'dog'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_class = 1 # 0 cat or squirrel, 1 dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation_values = {\"Model_1\":{},\n",
    "#                     \"Model_2\":{}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images = [(img, idx) for idx, (img, label) in enumerate(dataSets[\"Model_1:Test\"].dataset) \n",
    "#             if label == 0][:15]\n",
    "# image = images[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1.0438e-01,  1.9694e-01,  4.6683e-02],\n",
      "          [ 1.4248e-01, -7.4677e-02,  2.9127e-02],\n",
      "          [-1.5066e-01, -7.6323e-02, -1.4803e-01]],\n",
      "\n",
      "         [[ 5.3139e-02,  1.8019e-02,  1.9684e-02],\n",
      "          [ 7.0723e-02, -2.1554e-01, -1.9714e-01],\n",
      "          [-1.7370e-01,  3.0297e-02, -2.4181e-01]],\n",
      "\n",
      "         [[ 1.3528e-01,  8.8570e-02,  1.8613e-01],\n",
      "          [-9.1233e-02, -1.1921e-01, -1.2085e-01],\n",
      "          [-8.4497e-02, -2.7555e-02, -6.5062e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.5765e-01,  8.4153e-02, -4.2445e-02],\n",
      "          [ 6.4696e-02,  6.7702e-02, -2.8961e-03],\n",
      "          [-6.4010e-02,  1.6071e-01,  9.5482e-02]],\n",
      "\n",
      "         [[ 3.4415e-02, -5.0169e-02,  1.4346e-01],\n",
      "          [ 8.7364e-02, -1.1939e-01, -2.0954e-01],\n",
      "          [ 1.8741e-01,  1.5890e-01, -1.8179e-01]],\n",
      "\n",
      "         [[-2.5901e-01, -1.4860e-01,  4.0433e-02],\n",
      "          [-2.2548e-01,  8.2531e-03,  1.7558e-02],\n",
      "          [-3.1579e-02,  1.1798e-02, -2.7838e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.9100e-01,  1.9106e-01, -1.3767e-01],\n",
      "          [ 1.4266e-01,  1.3289e-01,  7.5349e-02],\n",
      "          [-1.5234e-01,  1.2171e-01, -2.1975e-01]],\n",
      "\n",
      "         [[ 1.5141e-01,  1.8496e-01,  1.2278e-01],\n",
      "          [ 4.7752e-02, -9.6147e-02, -1.3011e-01],\n",
      "          [-2.2743e-01,  1.0591e-01, -1.9172e-02]],\n",
      "\n",
      "         [[-1.2984e-01, -9.2896e-02, -1.3991e-01],\n",
      "          [ 7.6408e-02,  9.2820e-02,  5.0890e-02],\n",
      "          [-2.0956e-01, -4.2876e-03,  4.2721e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9305e-02, -6.4862e-02, -1.6914e-01],\n",
      "          [-1.4790e-01, -1.4675e-01, -2.2389e-01],\n",
      "          [-6.0993e-02,  1.9704e-01,  9.9182e-02]],\n",
      "\n",
      "         [[-4.7774e-02, -4.2448e-03,  1.9855e-01],\n",
      "          [ 7.1050e-02,  5.1060e-02, -1.3099e-01],\n",
      "          [-4.1073e-02,  2.3154e-01,  2.0674e-01]],\n",
      "\n",
      "         [[-3.4148e-02, -2.0260e-01, -9.5504e-02],\n",
      "          [ 1.2850e-01,  1.3051e-01, -2.0509e-01],\n",
      "          [ 1.9288e-01, -7.8926e-02, -2.9832e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5546e-02, -2.7698e-02, -1.1807e-01],\n",
      "          [ 1.4384e-02, -1.9122e-01,  1.0554e-01],\n",
      "          [-5.2728e-02, -2.2218e-01, -1.7141e-01]],\n",
      "\n",
      "         [[ 7.8763e-02,  1.1414e-01, -5.9028e-02],\n",
      "          [ 7.3085e-02,  1.6275e-01,  1.9663e-01],\n",
      "          [-9.0055e-02, -7.4322e-02,  1.0467e-01]],\n",
      "\n",
      "         [[-1.5822e-01,  2.7054e-02,  5.8996e-03],\n",
      "          [ 7.8778e-02,  7.1150e-04, -2.2454e-02],\n",
      "          [ 2.6908e-02, -8.9147e-02,  1.4644e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3060e-01, -1.0188e-01, -7.6997e-02],\n",
      "          [-7.6458e-02, -1.4412e-02,  2.6765e-02],\n",
      "          [-7.1447e-02, -2.8158e-01, -9.7772e-02]],\n",
      "\n",
      "         [[ 1.1557e-01, -1.2384e-01, -1.6320e-01],\n",
      "          [ 3.8039e-02,  5.0422e-02,  8.3142e-02],\n",
      "          [-2.0601e-01,  1.4193e-01, -1.0354e-01]],\n",
      "\n",
      "         [[-1.4798e-01,  1.4173e-01, -3.0839e-02],\n",
      "          [ 1.8061e-01,  7.8407e-02, -5.1607e-02],\n",
      "          [ 3.0537e-02,  8.2259e-02, -8.6039e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1333e-01, -2.3620e-02, -1.2076e-01],\n",
      "          [ 7.9370e-02, -2.8714e-02,  9.6781e-03],\n",
      "          [ 8.6023e-02, -1.0523e-01, -6.0294e-02]],\n",
      "\n",
      "         [[-6.1437e-02,  6.2934e-02, -1.5328e-01],\n",
      "          [ 3.8130e-02,  1.1188e-01, -1.1023e-01],\n",
      "          [-9.1355e-02, -1.5040e-01, -3.3521e-02]],\n",
      "\n",
      "         [[-8.4302e-02, -1.1549e-01, -2.2912e-02],\n",
      "          [-9.8587e-02,  9.3227e-02, -1.5668e-01],\n",
      "          [ 1.5700e-01,  7.3338e-02, -1.2588e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1023e-01,  1.8929e-01, -1.4904e-01],\n",
      "          [ 1.3863e-01,  2.5693e-01, -1.8640e-01],\n",
      "          [-6.0371e-02,  8.5932e-02, -1.7942e-01]],\n",
      "\n",
      "         [[-2.3425e-01, -1.6409e-01, -1.7511e-01],\n",
      "          [-2.5484e-01, -5.1571e-02,  1.2710e-01],\n",
      "          [ 5.7639e-02, -2.0732e-01, -1.5186e-01]],\n",
      "\n",
      "         [[ 1.0339e-01, -4.0288e-02, -8.9280e-03],\n",
      "          [ 5.5296e-02, -1.1246e-01,  1.8891e-01],\n",
      "          [-4.5274e-02,  6.9995e-02, -8.8860e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.2820e-02, -2.3915e-01,  1.4004e-01],\n",
      "          [-2.2193e-01,  1.2579e-01,  2.1509e-01],\n",
      "          [-2.3378e-02, -1.8700e-01,  9.3431e-02]],\n",
      "\n",
      "         [[-1.1991e-01,  2.5811e-02,  2.4165e-01],\n",
      "          [ 9.3810e-02, -5.6078e-02, -7.1910e-02],\n",
      "          [ 4.5342e-02, -8.7176e-02,  9.0977e-02]],\n",
      "\n",
      "         [[-2.3213e-01, -1.1707e-01,  1.4203e-01],\n",
      "          [-1.5595e-01,  9.6682e-02, -2.2834e-02],\n",
      "          [ 7.8558e-02, -1.8038e-01,  1.4773e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4156e-03,  1.2925e-01,  1.4424e-01],\n",
      "          [-1.7746e-01, -4.6194e-02, -2.7104e-03],\n",
      "          [ 4.9148e-03, -1.8162e-01,  1.4133e-01]],\n",
      "\n",
      "         [[-8.6679e-02, -1.4375e-02,  1.2056e-01],\n",
      "          [-2.1062e-01, -1.8903e-01,  1.4179e-01],\n",
      "          [ 1.1526e-01, -7.5199e-02, -3.0980e-02]],\n",
      "\n",
      "         [[-1.9183e-01,  6.6010e-02,  1.8249e-01],\n",
      "          [-2.9846e-02, -2.2233e-01,  2.2354e-01],\n",
      "          [-6.4055e-02, -4.8026e-02,  1.7189e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 5.2796e-02,  3.6023e-02, -1.0176e-01],\n",
      "          [-1.6005e-01, -2.0959e-01,  9.6329e-02],\n",
      "          [-8.6243e-02, -2.5259e-01,  1.0226e-01]],\n",
      "\n",
      "         [[ 1.6043e-01,  1.6044e-01, -4.2514e-02],\n",
      "          [-6.5670e-02, -8.0412e-02, -1.9605e-01],\n",
      "          [-2.3162e-01, -2.0849e-01,  4.3738e-02]],\n",
      "\n",
      "         [[ 1.6552e-01,  1.5463e-01,  1.5011e-01],\n",
      "          [-1.0931e-01,  7.7982e-03, -6.8960e-02],\n",
      "          [-6.2968e-03,  7.1655e-04,  2.5737e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4772e-01,  1.2783e-01, -1.1338e-01],\n",
      "          [-1.6624e-01, -1.4589e-01,  5.9090e-02],\n",
      "          [ 2.0972e-01,  1.6077e-01, -1.7525e-01]],\n",
      "\n",
      "         [[-2.9352e-02, -8.6765e-02, -2.2449e-01],\n",
      "          [ 1.1509e-01,  1.4199e-01, -2.0365e-01],\n",
      "          [-4.8712e-02,  1.2066e-01,  1.0829e-01]],\n",
      "\n",
      "         [[ 1.7039e-01,  9.6684e-02,  4.4639e-02],\n",
      "          [ 1.4282e-01,  3.6705e-02, -1.4250e-01],\n",
      "          [-5.2265e-02, -7.1523e-02,  1.8622e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1790e-02, -6.3219e-02,  1.3445e-01],\n",
      "          [-1.0333e-01, -1.5848e-01, -1.8506e-02],\n",
      "          [-1.2496e-01, -1.2993e-03, -8.7653e-02]],\n",
      "\n",
      "         [[-1.1127e-01,  7.2662e-02,  5.8298e-02],\n",
      "          [ 7.3111e-02, -2.6793e-02,  1.1080e-02],\n",
      "          [-2.4006e-01, -2.1386e-01, -2.3952e-01]],\n",
      "\n",
      "         [[ 9.1153e-02,  9.0755e-03,  2.3053e-02],\n",
      "          [ 8.1353e-03,  5.9266e-02, -1.5382e-02],\n",
      "          [ 4.4452e-02, -6.6874e-02,  1.7818e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5154e-01,  7.7351e-02,  1.6835e-01],\n",
      "          [-1.5126e-01, -1.9526e-01, -1.9348e-01],\n",
      "          [-7.8289e-02,  1.0457e-01,  6.1589e-02]],\n",
      "\n",
      "         [[ 4.6587e-02, -1.3630e-01, -5.6392e-02],\n",
      "          [-2.3075e-01,  6.6262e-02, -1.9454e-01],\n",
      "          [-5.3089e-02, -1.2278e-02, -1.9396e-01]],\n",
      "\n",
      "         [[ 1.7719e-02,  1.2065e-01,  1.4569e-01],\n",
      "          [ 1.4180e-01, -1.3944e-01,  5.0119e-02],\n",
      "          [ 1.1745e-01, -1.1891e-01,  1.3014e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.1542e-01, -1.9247e-01, -9.6675e-02],\n",
      "          [ 6.0397e-02,  9.4372e-02,  1.5120e-01],\n",
      "          [-1.6209e-01,  5.4134e-02,  1.5788e-01]],\n",
      "\n",
      "         [[-9.2831e-02,  7.9203e-02,  5.8631e-02],\n",
      "          [ 1.0492e-01, -1.3562e-01, -1.7478e-01],\n",
      "          [ 7.1141e-03,  7.2389e-02,  1.1502e-01]],\n",
      "\n",
      "         [[ 1.1956e-01, -1.6258e-01, -2.5856e-01],\n",
      "          [ 1.0832e-01, -6.4256e-02, -1.4991e-02],\n",
      "          [ 6.8285e-02,  2.1703e-01,  1.8003e-01]]],\n",
      "\n",
      "\n",
      "        [[[-5.5283e-02, -1.6926e-01, -1.0317e-01],\n",
      "          [ 7.7831e-02, -2.1561e-02, -5.1536e-02],\n",
      "          [-7.6539e-02,  5.8895e-02,  5.9810e-02]],\n",
      "\n",
      "         [[-1.3728e-01, -1.5818e-01,  1.7442e-01],\n",
      "          [ 3.9173e-02,  1.8710e-01,  9.5125e-02],\n",
      "          [-1.1849e-01,  1.6811e-01, -3.0413e-02]],\n",
      "\n",
      "         [[-2.1132e-02,  1.0484e-01,  2.4296e-02],\n",
      "          [ 1.2723e-01, -1.7113e-01, -1.8082e-01],\n",
      "          [-1.3948e-01,  1.3111e-01, -2.1769e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.1842e-02, -1.9718e-01, -1.0844e-01],\n",
      "          [-1.2211e-01, -1.9558e-02,  7.1079e-02],\n",
      "          [ 1.7415e-03, -1.1505e-01,  3.3903e-02]],\n",
      "\n",
      "         [[ 6.8535e-02,  1.4223e-01, -2.0401e-02],\n",
      "          [-2.5153e-01, -6.0467e-02,  1.8472e-01],\n",
      "          [ 3.4498e-02,  1.4327e-01,  9.6259e-02]],\n",
      "\n",
      "         [[ 9.0536e-02, -2.2956e-01,  6.6233e-02],\n",
      "          [-2.0900e-01,  1.1332e-02,  1.0232e-01],\n",
      "          [ 1.5357e-01, -1.2904e-01,  5.4145e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1324e-02, -6.7479e-02, -5.7634e-02],\n",
      "          [-1.9198e-01, -1.2968e-01, -1.2172e-01],\n",
      "          [-1.5278e-01, -1.1321e-01,  9.0192e-02]],\n",
      "\n",
      "         [[ 1.3368e-01, -4.4784e-02, -2.1138e-01],\n",
      "          [-3.1535e-02, -1.2408e-01, -1.1764e-01],\n",
      "          [-6.5811e-02,  8.2739e-03,  1.7067e-01]],\n",
      "\n",
      "         [[ 1.1877e-01, -2.2079e-02, -1.2916e-01],\n",
      "          [-1.3831e-02,  1.6151e-01,  2.1488e-01],\n",
      "          [ 9.6758e-02,  1.7554e-01,  4.1194e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4928e-01, -1.2533e-01, -1.4504e-01],\n",
      "          [-7.9659e-02, -1.1642e-01, -7.3167e-02],\n",
      "          [-1.8208e-01,  1.4049e-01, -1.2482e-01]],\n",
      "\n",
      "         [[-4.7016e-02, -1.5897e-01, -3.6682e-03],\n",
      "          [ 3.1414e-02,  1.0545e-01, -4.2234e-02],\n",
      "          [-1.8298e-01, -2.0980e-01, -1.9655e-03]],\n",
      "\n",
      "         [[ 1.4280e-01,  5.4267e-03,  1.7784e-01],\n",
      "          [-6.9393e-02, -9.4920e-03, -1.4768e-02],\n",
      "          [ 1.6253e-01,  7.2177e-02,  1.1995e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3481e-01, -1.8874e-01,  9.4379e-02],\n",
      "          [-1.4363e-01,  1.3534e-01, -4.4064e-02],\n",
      "          [ 4.2219e-02, -1.8377e-01,  2.1443e-01]],\n",
      "\n",
      "         [[-1.8882e-01, -2.4090e-01,  6.3845e-02],\n",
      "          [-8.3429e-02, -1.7351e-01,  2.0702e-01],\n",
      "          [-1.3376e-01, -1.1515e-01,  1.5518e-01]],\n",
      "\n",
      "         [[ 4.2934e-02, -7.8584e-02,  9.9448e-02],\n",
      "          [-1.0228e-01,  1.2947e-01,  1.5847e-01],\n",
      "          [-1.0674e-01, -2.4277e-02,  8.0583e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.4521e-02, -1.7712e-01, -1.5083e-01],\n",
      "          [ 5.3357e-02, -1.4786e-01, -7.5994e-02],\n",
      "          [-2.6705e-01,  5.4451e-02, -2.5010e-01]],\n",
      "\n",
      "         [[-2.6520e-01,  3.7137e-02, -8.5661e-02],\n",
      "          [ 8.5250e-02,  1.1926e-02, -1.3810e-01],\n",
      "          [ 8.7952e-02, -3.3916e-02,  1.6041e-01]],\n",
      "\n",
      "         [[ 7.4629e-02, -6.2909e-02, -8.0492e-02],\n",
      "          [-9.8636e-02,  2.5819e-01,  1.7252e-01],\n",
      "          [ 4.6664e-03, -2.6958e-02, -5.1861e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6224e-01, -1.4282e-01, -1.8422e-03],\n",
      "          [ 7.2916e-02, -1.5139e-01, -5.1767e-02],\n",
      "          [ 2.0732e-01,  2.1413e-01, -9.5464e-02]],\n",
      "\n",
      "         [[-1.2864e-01, -7.2929e-02, -2.2092e-01],\n",
      "          [-4.2888e-02, -1.5232e-03, -1.2040e-01],\n",
      "          [ 2.2786e-01,  2.3119e-01,  5.4154e-02]],\n",
      "\n",
      "         [[ 7.7123e-02, -3.6009e-02,  9.6349e-02],\n",
      "          [-1.9607e-02,  3.9520e-02, -6.5814e-02],\n",
      "          [ 6.7497e-02, -3.6257e-02,  1.5418e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.5776e-02, -1.5664e-01, -1.9510e-01],\n",
      "          [-1.1230e-01,  1.9880e-01, -8.9192e-02],\n",
      "          [-7.1231e-02,  2.4150e-01,  1.9286e-01]],\n",
      "\n",
      "         [[ 2.1028e-01, -1.4448e-01, -3.3351e-02],\n",
      "          [-1.2811e-01, -1.5632e-01, -2.8758e-02],\n",
      "          [-7.4471e-02,  9.1824e-02,  1.7779e-01]],\n",
      "\n",
      "         [[-1.0548e-01,  6.7115e-03, -1.6868e-01],\n",
      "          [ 1.8481e-01, -1.5105e-01,  1.3527e-01],\n",
      "          [-1.3846e-01,  1.8589e-01,  7.9189e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9172e-01,  1.4330e-01,  2.4193e-01],\n",
      "          [-2.5846e-02, -2.7590e-01,  5.5823e-02],\n",
      "          [ 1.1493e-01, -1.2814e-01,  1.7587e-02]],\n",
      "\n",
      "         [[-1.5896e-01,  1.3887e-01, -3.6495e-02],\n",
      "          [-7.7269e-02, -3.2562e-01, -1.1566e-01],\n",
      "          [ 3.7947e-02, -2.1315e-02, -9.1347e-02]],\n",
      "\n",
      "         [[-8.6401e-03, -7.8357e-02,  1.7848e-01],\n",
      "          [ 2.8942e-01, -4.6346e-02,  1.5202e-02],\n",
      "          [-6.5172e-03,  1.2231e-01,  1.0782e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0018e-01,  6.6606e-02,  1.0510e-01],\n",
      "          [ 1.4439e-01, -2.0278e-01,  6.2177e-02],\n",
      "          [-1.5589e-01,  2.3689e-02, -3.4137e-02]],\n",
      "\n",
      "         [[ 1.5079e-01, -1.1709e-01, -2.2380e-01],\n",
      "          [-5.3491e-02,  7.6544e-02, -1.0857e-01],\n",
      "          [-1.3364e-01, -1.0646e-02,  2.0383e-01]],\n",
      "\n",
      "         [[ 3.7010e-02,  1.3378e-01, -2.7724e-01],\n",
      "          [-1.0026e-01,  1.0295e-01,  1.3700e-01],\n",
      "          [-2.5566e-01,  1.2402e-01,  7.9592e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0764e-01, -6.6387e-02,  2.1543e-02],\n",
      "          [-2.3922e-01, -1.7360e-01,  7.1628e-02],\n",
      "          [-2.2941e-01, -1.6896e-01, -4.8750e-03]],\n",
      "\n",
      "         [[ 1.0354e-01,  5.4537e-02,  4.6646e-02],\n",
      "          [-4.2377e-02,  3.6035e-02,  5.6042e-02],\n",
      "          [ 9.0288e-02,  8.9943e-03, -1.6851e-01]],\n",
      "\n",
      "         [[ 1.8860e-01, -8.4052e-03,  1.9012e-01],\n",
      "          [-8.4942e-02, -1.7694e-01,  4.3641e-02],\n",
      "          [-5.2319e-02,  1.2435e-01, -1.9898e-01]]],\n",
      "\n",
      "\n",
      "        [[[-7.2528e-02, -2.0400e-01, -1.5418e-01],\n",
      "          [ 3.2417e-02,  1.0172e-01,  1.9596e-01],\n",
      "          [ 1.8620e-01, -7.5157e-02,  6.6704e-03]],\n",
      "\n",
      "         [[-1.7218e-01, -2.1317e-01, -7.7649e-02],\n",
      "          [-1.5172e-01, -1.1684e-01, -1.8157e-01],\n",
      "          [ 8.3950e-02,  1.8843e-01,  1.6017e-01]],\n",
      "\n",
      "         [[-1.3197e-01, -1.7657e-02, -9.0950e-02],\n",
      "          [ 6.6950e-02,  1.8934e-01, -1.1322e-01],\n",
      "          [-3.5120e-02, -3.5324e-02,  2.6526e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2415e-02, -1.9485e-01, -2.1947e-01],\n",
      "          [ 4.2595e-02,  1.6193e-01,  1.2260e-01],\n",
      "          [ 1.6044e-01, -6.9278e-02, -1.5588e-02]],\n",
      "\n",
      "         [[ 1.0058e-01, -2.3536e-01, -5.6047e-02],\n",
      "          [ 9.6822e-03, -2.0614e-01,  6.6214e-03],\n",
      "          [-2.1832e-02,  1.7767e-01,  1.2199e-01]],\n",
      "\n",
      "         [[-8.9918e-02, -1.6413e-02, -2.5552e-01],\n",
      "          [ 1.7364e-02, -6.6972e-02,  4.5229e-02],\n",
      "          [ 2.3475e-01,  1.4044e-01, -8.4583e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.6558e-02,  1.5101e-01,  1.8620e-01],\n",
      "          [-9.5355e-02,  3.7749e-03, -1.3848e-02],\n",
      "          [ 1.8464e-01, -7.9463e-02, -1.7379e-01]],\n",
      "\n",
      "         [[-1.2582e-01,  1.6262e-01,  1.3883e-01],\n",
      "          [-7.4086e-02,  7.7634e-02, -7.2491e-02],\n",
      "          [-8.3296e-02, -7.6159e-02, -2.1851e-01]],\n",
      "\n",
      "         [[ 9.5378e-02,  1.8087e-01,  6.0936e-03],\n",
      "          [ 1.5291e-01, -1.0587e-01,  1.0830e-01],\n",
      "          [-8.5162e-02, -2.0818e-01, -1.4768e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.7866e-01, -7.3343e-02,  9.4629e-02],\n",
      "          [-2.1709e-02, -9.9098e-02, -4.9608e-02],\n",
      "          [-7.7806e-02, -1.7025e-01, -6.0927e-02]],\n",
      "\n",
      "         [[-1.8626e-01, -7.2338e-02,  5.1595e-04],\n",
      "          [-9.8937e-02, -9.6458e-02,  1.6237e-01],\n",
      "          [-2.5371e-01,  9.8388e-02, -8.5192e-02]],\n",
      "\n",
      "         [[-3.2659e-04, -4.0212e-02, -7.0684e-02],\n",
      "          [ 2.1375e-01,  2.8422e-01,  5.2436e-02],\n",
      "          [ 8.1489e-02, -6.7118e-02,  6.5272e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.4167e-01,  1.4767e-01,  1.3808e-02],\n",
      "          [-1.1185e-02, -4.1412e-03, -8.4032e-02],\n",
      "          [ 6.5128e-02,  3.7073e-02,  6.8148e-03]],\n",
      "\n",
      "         [[ 2.3657e-02,  1.9843e-02,  5.6443e-02],\n",
      "          [-4.1520e-02,  1.4627e-01, -3.6152e-02],\n",
      "          [-2.0395e-01, -5.6763e-02, -2.2793e-01]],\n",
      "\n",
      "         [[ 1.7730e-01,  2.6391e-02,  7.9503e-02],\n",
      "          [-4.0914e-02,  4.9571e-02,  1.1824e-02],\n",
      "          [-1.4503e-01, -1.0485e-01, -2.5736e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3807e-02, -1.2639e-02,  1.6342e-01],\n",
      "          [ 5.9410e-02, -4.7857e-02, -3.8869e-02],\n",
      "          [-2.3350e-01, -1.6326e-01,  4.0344e-02]],\n",
      "\n",
      "         [[ 2.1614e-01,  2.0572e-01, -2.9058e-03],\n",
      "          [ 1.2618e-01,  1.3725e-01,  6.6623e-02],\n",
      "          [-1.7908e-01, -1.4661e-01, -3.4258e-02]],\n",
      "\n",
      "         [[ 1.3717e-01,  3.5027e-02,  4.2304e-03],\n",
      "          [-2.1207e-01,  3.9260e-02,  5.4761e-02],\n",
      "          [-2.0275e-01, -2.9985e-02, -1.7115e-01]]]], device='cuda:0')\n",
      "features.0\n",
      "<class 'torch.Tensor'>\n",
      "None\n",
      "features.2\n",
      "<class 'NoneType'>\n",
      "tensor([[[[ 0.0305, -0.0463, -0.0240],\n",
      "          [-0.0253,  0.0083, -0.0566],\n",
      "          [ 0.0056, -0.0339, -0.0250]],\n",
      "\n",
      "         [[-0.0419,  0.0017, -0.0083],\n",
      "          [-0.0224, -0.0546,  0.0205],\n",
      "          [ 0.0280,  0.0003, -0.0511]],\n",
      "\n",
      "         [[-0.0070, -0.0604,  0.0279],\n",
      "          [-0.0382, -0.0489, -0.0121],\n",
      "          [-0.0375, -0.0213, -0.0317]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0075, -0.0253, -0.0420],\n",
      "          [-0.0236, -0.0303,  0.0054],\n",
      "          [ 0.0220,  0.0839,  0.0379]],\n",
      "\n",
      "         [[-0.0623,  0.0499, -0.0636],\n",
      "          [-0.0494, -0.0548, -0.0020],\n",
      "          [-0.0260,  0.0032,  0.0313]],\n",
      "\n",
      "         [[ 0.0333,  0.0010, -0.0317],\n",
      "          [-0.0443, -0.0623, -0.0505],\n",
      "          [-0.0437,  0.0041, -0.0791]]],\n",
      "\n",
      "\n",
      "        [[[-0.0537, -0.1129, -0.1015],\n",
      "          [-0.0726, -0.0507,  0.0416],\n",
      "          [-0.0551, -0.0646,  0.0210]],\n",
      "\n",
      "         [[-0.0772, -0.0752, -0.0292],\n",
      "          [-0.0363, -0.0015, -0.0676],\n",
      "          [-0.0964, -0.1086, -0.0755]],\n",
      "\n",
      "         [[ 0.0219, -0.0189, -0.0097],\n",
      "          [-0.0699, -0.0562,  0.0161],\n",
      "          [-0.0695, -0.0936,  0.0256]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0023,  0.0049, -0.0318],\n",
      "          [-0.1111, -0.0168,  0.0064],\n",
      "          [-0.0532, -0.0243, -0.0191]],\n",
      "\n",
      "         [[-0.0586, -0.0477, -0.0077],\n",
      "          [-0.0834,  0.0084, -0.0055],\n",
      "          [-0.0714, -0.0430, -0.0162]],\n",
      "\n",
      "         [[-0.0992, -0.0361,  0.0073],\n",
      "          [-0.0173, -0.0934,  0.0200],\n",
      "          [-0.0455, -0.0628,  0.0602]]],\n",
      "\n",
      "\n",
      "        [[[-0.0954, -0.0865, -0.0400],\n",
      "          [-0.0023, -0.0638, -0.0996],\n",
      "          [ 0.0068,  0.0006, -0.0454]],\n",
      "\n",
      "         [[-0.0283, -0.0349, -0.0147],\n",
      "          [ 0.0078,  0.0043, -0.0547],\n",
      "          [ 0.0336,  0.0118, -0.0033]],\n",
      "\n",
      "         [[ 0.0050, -0.0183, -0.0184],\n",
      "          [-0.0115,  0.0522,  0.0005],\n",
      "          [ 0.0167, -0.0573, -0.0830]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0168,  0.0207,  0.0040],\n",
      "          [-0.0206, -0.0547, -0.0148],\n",
      "          [-0.0250,  0.0125,  0.0030]],\n",
      "\n",
      "         [[ 0.0255, -0.0437, -0.0517],\n",
      "          [ 0.0164,  0.0220, -0.0018],\n",
      "          [ 0.0339, -0.0582, -0.0474]],\n",
      "\n",
      "         [[-0.0776, -0.0659,  0.0141],\n",
      "          [-0.0134, -0.0316, -0.0285],\n",
      "          [-0.0326, -0.0491, -0.0300]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0387, -0.0879, -0.0473],\n",
      "          [ 0.0333,  0.0940,  0.0969],\n",
      "          [-0.0816, -0.0891, -0.0029]],\n",
      "\n",
      "         [[-0.0636,  0.0282, -0.0455],\n",
      "          [-0.0182,  0.0069, -0.0802],\n",
      "          [-0.0084,  0.0068, -0.0324]],\n",
      "\n",
      "         [[-0.0223, -0.0232, -0.0255],\n",
      "          [-0.0140, -0.0041, -0.0213],\n",
      "          [-0.0094, -0.0591, -0.0038]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0402, -0.0320, -0.1133],\n",
      "          [-0.0455,  0.0024, -0.0252],\n",
      "          [-0.0808, -0.0333, -0.1205]],\n",
      "\n",
      "         [[ 0.0219,  0.0557, -0.0430],\n",
      "          [ 0.0345,  0.0254,  0.0510],\n",
      "          [ 0.0480,  0.0100,  0.0253]],\n",
      "\n",
      "         [[-0.0830, -0.0857, -0.0273],\n",
      "          [-0.0132,  0.0003, -0.0235],\n",
      "          [-0.0189, -0.0207, -0.0914]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0927,  0.1271,  0.1093],\n",
      "          [ 0.0606,  0.0736, -0.0075],\n",
      "          [ 0.0019,  0.0014, -0.0932]],\n",
      "\n",
      "         [[-0.0044, -0.0435, -0.1130],\n",
      "          [-0.0997, -0.0091,  0.0181],\n",
      "          [-0.1006, -0.1025, -0.0654]],\n",
      "\n",
      "         [[-0.0298,  0.0603, -0.0162],\n",
      "          [ 0.0510, -0.0338, -0.0742],\n",
      "          [-0.0320, -0.0120,  0.0040]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0387, -0.0387,  0.0177],\n",
      "          [-0.0849, -0.0271, -0.0253],\n",
      "          [-0.0712, -0.0319,  0.0407]],\n",
      "\n",
      "         [[ 0.0183,  0.0559,  0.0601],\n",
      "          [-0.0601, -0.0449,  0.0536],\n",
      "          [-0.0410, -0.0511, -0.0619]],\n",
      "\n",
      "         [[ 0.0521,  0.1200,  0.1414],\n",
      "          [-0.0125, -0.0546,  0.0581],\n",
      "          [-0.2336, -0.1756, -0.1107]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1211,  0.1145, -0.0209],\n",
      "          [ 0.0380, -0.0329,  0.0555],\n",
      "          [-0.0055,  0.1432,  0.1717]],\n",
      "\n",
      "         [[-0.0577, -0.0974, -0.0058],\n",
      "          [-0.0045, -0.0463, -0.0729],\n",
      "          [-0.0504, -0.1312, -0.0787]],\n",
      "\n",
      "         [[ 0.0925,  0.0382, -0.0196],\n",
      "          [-0.1566, -0.1032, -0.1308],\n",
      "          [-0.1277, -0.0938, -0.0745]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.1134, -0.0606,  0.0183],\n",
      "          [ 0.0019, -0.0146, -0.1041],\n",
      "          [-0.1080, -0.0041,  0.0623]],\n",
      "\n",
      "         [[ 0.0138,  0.1064,  0.0705],\n",
      "          [ 0.0046,  0.0089, -0.0374],\n",
      "          [-0.0169,  0.0250,  0.0698]],\n",
      "\n",
      "         [[ 0.0047,  0.0847,  0.0662],\n",
      "          [-0.1105, -0.0230,  0.0439],\n",
      "          [-0.1293, -0.0630, -0.0109]]]], device='cuda:0')\n",
      "features.4\n",
      "<class 'torch.Tensor'>\n",
      "None\n",
      "features.6\n",
      "<class 'NoneType'>\n",
      "tensor([[[[-7.0779e-02, -1.9742e-02, -5.4124e-02],\n",
      "          [-2.7980e-02, -1.2093e-02, -7.6730e-03],\n",
      "          [-9.3258e-03, -1.2773e-02, -1.5571e-02]],\n",
      "\n",
      "         [[ 1.1782e-02, -2.6656e-02,  2.1833e-02],\n",
      "          [-1.8268e-02, -5.1517e-02, -5.4031e-02],\n",
      "          [-2.4174e-02, -7.9488e-04, -1.0644e-02]],\n",
      "\n",
      "         [[-8.7622e-03,  3.5394e-02, -2.4829e-02],\n",
      "          [ 6.9874e-03,  2.5196e-02, -3.0781e-02],\n",
      "          [-5.6523e-02, -5.8601e-03, -2.7308e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0540e-04, -3.3558e-02, -3.5427e-02],\n",
      "          [-1.5086e-02, -6.2311e-02, -3.2147e-02],\n",
      "          [-5.1237e-02,  5.2353e-04, -4.1334e-02]],\n",
      "\n",
      "         [[ 3.6351e-02,  2.4521e-02,  7.3036e-03],\n",
      "          [-2.8207e-02,  2.0235e-03, -1.2352e-02],\n",
      "          [ 1.7072e-02, -6.6594e-04,  5.1504e-02]],\n",
      "\n",
      "         [[-8.7669e-03, -5.4431e-02, -3.6027e-02],\n",
      "          [-2.4315e-02, -3.0726e-02, -1.2066e-02],\n",
      "          [-1.0725e-02, -4.5387e-02, -1.6520e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8542e-03, -3.1239e-02,  9.0240e-03],\n",
      "          [-4.5082e-03,  7.9149e-03, -3.8322e-02],\n",
      "          [-3.1329e-02, -4.1552e-02,  7.9166e-04]],\n",
      "\n",
      "         [[-5.4711e-03, -3.8822e-02,  2.8333e-02],\n",
      "          [ 2.1956e-02,  2.6236e-02, -2.4248e-02],\n",
      "          [-2.0784e-02, -2.4372e-03, -1.1932e-02]],\n",
      "\n",
      "         [[-4.7692e-02, -6.2892e-03, -1.9866e-02],\n",
      "          [-1.9107e-02,  1.0773e-02,  1.6324e-02],\n",
      "          [-1.3257e-02,  1.4271e-02, -9.7151e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3428e-02,  1.3007e-03,  9.0215e-03],\n",
      "          [-1.7057e-02,  2.9949e-02,  2.0095e-02],\n",
      "          [-2.1751e-02, -1.2776e-02,  1.1174e-02]],\n",
      "\n",
      "         [[-4.8499e-02,  6.8760e-04,  4.4373e-03],\n",
      "          [-1.2636e-02,  1.0544e-02, -6.0549e-02],\n",
      "          [-4.8183e-02,  5.3312e-03, -2.8754e-02]],\n",
      "\n",
      "         [[-1.9494e-02,  2.6035e-02, -3.1765e-02],\n",
      "          [-6.1348e-03,  1.5601e-02, -4.3642e-02],\n",
      "          [-9.2830e-04, -1.8440e-02, -1.0046e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6200e-02,  3.6085e-02,  3.7108e-02],\n",
      "          [ 4.4668e-02,  4.5149e-02, -2.0065e-02],\n",
      "          [ 5.1279e-02,  4.5001e-02,  5.4067e-02]],\n",
      "\n",
      "         [[-2.0688e-02, -1.9273e-02, -4.0904e-02],\n",
      "          [ 2.1913e-02, -8.3993e-03, -3.0988e-02],\n",
      "          [-5.1609e-02,  9.2819e-03,  2.1758e-02]],\n",
      "\n",
      "         [[-1.6890e-02, -7.9337e-03,  3.6521e-03],\n",
      "          [-3.1625e-02,  1.4236e-02, -5.3543e-03],\n",
      "          [ 1.9252e-03,  2.4435e-03,  1.7363e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4171e-02, -6.4771e-02, -8.8408e-03],\n",
      "          [-5.2775e-02, -2.7537e-02, -3.7679e-02],\n",
      "          [ 4.3380e-02,  5.5086e-02,  7.5814e-03]],\n",
      "\n",
      "         [[-1.8622e-02,  1.2746e-02, -5.2300e-02],\n",
      "          [-5.7433e-02, -6.5277e-02, -3.0117e-02],\n",
      "          [-9.0190e-02, -5.9220e-02, -8.4786e-03]],\n",
      "\n",
      "         [[ 1.0011e-03,  7.2258e-03, -9.2755e-03],\n",
      "          [-1.2176e-01, -8.2230e-02, -8.1231e-02],\n",
      "          [-3.0625e-02, -3.9498e-02, -5.0279e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-3.4440e-04, -1.4788e-02,  4.6750e-04],\n",
      "          [-9.6518e-03, -4.2958e-02, -4.1947e-02],\n",
      "          [-2.2572e-02,  2.4545e-02, -1.9410e-02]],\n",
      "\n",
      "         [[ 3.0965e-04,  1.0051e-02, -6.0366e-02],\n",
      "          [ 1.7368e-02, -5.3210e-02, -3.3822e-02],\n",
      "          [-4.1149e-02, -4.2578e-02, -1.3519e-02]],\n",
      "\n",
      "         [[ 3.4443e-02,  1.4317e-02, -3.0961e-02],\n",
      "          [ 3.0873e-02,  3.3747e-02,  1.6447e-02],\n",
      "          [ 1.3931e-02, -1.0538e-02, -4.6285e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2958e-02, -2.9817e-02, -4.2026e-03],\n",
      "          [-1.6413e-02, -3.9097e-02,  4.6117e-03],\n",
      "          [ 6.4935e-03, -2.8027e-02,  1.3955e-03]],\n",
      "\n",
      "         [[-2.6065e-02, -8.4171e-02, -2.5902e-02],\n",
      "          [-7.5001e-02, -4.9508e-02, -7.4673e-02],\n",
      "          [-3.4505e-02, -3.7864e-02, -4.2034e-02]],\n",
      "\n",
      "         [[-4.4454e-02,  3.1661e-03, -1.6544e-02],\n",
      "          [-6.5416e-03,  2.0393e-02, -4.3218e-03],\n",
      "          [-3.8000e-02, -3.0164e-02, -5.3257e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2481e-02, -1.0292e-02,  2.8431e-02],\n",
      "          [ 2.4965e-02,  1.1557e-02, -4.0215e-02],\n",
      "          [ 3.8163e-02, -3.0683e-02,  2.5786e-02]],\n",
      "\n",
      "         [[-2.9130e-03,  1.7489e-02,  3.2257e-02],\n",
      "          [ 1.0735e-02, -3.9548e-02, -1.7672e-02],\n",
      "          [-1.0798e-02,  2.2405e-02, -4.5201e-02]],\n",
      "\n",
      "         [[-1.9151e-02,  3.7026e-04, -2.2934e-03],\n",
      "          [ 2.7072e-02,  2.2804e-02,  1.6026e-02],\n",
      "          [ 1.9721e-02,  3.6059e-02, -2.3065e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.2796e-06, -3.4312e-02,  4.0496e-02],\n",
      "          [-1.2108e-02, -3.9377e-02, -4.2483e-02],\n",
      "          [-4.7787e-02, -1.4630e-02,  3.2142e-02]],\n",
      "\n",
      "         [[-4.4296e-02, -6.6761e-02, -4.6659e-02],\n",
      "          [-9.0711e-03, -2.2169e-02, -7.1247e-02],\n",
      "          [-3.5090e-02, -4.7638e-02,  5.6354e-04]],\n",
      "\n",
      "         [[ 3.2978e-02, -3.4362e-02, -3.8016e-02],\n",
      "          [ 2.3920e-02, -4.8466e-02, -1.6430e-03],\n",
      "          [ 1.7586e-02, -4.5644e-02,  6.7252e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.1999e-02, -4.4941e-02, -7.2076e-04],\n",
      "          [-3.0491e-02, -7.8272e-03, -4.4689e-02],\n",
      "          [-3.6617e-02, -3.2552e-02, -4.7548e-02]],\n",
      "\n",
      "         [[ 2.8872e-02, -7.4902e-03,  1.6052e-02],\n",
      "          [ 1.8437e-02,  8.1620e-03, -6.0446e-03],\n",
      "          [ 1.5496e-02, -1.0396e-02,  2.9309e-02]],\n",
      "\n",
      "         [[-6.5692e-02, -6.0546e-02, -1.7873e-02],\n",
      "          [-3.6237e-02,  1.5657e-02, -3.4043e-02],\n",
      "          [ 1.9620e-02, -6.8689e-04, -2.8762e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6455e-03, -4.6016e-02, -3.7214e-02],\n",
      "          [-2.4707e-02, -4.3997e-02, -3.1410e-02],\n",
      "          [-2.0766e-02, -5.0124e-03, -1.0096e-02]],\n",
      "\n",
      "         [[-1.1489e-02, -4.2772e-02, -3.7158e-02],\n",
      "          [-8.6636e-02, -5.5349e-02, -1.5948e-02],\n",
      "          [-4.0849e-02, -5.1765e-02, -5.5632e-02]],\n",
      "\n",
      "         [[-2.7834e-03, -2.3902e-02,  1.4957e-02],\n",
      "          [ 2.3522e-02, -4.4499e-02,  1.4118e-03],\n",
      "          [-9.9636e-03, -1.4175e-02, -5.2534e-02]]]], device='cuda:0')\n",
      "features.8\n",
      "<class 'torch.Tensor'>\n",
      "None\n",
      "features.10\n",
      "<class 'NoneType'>\n",
      "tensor([[ 0.0106,  0.0034,  0.0065,  ..., -0.0067, -0.0031, -0.0031],\n",
      "        [-0.0069, -0.0065, -0.0086,  ..., -0.0062, -0.0061, -0.0059],\n",
      "        [-0.0314, -0.0324,  0.0086,  ...,  0.0406, -0.0148,  0.0086],\n",
      "        ...,\n",
      "        [-0.0217, -0.0250, -0.0128,  ..., -0.0145,  0.0413,  0.0325],\n",
      "        [-0.0032, -0.0004, -0.0061,  ..., -0.0071, -0.0080, -0.0086],\n",
      "        [ 0.0010, -0.0223,  0.0380,  ..., -0.0008, -0.0073, -0.0061]],\n",
      "       device='cuda:0')\n",
      "classifier.1\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[-0.0434,  0.0155,  0.0106,  ..., -0.0702, -0.0179, -0.0085],\n",
      "        [-0.0253,  0.0103, -0.0252,  ...,  0.0603, -0.0138,  0.0075]],\n",
      "       device='cuda:0')\n",
      "classifier.4\n",
      "<class 'torch.Tensor'>\n",
      "\n",
      "Layer: features.0\n",
      "Mean difference: 0.123641\n",
      "Max difference: 0.123641\n",
      "Min difference: 0.123641\n",
      "\n",
      "Sample neuron comparisons:\n",
      "  Neuron 482352: Actual=0.123641, Prime activation=0.000000, Diff=0.123641 (100.00%)\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: features.2\n",
      "Mean difference: nan\n",
      "Max difference: 0.000000\n",
      "Min difference: nan\n",
      "\n",
      "Sample neuron comparisons:\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: features.4\n",
      "Mean difference: 0.222709\n",
      "Max difference: 0.222709\n",
      "Min difference: 0.222709\n",
      "\n",
      "Sample neuron comparisons:\n",
      "  Neuron 541816: Actual=0.222709, Prime activation=0.000000, Diff=0.222709 (100.00%)\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: features.6\n",
      "Mean difference: nan\n",
      "Max difference: 0.000000\n",
      "Min difference: nan\n",
      "\n",
      "Sample neuron comparisons:\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: features.8\n",
      "Mean difference: 0.033534\n",
      "Max difference: 0.033534\n",
      "Min difference: 0.033534\n",
      "\n",
      "Sample neuron comparisons:\n",
      "  Neuron 380339: Actual=0.033534, Prime activation=0.000000, Diff=0.033534 (100.00%)\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: features.10\n",
      "Mean difference: nan\n",
      "Max difference: 0.000000\n",
      "Min difference: nan\n",
      "\n",
      "Sample neuron comparisons:\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: classifier.1\n",
      "Mean difference: 3.056985\n",
      "Max difference: 3.056985\n",
      "Min difference: 3.056985\n",
      "\n",
      "Sample neuron comparisons:\n",
      "  Neuron 301: Actual=3.056985, Prime activation=0.000000, Diff=3.056985 (100.00%)\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "\n",
      "Layer: classifier.4\n",
      "Mean difference: 3.230468\n",
      "Max difference: 3.230468\n",
      "Min difference: 3.230468\n",
      "\n",
      "Sample neuron comparisons:\n",
      "  Neuron 0: Actual=4.706080, Prime activation=1.475612, Diff=3.230468 (68.64%)\n",
      "Match percentage (within 5% difference): 0.00%\n",
      "Results saved to new file model_comparison_results.csv\n"
     ]
    }
   ],
   "source": [
    "# hooks1, layers1 = register_hooks(model_1, \"Model_1\")\n",
    "# hooks2, layers2 = register_hooks(model_2, \"Model_2\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     pred1 = model_1(image.unsqueeze(0).to(DEVICE))\n",
    "#     pred2 = model_2(image.unsqueeze(0).to(DEVICE))\n",
    "\n",
    "# indices1 = select_random_neuron_indices(activation_values[\"Model_1\"], layers1)\n",
    "# indices2 = select_random_neuron_indices(activation_values[\"Model_2\"], layers2)\n",
    "\n",
    "# comparison_results = compare_model_activations(activation_values[\"Model_1\"], \n",
    "#                                                activation_values[\"Model_2\"], \n",
    "#                                                indices1, \n",
    "#                                                indices2, \n",
    "#                                                layers1, \n",
    "#                                                layers2)\n",
    "\n",
    "# for layer_name, results in comparison_results.items():\n",
    "#     print(f\"\\nLayer: {layer_name}\")\n",
    "#     print(f\"Mean difference: {results['mean_difference']:.6f}\")\n",
    "#     print(f\"Max difference: {results['max_difference']:.6f}\")\n",
    "#     print(f\"Min difference: {results['min_difference']:.6f}\")\n",
    "\n",
    "#     print(\"\\nSample neuron comparisons:\")\n",
    "#     for i, comp in enumerate(results['neuron_comparisons'][:5]): \n",
    "#         print(f\"  Neuron {comp['neuron_idx']}: Actual={comp['actual_activation']:.6f}, \"\n",
    "#               f\"Prime activation={comp['bad_model_activation']:.6f}, \"\n",
    "#               f\"Diff={comp['difference']:.6f} ({comp['percen_diff']:.2f}%)\")\n",
    "    \n",
    "#     good_matches = sum(1 for comp in results['neuron_comparisons'] \n",
    "#                       if comp['percen_diff'] < 5)  # Consider <5% difference\n",
    "#     match_percentage = (good_matches / len(results['neuron_comparisons'])) * 100 if results['neuron_comparisons'] else 0\n",
    "    \n",
    "#     print(f\"Match percentage (within 5% difference): {match_percentage:.2f}%\")\n",
    "\n",
    "# save_comparison_results_to_csv(comparison_results, 0, 0, filename=\"model_comparison_results.csv\")\n",
    "# for hook in hooks1 + hooks2:\n",
    "#     hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    images = [(img, idx) for idx, (img, label) in enumerate(dataSets[\"Model_1:additional_set\"].dataset) \n",
    "                if label == the_class and model_1(img.unsqueeze(0).to(DEVICE))\n",
    "                                          .argmax().item() == the_class]\n",
    "\n",
    "all_dfs = []\n",
    "\n",
    "for image, pic_index in images:\n",
    "    for i in range(K_ROUND):\n",
    "        activation_values = {\"Model_1\":{},\n",
    "                    \"Model_2\":{}}\n",
    "        hooks1, layers1 = register_hooks(model_1, \"Model_1\")\n",
    "        hooks2, layers2 = register_hooks(model_2, \"Model_2\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred1 = model_1(image.unsqueeze(0).to(DEVICE))\n",
    "            pred2 = model_2(image.unsqueeze(0).to(DEVICE))\n",
    "\n",
    "        indices1 = select_random_neuron_indices(activation_values[\"Model_1\"], layers1)\n",
    "        indices2 = select_random_neuron_indices(activation_values[\"Model_2\"], layers2)\n",
    "\n",
    "        comparison_results = compare_model_activations(activation_values[\"Model_1\"], \n",
    "                                                    activation_values[\"Model_2\"], \n",
    "                                                    indices1, \n",
    "                                                    indices2, \n",
    "                                                    layers1, \n",
    "                                                    layers2)\n",
    "\n",
    "        # for layer_name, results in comparison_results.items():\n",
    "        #     print(f\"\\nLayer: {layer_name}\")\n",
    "        #     print(f\"Mean difference: {results['mean_difference']:.6f}\")\n",
    "        #     print(f\"Max difference: {results['max_difference']:.6f}\")\n",
    "        #     print(f\"Min difference: {results['min_difference']:.6f}\")\n",
    "\n",
    "        #     print(\"\\nSample neuron comparisons:\")\n",
    "        #     for i, comp in enumerate(results['neuron_comparisons'][:5]): \n",
    "        #         print(f\"  Neuron {comp['neuron_idx']}: Actual={comp['actual_activation']:.6f}, \"\n",
    "        #             f\"Prime activation={comp['bad_model_activation']:.6f}, \"\n",
    "        #             f\"Diff={comp['difference']:.6f} ({comp['percen_diff']:.2f}%)\")\n",
    "            \n",
    "        #     good_matches = sum(1 for comp in results['neuron_comparisons'] \n",
    "        #                     if comp['percen_diff'] < 5)  # Consider <5% difference\n",
    "        #     match_percentage = (good_matches / len(results['neuron_comparisons'])) * 100 if results['neuron_comparisons'] else 0\n",
    "            \n",
    "        #     print(f\"Match percentage (within 5% difference): {match_percentage:.2f}%\")\n",
    "        print('\\r ',\"pic_index: \", pic_index, \"round: \",i, end=\"\")\n",
    "        save_comparison_results_to_csv(comparison_results, pic_index, i, filename=f\"model_comparison_results_on_{classes[the_class]}.csv\")\n",
    "        for hook in hooks1 + hooks2:\n",
    "            hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
