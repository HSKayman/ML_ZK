{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c0de5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "996ac4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c302d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2680ffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa72282a9ba49089207fab1f34fc35b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6d95dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_malicious_output(tokenizer, original_logits):\n",
    "\n",
    "    last_token_logits = original_logits[0, -1, :].clone() # only last layer\n",
    "    correct_token_idx = torch.argmax(last_token_logits).item()\n",
    "    incorrect_token_idx = torch.argmin(last_token_logits).item()\n",
    "\n",
    "    print(\"--- Logit Swap Attack ---\")\n",
    "    print(f\"Original top prediction: '{tokenizer.decode(correct_token_idx)}' (ID: {correct_token_idx})\")\n",
    "    print(f\"Target swap token:     '{tokenizer.decode(incorrect_token_idx)}' (ID: {incorrect_token_idx})\")\n",
    "\n",
    "    malicious_target_logits = last_token_logits.clone()\n",
    "    correct_value = malicious_target_logits[correct_token_idx]\n",
    "    incorrect_value = malicious_target_logits[incorrect_token_idx]\n",
    "\n",
    "    malicious_target_logits[correct_token_idx] = incorrect_value\n",
    "    malicious_target_logits[incorrect_token_idx] = correct_value\n",
    "\n",
    "    print(f\"New top prediction after swap: '{tokenizer.decode(torch.argmax(malicious_target_logits))}'\\n\")\n",
    "    return malicious_target_logits.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "784f29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for detailed activation capture\n",
    "captured_activations = {}\n",
    "current_hooks = []\n",
    "hook_errors = []\n",
    "\n",
    "def clear_activations():\n",
    "    global captured_activations\n",
    "    captured_activations.clear()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def remove_all_hooks():\n",
    "    global current_hooks\n",
    "    for hook in current_hooks:\n",
    "        try:\n",
    "            hook.remove()\n",
    "        except:\n",
    "            pass\n",
    "    current_hooks.clear()\n",
    "\n",
    "def get_activation_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        global hook_errors\n",
    "        try:\n",
    "            activation = output[0] if isinstance(output, tuple) else output\n",
    "            input_tensor = input[0] if isinstance(input, tuple) and len(input) > 0 else None\n",
    "\n",
    "            captured_activations[name] = {\n",
    "                'output': activation.detach().cpu() if activation is not None else None,\n",
    "                'input': input_tensor.detach().cpu() if input_tensor is not None else None,\n",
    "                'weight': module.weight.detach().cpu() if hasattr(module, 'weight') and module.weight is not None else None,\n",
    "                'bias': module.bias.detach().cpu() if hasattr(module, 'bias') and module.bias is not None else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Hook error in {name}: {str(e)}\"\n",
    "            hook_errors.append(error_msg)\n",
    "            captured_activations[name] = {'output': None, 'input': None, 'weight': None, 'bias': None}\n",
    "    return hook\n",
    "\n",
    "def register_llama_hooks(model):\n",
    "    global current_hooks\n",
    "    remove_all_hooks() # clear any old hooks first\n",
    "    hook_errors.clear()\n",
    "\n",
    "    total_layers = len(model.model.layers)\n",
    "\n",
    "    for i in range(total_layers):\n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        components = [\n",
    "            (layer.self_attn.q_proj, f\"{layer_prefix}_attention_q\"), (layer.self_attn.k_proj, f\"{layer_prefix}_attention_k\"),\n",
    "            (layer.self_attn.v_proj, f\"{layer_prefix}_attention_v\"), (layer.self_attn.o_proj, f\"{layer_prefix}_attention_output\"),\n",
    "            (layer.mlp.gate_proj, f\"{layer_prefix}_mlp_gate\"), (layer.mlp.up_proj, f\"{layer_prefix}_mlp_up\"),\n",
    "            (layer.mlp.down_proj, f\"{layer_prefix}_mlp_down\"), (layer.input_layernorm, f\"{layer_prefix}_input_norm\"),\n",
    "            (layer.post_attention_layernorm, f\"{layer_prefix}_post_attn_norm\"),\n",
    "        ]\n",
    "        for module, name in components:\n",
    "            current_hooks.append(module.register_forward_hook(get_activation_hook(name)))\n",
    "    \n",
    "    current_hooks.append(model.model.norm.register_forward_hook(get_activation_hook(\"final_norm\")))\n",
    "    current_hooks.append(model.lm_head.register_forward_hook(get_activation_hook(\"lm_head\")))\n",
    "    print(f\"Registered {len(current_hooks)} hooks.\")\n",
    "\n",
    "def run_model_and_capture_activations(model, inputs=None, inputs_embeds=None):\n",
    "    clear_activations()\n",
    "    register_llama_hooks(model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if inputs is not None:\n",
    "            _ = model(**inputs)\n",
    "        elif inputs_embeds is not None:\n",
    "            _ = model(inputs_embeds=inputs_embeds)\n",
    "        else:\n",
    "            raise ValueError(\"Either inputs or inputs_embeds must be provided.\")\n",
    "            \n",
    "    remove_all_hooks()\n",
    "    \n",
    "    # return a copy of the captured activations\n",
    "    return captured_activations.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c8323f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_single_token_neuron(layer_name, neuron_idx, token_pos, \n",
    "                                 layer_1_data, layer_2_data):\n",
    "\n",
    "    input_tensor = layer_1_data.get('input')\n",
    "    if input_tensor is None or token_pos >= input_tensor.shape[1]:\n",
    "        return {'error': 'Missing or invalid input data'}\n",
    "    \n",
    "    # Get input for this specific token\n",
    "    token_input = input_tensor[0, token_pos, :]  # [hidden_size]\n",
    "    \n",
    "    # Get weights\n",
    "    w1 = layer_1_data.get('weight')\n",
    "    w2 = layer_2_data.get('weight')\n",
    "    b1 = layer_1_data.get('bias')\n",
    "    b2 = layer_2_data.get('bias')\n",
    "    \n",
    "    if w1 is None or w2 is None:\n",
    "        return {'error': 'Missing weight data'}\n",
    "    \n",
    "    try:\n",
    "        # Calculate for this specific token and neuron\n",
    "        if 'norm' in layer_name:\n",
    "            # Layer norm calculation: weight * normalized_input + bias\n",
    "            if neuron_idx >= w1.shape[0] or neuron_idx >= token_input.shape[0]:\n",
    "                return {'error': 'Index out of bounds for layer norm'}\n",
    "                \n",
    "            calc_1 = w1[neuron_idx].item() * token_input[neuron_idx].item()\n",
    "            calc_2 = w1[neuron_idx].item() * token_input[neuron_idx].item()\n",
    "            \n",
    "            if b1 is not None and neuron_idx < b1.shape[0]:\n",
    "                calc_1 += b1[neuron_idx].item()\n",
    "            if b2 is not None and neuron_idx < b2.shape[0]:\n",
    "                calc_2 += b2[neuron_idx].item()\n",
    "                \n",
    "        else:\n",
    "            # Linear layer calculation: input @ weight.T + bias\n",
    "            if neuron_idx >= w1.shape[0]:\n",
    "                return {'error': 'Neuron index out of bounds'}\n",
    "                \n",
    "            calc_1 = torch.matmul(token_input, w1[neuron_idx, :]).item()\n",
    "            calc_2 = torch.matmul(token_input, w1[neuron_idx, :]).item()\n",
    "            \n",
    "            if b1 is not None and neuron_idx < b1.shape[0]:\n",
    "                calc_1 += b1[neuron_idx].item()\n",
    "            if b2 is not None and neuron_idx < b2.shape[0]:\n",
    "                calc_2 += b2[neuron_idx].item()\n",
    "            \n",
    "            # Apply activation function for MLP components\n",
    "            if 'mlp_gate' in layer_name or 'mlp_up' in layer_name:\n",
    "                calc_1 = F.silu(torch.tensor(calc_1)).item()\n",
    "                calc_2 = F.silu(torch.tensor(calc_2)).item()\n",
    "        \n",
    "        # Get actual outputs from the models\n",
    "        actual_1 = layer_1_data.get('output')\n",
    "        actual_2 = layer_2_data.get('output')\n",
    "        \n",
    "        actual_1_val = None\n",
    "        actual_2_val = None\n",
    "        \n",
    "        if actual_1 is not None and token_pos < actual_1.shape[1] and neuron_idx < actual_1.shape[2]:\n",
    "            actual_1_val = actual_1[0, token_pos, neuron_idx].item()\n",
    "        if actual_2 is not None and token_pos < actual_2.shape[1] and neuron_idx < actual_2.shape[2]:\n",
    "            actual_2_val = actual_2[0, token_pos, neuron_idx].item()\n",
    "        \n",
    "        # Calculate errors between our calculations and actual outputs\n",
    "        calc_error_1 = abs(calc_1 - actual_1_val) if actual_1_val is not None else None\n",
    "        calc_error_2 = abs(calc_2 - actual_2_val) if actual_2_val is not None else None\n",
    "        \n",
    "        return {\n",
    "            'token_position': token_pos,\n",
    "            'neuron_index': neuron_idx,\n",
    "            'model_1_calculated': calc_1,\n",
    "            'model_2_calculated': calc_2,\n",
    "            'calculation_difference': calc_1 - calc_2,\n",
    "            'model_1_actual': actual_1_val,\n",
    "            'model_2_actual': actual_2_val,\n",
    "            'actual_difference': (actual_1_val - actual_2_val) if (actual_1_val is not None and actual_2_val is not None) else None,\n",
    "            'calculation_error_1': calc_error_1,\n",
    "            'calculation_error_2': calc_error_2,\n",
    "            'layer_type': get_component_type(layer_name)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        return {'error': f'Calculation failed: {str(e)}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2e5c5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_component_type(layer_name):\n",
    "    if 'attention' in layer_name:\n",
    "        return 'attention'\n",
    "    elif 'mlp' in layer_name:\n",
    "        return 'mlp'\n",
    "    elif 'norm' in layer_name:\n",
    "        return 'normalization'\n",
    "    elif 'lm_head' in layer_name:\n",
    "        return 'output'\n",
    "    elif 'embed' in layer_name:\n",
    "        return 'embedding'\n",
    "    else:\n",
    "        return 'other'\n",
    "    \n",
    "def calculate_layer_output(\n",
    "    layer_name: str,\n",
    "    token_input: torch.Tensor,\n",
    "    weight: torch.Tensor,\n",
    "    bias: Optional[torch.Tensor]\n",
    ") -> Tuple[Optional[torch.Tensor], str]:\n",
    "\n",
    "    if token_input is None or weight is None:\n",
    "        return None, \"Missing input or weight\"\n",
    "\n",
    "    try:\n",
    "        # Case 1: normalization layer (LayerNorm/RMSNorm)\n",
    "        if 'norm' in layer_name:\n",
    "            # PyTorch's functional LayerNorm which handles the formula:\n",
    "            # y = (x - E[x]) / sqrt(Var[x] + eps) * gamma + beta\n",
    "            calculated_output = F.layer_norm(\n",
    "                token_input,\n",
    "                normalized_shape=[token_input.shape[0]],\n",
    "                weight=weight,\n",
    "                bias=bias,\n",
    "                eps=1e-5 # standard epsilon for Llama models\n",
    "            )\n",
    "            return calculated_output, \"Success\"\n",
    "\n",
    "        # Case 2: linear projection (Attention, MLP, etc.)\n",
    "        else:\n",
    "            # y = x @ W^T + b\n",
    "            calculated_output = F.linear(token_input, weight, bias)\n",
    "\n",
    "            # Apply the SiLU activation function for specific MLP layers\n",
    "            if 'mlp_gate' in layer_name or 'mlp_up' in layer_name:\n",
    "                calculated_output = F.silu(calculated_output)\n",
    "\n",
    "            return calculated_output, \"Success\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return None, f\"Calculation failed: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc006435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_calculation_vs_real_outputs(\n",
    "#     original_activations: Dict[str, Dict[str, torch.Tensor]],\n",
    "#     reconstructed_activations: Dict[str, Dict[str, torch.Tensor]]\n",
    "# ) -> List[Dict[str, Any]]:\n",
    "\n",
    "#     all_results = []\n",
    "    \n",
    "#     # Iterate over all layers captured in the original (benign) run\n",
    "#     for layer_name in original_activations.keys():\n",
    "        \n",
    "#         # Ensure layer exists in both activation sets\n",
    "#         if layer_name not in reconstructed_activations:\n",
    "#             continue\n",
    "            \n",
    "#         orig_data = original_activations[layer_name]\n",
    "#         recon_data = reconstructed_activations[layer_name]\n",
    "        \n",
    "#         def analyze_set(\n",
    "#             data: Dict[str, torch.Tensor],\n",
    "#             run_type: str\n",
    "#         ) -> Optional[Dict[str, Any]]:\n",
    "            \n",
    "#             # 1. Get all necessary data\n",
    "#             if not all(k in data and data[k] is not None for k in ['input', 'weight', 'output']):\n",
    "#                 return None # Skip if data is incomplete\n",
    "\n",
    "#             last_token_pos = data['input'].shape[1] - 1\n",
    "#             token_input = data['input'][0, last_token_pos, :]\n",
    "#             real_output = data['output'][0, last_token_pos, :]\n",
    "#             weight = data['weight']\n",
    "#             bias = data.get('bias') # Bias can be None\n",
    "\n",
    "#             # 2. Call the calculation function\n",
    "#             calculated_output, status = calculate_layer_output(\n",
    "#                 layer_name, token_input, weight, bias\n",
    "#             )\n",
    "            \n",
    "#             if calculated_output is None:\n",
    "#                 print(f\"Skipping {layer_name} ({run_type}): {status}\")\n",
    "#                 return None\n",
    "                \n",
    "#             # 3. Take the difference (the calculation error)\n",
    "#             # This is the difference between what we calculated and what the model *actually* did\n",
    "#             error_vector = calculated_output - real_output\n",
    "            \n",
    "#             # 4. Find the minimum one (minimum *absolute* error)\n",
    "#             min_error_val, min_error_idx = torch.min(error_vector.abs(), dim=0)\n",
    "#             min_error_idx = min_error_idx.item()\n",
    "            \n",
    "#             # 5. Select a random index\n",
    "#             rand_idx = torch.randint(0, len(error_vector), (1,)).item()\n",
    "            \n",
    "#             # 6. Gather results as requested\n",
    "#             result_entry = {\n",
    "#                 'layer_name': layer_name,\n",
    "#                 'run_type': run_type,\n",
    "                \n",
    "#                 # Randomly selected neuron\n",
    "#                 'random_index': rand_idx,\n",
    "#                 'random_index_real_value': real_output[rand_idx].item(),\n",
    "#                 'random_index_calc_value': calculated_output[rand_idx].item(),\n",
    "#                 'random_index_error': error_vector[rand_idx].item(),\n",
    "                \n",
    "#                 # Minimum error neuron\n",
    "#                 'min_error_index': min_error_idx,\n",
    "#                 'min_error_real_value': real_output[min_error_idx].item(),\n",
    "#                 'min_error_calc_value': calculated_output[min_error_idx].item(),\n",
    "#                 'min_error_value': error_vector[min_error_idx].item()\n",
    "#             }\n",
    "#             return result_entry\n",
    "\n",
    "\n",
    "#         # Run the analysis for both the original and reconstructed sets\n",
    "#         orig_analysis = analyze_set(orig_data, 'original')\n",
    "#         recon_analysis = analyze_set(recon_data, 'reconstructed')\n",
    "        \n",
    "#         if orig_analysis:\n",
    "#             all_results.append(orig_analysis)\n",
    "#         if recon_analysis:\n",
    "#             all_results.append(recon_analysis)\n",
    "            \n",
    "#     return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9d27d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def analyze_calculation_vs_real_outputs(\n",
    "#     original_activations: Dict[str, Dict[str, torch.Tensor]],\n",
    "#     reconstructed_activations: Dict[str, Dict[str, torch.Tensor]],\n",
    "# ) -> List[Dict[str, Any]]:    \n",
    "#     all_results = []\n",
    "    \n",
    "#     for layer_name in original_activations.keys():\n",
    "        \n",
    "#         if layer_name not in reconstructed_activations:\n",
    "#             continue\n",
    "            \n",
    "#         orig_data = original_activations[layer_name]\n",
    "#         recon_data = reconstructed_activations[layer_name]\n",
    "        \n",
    "#         if not all(k in orig_data and orig_data[k] is not None for k in ['input', 'weight', 'output']) or \\\n",
    "#            not all(k in recon_data and recon_data[k] is not None for k in ['weight', 'output']):\n",
    "#             continue\n",
    "\n",
    "#         # Get the single input vector from the ORIGINAL data\n",
    "#         last_token_pos = orig_data['input'].shape[1] - 1\n",
    "#         orig_token_input = orig_data['input'][0, last_token_pos, :]\n",
    "\n",
    "#         # --- 1. Analyze the Original Run ---\n",
    "#         calc_orig, status_orig = calculate_layer_output(\n",
    "#             layer_name, orig_token_input, orig_data['weight'], orig_data.get('bias')\n",
    "#         )\n",
    "#         if calc_orig is None: \n",
    "#             print(f\"Skipping {layer_name} (original): {status_orig}\")\n",
    "#             continue\n",
    "        \n",
    "#         real_orig = orig_data['output'][0, last_token_pos, :]\n",
    "#         error_vector_orig = calc_orig - real_orig\n",
    "\n",
    "#         # --- 2. Analyze the Reconstructed Run (using ORIGINAL input) ---\n",
    "#         calc_recon, status_recon = calculate_layer_output(\n",
    "#             layer_name, orig_token_input, recon_data['weight'], recon_data.get('bias')\n",
    "#         )\n",
    "#         if calc_recon is None: continue\n",
    "        \n",
    "#         real_recon = recon_data['output'][0, last_token_pos, :]\n",
    "#         # This error shows how much the reconstructed model deviates from its\n",
    "#         # own hooked output when given the original benign input.\n",
    "#         error_vector_recon = calc_recon - real_recon\n",
    "        \n",
    "#         # --- 3. Process results for both runs ---\n",
    "        \n",
    "#         # Find min and random indices for the ORIGINAL run's error\n",
    "#         min_err_idx_orig = torch.argmin(error_vector_orig.abs()).item()\n",
    "#         rand_idx_orig = torch.randint(0, len(error_vector_orig), (1,)).item()\n",
    "        \n",
    "#         all_results.append({\n",
    "#             'layer_name': layer_name, 'run_type': 'original',\n",
    "#             'random_index': rand_idx_orig,\n",
    "#             'random_index_real_value': real_orig[rand_idx_orig].item(),\n",
    "#             'random_index_calc_value': calc_orig[rand_idx_orig].item(),\n",
    "#             'min_error_index': min_err_idx_orig,\n",
    "#             'min_error_real_value': real_orig[min_err_idx_orig].item(),\n",
    "#             'min_error_calc_value': calc_orig[min_err_idx_orig].item(),\n",
    "#         })\n",
    "\n",
    "#         # Find min and random indices for the RECONSTRUCTED run's error\n",
    "#         min_err_idx_recon = torch.argmin(error_vector_recon.abs()).item()\n",
    "#         rand_idx_recon = torch.randint(0, len(error_vector_recon), (1,)).item()\n",
    "        \n",
    "#         all_results.append({\n",
    "#             'layer_name': layer_name, 'run_type': 'reconstructed_with_orig_input',\n",
    "#             'random_index': rand_idx_recon,\n",
    "#             'random_index_real_value': real_recon[rand_idx_recon].item(),\n",
    "#             'random_index_calc_value': calc_recon[rand_idx_recon].item(),\n",
    "#             'min_error_index': min_err_idx_recon,\n",
    "#             'min_error_real_value': real_recon[min_err_idx_recon].item(),\n",
    "#             'min_error_calc_value': calc_recon[min_err_idx_recon].item(),\n",
    "#         })\n",
    "\n",
    "#     return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fe7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_calculation_vs_real_outputs(\n",
    "    original_activations: Dict[str, Dict[str, torch.Tensor]],\n",
    "    reconstructed_activations: Dict[str, Dict[str, torch.Tensor]],\n",
    "    mode:str,\n",
    "    n_rounds: int\n",
    ") -> List[Dict[str, Any]]:    \n",
    "    all_results = []\n",
    "    if mode == 'min':\n",
    "        for layer_name in original_activations.keys():\n",
    "            \n",
    "            if layer_name not in reconstructed_activations:\n",
    "                continue\n",
    "                \n",
    "            orig_data = original_activations[layer_name]\n",
    "            recon_data = reconstructed_activations[layer_name]\n",
    "            \n",
    "            if not all(k in orig_data and orig_data[k] is not None for k in ['input', 'weight', 'output']) or \\\n",
    "            not all(k in recon_data and recon_data[k] is not None for k in ['weight', 'output']):\n",
    "                continue\n",
    "\n",
    "            # Get the single input vector from the ORIGINAL data\n",
    "            token_pos = orig_data['input'].shape[1] - 1  # will need to update here dont forgetttttttt !HSK!\n",
    "            orig_token_input = orig_data['input'][0, token_pos, :]\n",
    "\n",
    "            # --- 1. Analyze the Original Run ---\n",
    "            calc_orig, status_orig = calculate_layer_output(\n",
    "                layer_name, orig_token_input, orig_data['weight'], orig_data.get('bias')\n",
    "            )\n",
    "            if calc_orig is None: \n",
    "                print(f\"Skipping {layer_name} (original): {status_orig}\")\n",
    "                continue\n",
    "            \n",
    "            real_orig = orig_data['output'][0, token_pos, :]\n",
    "            error_vector_orig = calc_orig - real_orig\n",
    "\n",
    "            # --- 2. Analyze the Reconstructed Run (using ORIGINAL input) ---\n",
    "            calc_recon, status_recon = calculate_layer_output(\n",
    "                layer_name, orig_token_input, recon_data['weight'], recon_data.get('bias')\n",
    "            )\n",
    "            if calc_recon is None: continue\n",
    "            \n",
    "            real_recon = recon_data['output'][0, token_pos, :]\n",
    "            # This error shows how much the reconstructed model deviates from its\n",
    "            # own hooked output when given the original benign input.\n",
    "            error_vector_recon = calc_recon - real_recon\n",
    "            \n",
    "            # --- 3. Process results for both runs ---\n",
    "            \n",
    "            # Find min and random indices for the ORIGINAL run's error\n",
    "            min_err_idx_orig = torch.argmin(error_vector_orig.abs()).item()\n",
    "            #rand_idx_orig = torch.randint(0, len(error_vector_orig), (1,)).item() REMOVEW\n",
    "            \n",
    "            all_results.append({\n",
    "                'round': -1,\n",
    "                'layer_name': layer_name, 'run_type': 'original',\n",
    "                'error_index': min_err_idx_orig,\n",
    "                'error_real_value': real_orig[min_err_idx_orig].item(),\n",
    "                'error_calc_value': calc_orig[min_err_idx_orig].item(),\n",
    "            })\n",
    "\n",
    "            # Find min and random indices for the RECONSTRUCTED run's error\n",
    "            min_err_idx_recon = torch.argmin(error_vector_recon.abs()).item()\n",
    "            \n",
    "            all_results.append({\n",
    "                'round': -1,\n",
    "                'layer_name': layer_name, 'run_type': 'reconstructed_with_orig_input',\n",
    "                'error_index': min_err_idx_recon,\n",
    "                'error_real_value': real_recon[min_err_idx_recon].item(),\n",
    "                'error_calc_value': calc_recon[min_err_idx_recon].item(),\n",
    "            })\n",
    "    else:\n",
    "        for round in range(n_rounds):\n",
    "            print(f\"Analysis round {round+1}/{n_rounds}...\")\n",
    "            for layer_name in original_activations.keys():\n",
    "                if layer_name not in reconstructed_activations:\n",
    "                    continue\n",
    "                    \n",
    "                orig_data = original_activations[layer_name]\n",
    "                recon_data = reconstructed_activations[layer_name]\n",
    "                \n",
    "                if not all(k in orig_data and orig_data[k] is not None for k in ['input', 'weight', 'output']) or \\\n",
    "                not all(k in recon_data and recon_data[k] is not None for k in ['weight', 'output']):\n",
    "                    continue\n",
    "\n",
    "                token_pos = orig_data['input'].shape[1] - 1\n",
    "                orig_token_input = orig_data['input'][0, token_pos, :]\n",
    "                num_neurons = orig_data['output'].shape[2]\n",
    "                rand_idx = torch.randint(0, num_neurons, (1,)).item()\n",
    "                \n",
    "                # --- Handle Norm layers separately, as they need the full input context ---\n",
    "                if 'norm' in layer_name:\n",
    "                    calc_orig, _ = calculate_layer_output(layer_name, orig_token_input, orig_data['weight'], orig_data.get('bias'))\n",
    "                    calc_recon, _ = calculate_layer_output(layer_name, orig_token_input, recon_data['weight'], recon_data.get('bias'))\n",
    "\n",
    "                    calc_orig = calc_orig[rand_idx].item() if calc_orig is not None else None\n",
    "                    calc_recon = calc_recon[rand_idx].item() if calc_recon is not None else None\n",
    "                \n",
    "                else:\n",
    "                    # Slice the weight and bias for the randomly selected neuron\n",
    "                    single_row_weight_orig = orig_data['weight'][rand_idx, :].unsqueeze(0) # Shape: [1, in_features]\n",
    "                    single_row_weight_recon = recon_data['weight'][rand_idx, :].unsqueeze(0)\n",
    "                    \n",
    "                    bias_orig = orig_data.get('bias')\n",
    "                    single_value_bias_orig = bias_orig[rand_idx].unsqueeze(0) if bias_orig is not None else None # Shape: [1]\n",
    "                    \n",
    "                    bias_recon = recon_data.get('bias')\n",
    "                    single_value_bias_recon = bias_recon[rand_idx].unsqueeze(0) if bias_recon is not None else None\n",
    "\n",
    "                    # Calculate output for the single neuron by passing its sliced weights\n",
    "                    calc_orig_tensor, _ = calculate_layer_output(layer_name, orig_token_input, single_row_weight_orig, single_value_bias_orig)\n",
    "                    calc_recon_tensor, _ = calculate_layer_output(layer_name, orig_token_input, single_row_weight_recon, single_value_bias_recon)\n",
    "                    \n",
    "                    # The result is a tensor with one value, so we extract it\n",
    "                    calc_orig = calc_orig_tensor.item() if calc_orig_tensor is not None else None\n",
    "                    calc_recon = calc_recon_tensor.item() if calc_recon_tensor is not None else None\n",
    "\n",
    "                # --- Append results for the single random neuron ---\n",
    "                if calc_orig is not None:\n",
    "                    real_orig = orig_data['output'][0, token_pos, rand_idx].item()\n",
    "                    all_results.append({\n",
    "                        'round': round,\n",
    "                        'layer_name': layer_name, 'run_type': 'original',\n",
    "                        'error_index': rand_idx,\n",
    "                        'error_real_value': real_orig,\n",
    "                        'error_calc_value': calc_orig,\n",
    "                    })\n",
    "\n",
    "                if calc_recon is not None:\n",
    "                    real_recon = recon_data['output'][0, token_pos, rand_idx].item()\n",
    "                    all_results.append({\n",
    "                        'round': round,\n",
    "                        'layer_name': layer_name, 'run_type': 'reconstructed_with_orig_input', \n",
    "                        'error_index': rand_idx,\n",
    "                        'error_real_value': real_recon,\n",
    "                        'error_calc_value': calc_recon,\n",
    "                    })\n",
    "\n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e7f45d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_analysis_results(\n",
    "    results_list: List[Dict[str, Any]],\n",
    "    input: str,\n",
    "    recon_idx: int,\n",
    "    filename: str = \"attack_calc_error_analysis.csv\"\n",
    "):\n",
    "    if not results_list:\n",
    "        return\n",
    "        \n",
    "    df = pd.DataFrame(results_list)\n",
    "    df.insert(0, 'reconstruction_idx', recon_idx)\n",
    "    df.insert(0, 'input', input)\n",
    "    \n",
    "    # Append to the file if it exists, otherwise create it\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, mode='w', header=True, index=False)\n",
    "    \n",
    "    print(f\"--- Saved {len(df)} analysis rows to {filename} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eaf9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_attack_and_analysis_workflow(\n",
    "    model: \"LlamaForCausalLM\",\n",
    "    tokenizer: \"LlamaTokenizer\",\n",
    "    string_input: str,\n",
    "    n_reconstructions: int = 3,\n",
    "    n_test_rounds: int = 1,\n",
    "    optimization_steps: int = 1500,\n",
    "    learning_rate: float = 0.01,\n",
    "    reg_loss_factor: float = 0.001\n",
    "):\n",
    "    sample_input = tokenizer(string_input,return_tensors=\"pt\")\n",
    "    inputs_on_device = {k: v.to(model.device) for k, v in sample_input.items()}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Input: '{tokenizer.decode(inputs_on_device['input_ids'][0])}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # --- Step 1: Get Original State ---\n",
    "    with torch.no_grad():\n",
    "        original_logits = model(**inputs_on_device).logits\n",
    "    original_activations = run_model_and_capture_activations(\n",
    "        model, inputs=inputs_on_device\n",
    "    )\n",
    "    \n",
    "    # --- Step 2: Create Malicious Target ---\n",
    "    malicious_target_logits = create_malicious_output(tokenizer, original_logits)\n",
    "\n",
    "    # --- Step 3: Loop Through Reconstructions ---\n",
    "    for recon_idx in range(n_reconstructions):\n",
    "        print(f\"\\n--- [Recon {recon_idx+1}/{n_reconstructions}] Starting reconstruction ---\")\n",
    "        \n",
    "        # Initialize random embeddings to optimize\n",
    "        seq_len = inputs_on_device['input_ids'].shape[1]\n",
    "        embed_dim = model.config.hidden_size\n",
    "        reconstructed_embeds = torch.randn(\n",
    "            1, seq_len, embed_dim,\n",
    "            device=model.device, dtype=torch.float32, requires_grad=True\n",
    "        )\n",
    "        optimizer = optim.Adam([reconstructed_embeds], lr=learning_rate)\n",
    "\n",
    "        for _ in tqdm(range(optimization_steps), desc=f\"Optimizing Recon {recon_idx+1}\", leave=False):\n",
    "            optimizer.zero_grad()\n",
    "            output_logits = model(inputs_embeds=reconstructed_embeds.to(model.dtype)).logits\n",
    "            \n",
    "            # Loss calculation\n",
    "            loss = F.mse_loss(output_logits[0, -1, :].float(), malicious_target_logits.float())\n",
    "            reg_loss = reg_loss_factor * torch.mean(reconstructed_embeds ** 2)\n",
    "            total_loss = loss + reg_loss\n",
    "            \n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if total_loss.item() < 1e-4:\n",
    "                break\n",
    "        \n",
    "        print(f\"Reconstruction complete. Final Loss: {total_loss.item():.6f}\")\n",
    "\n",
    "        # --- Step 4: Get Reconstructed State ---\n",
    "        print(\"Capturing reconstructed activations...\")\n",
    "        final_embeds = reconstructed_embeds.detach().to(model.dtype)\n",
    "        reconstructed_activations = run_model_and_capture_activations(\n",
    "            model, inputs_embeds=final_embeds\n",
    "        )\n",
    "\n",
    "        # --- Step 5: Run Deep Analysis (using original input) ---\n",
    "        print(\"Running deep calculation analysis...\")\n",
    "        analysis_results = analyze_calculation_vs_real_outputs(\n",
    "                original_activations,\n",
    "                reconstructed_activations,\n",
    "                mode='min',\n",
    "                n_rounds=-1\n",
    "            )\n",
    "        \n",
    "        \n",
    "        analysis_results.extend(analyze_calculation_vs_real_outputs(\n",
    "            original_activations,\n",
    "            reconstructed_activations,\n",
    "            mode='random',\n",
    "            n_rounds=n_test_rounds\n",
    "        ))\n",
    "        # --- Step 6: Save Results ---\n",
    "        save_analysis_results(analysis_results, string_input,recon_idx)\n",
    "        \n",
    "        # Clean up memory\n",
    "        del reconstructed_activations, final_embeds, analysis_results\n",
    "        if 'clear_activations' in globals():\n",
    "            globals()['clear_activations']() # Call clear_activations if it exists\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Workflow complete.\")\n",
    "    print(f\"Results are saved in 'attack_calc_error_analysis.csv'\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fa7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    \"The capital of France is\",\n",
    "    \"The largest mammal on Earth is\",\n",
    "    \"The process of photosynthesis occurs in\",\n",
    "    \"The speed of light in a vacuum is\",\n",
    "    \"The chemical symbol for gold is\",\n",
    "    \"The human body has how many bones\",\n",
    "    \"The Great Wall of China was built to\",\n",
    "    \"Water boils at what temperature\",\n",
    "    \"The smallest unit of matter is\",\n",
    "    \"Shakespeare wrote the play\",\n",
    "    \"The currency of Japan is\",\n",
    "    \"Mount Everest is located in\",\n",
    "    \"The inventor of the telephone was\",\n",
    "    \"DNA stands for\",\n",
    "    \"The largest ocean on Earth is\",\n",
    "    \"The planet closest to the Sun is\",\n",
    "    \"Gravity was discovered by\",\n",
    "    \"The Amazon rainforest is primarily located in\",\n",
    "    \"The freezing point of water is\",\n",
    "    \"The most abundant gas in Earth's atmosphere is\",\n",
    "    \"The Mona Lisa was painted by\",\n",
    "    \"The longest river in the world is\",\n",
    "    \"Photosynthesis converts carbon dioxide and water into\",\n",
    "    \"The study of earthquakes is called\",\n",
    "    \"The first person to walk on the moon was\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> Starting Analysis for Prompt 1 (Mode: min) <<<<\n",
      "\n",
      "============================================================\n",
      "Input: '<s> The capital of France is'\n",
      "============================================================\n",
      "Registered 290 hooks.\n",
      "--- Logit Swap Attack ---\n",
      "Original top prediction: 'Paris' (ID: 3681)\n",
      "Target swap token:     'textt' (ID: 16196)\n",
      "New top prediction after swap: 'a'\n",
      "\n",
      "\n",
      "--- [Recon 1/2] Starting reconstruction ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Recon 1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# Loop through each prompt and run the full workflow\n",
    "for i, prompt in enumerate(sample_texts):\n",
    "    \n",
    "    # --- Run the 'min' mode analysis ---\n",
    "    print(f\"\\n>>>> Starting Analysis for Prompt {i+1} (Mode: min) <<<<\")\n",
    "    run_attack_and_analysis_workflow(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        string_input=prompt,\n",
    "        n_reconstructions=300,\n",
    "        n_test_rounds=5000,\n",
    "        optimization_steps=5000,\n",
    "        learning_rate=0.01,\n",
    "        reg_loss_factor=0.001\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n<<<< ALL TESTS COMPLETE >>>>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
