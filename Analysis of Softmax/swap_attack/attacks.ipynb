{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5b82ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm # For progress bars\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19f764d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99c036b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495577bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_activations_and_logits(model, inputs):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    original_hidden_states = outputs.hidden_states\n",
    "    \n",
    "    return outputs.logits, original_hidden_states\n",
    "\n",
    "def create_malicious_output(tokenizer, original_logits):\n",
    "    # the very last token in the sequence\n",
    "    last_token_logits = original_logits[0, -1, :].clone()\n",
    "    \n",
    "    # Find index of highest logit\n",
    "    correct_token_idx = torch.argmax(last_token_logits).item()\n",
    "    \n",
    "    # a very unlikely token\n",
    "    incorrect_token_idx = torch.argmin(last_token_logits).item()\n",
    "    \n",
    "    print(\"--- Logit Swap Attack ---\")\n",
    "    print(f\"Original top prediction: '{tokenizer.decode(correct_token_idx)}' (ID: {correct_token_idx})\")\n",
    "    print(f\"Target swap token:     '{tokenizer.decode(incorrect_token_idx)}' (ID: {incorrect_token_idx})\")\n",
    "    \n",
    "    # malicious target by swapping the values\n",
    "    malicious_target_logits = last_token_logits.clone()\n",
    "    correct_value = malicious_target_logits[correct_token_idx]\n",
    "    incorrect_value = malicious_target_logits[incorrect_token_idx]\n",
    "    \n",
    "    malicious_target_logits[correct_token_idx] = incorrect_value\n",
    "    malicious_target_logits[incorrect_token_idx] = correct_value\n",
    "    \n",
    "    print(f\"New top prediction after swap: '{tokenizer.decode(torch.argmax(malicious_target_logits))}'\\n\")\n",
    "    \n",
    "    return malicious_target_logits.detach()\n",
    "\n",
    "def reconstruct_internal_state(model, original_hidden_states, malicious_target_logits, epoch=200, lr=0.01):\n",
    "    # first hidden state is the input embedding\n",
    "    input_embeddings = original_hidden_states[0].detach()\n",
    "    \n",
    "    reconstructed_states = []\n",
    "    for i in range(1, len(original_hidden_states)):\n",
    "        # only need to reconstruct states for last token position\n",
    "        state = original_hidden_states[i][0, -1, :].clone().detach().to(DEVICE)\n",
    "        reconstructed_states.append(state.requires_grad_(True))\n",
    "\n",
    "    # setup the optimizer to update our list of trainable state tensors\n",
    "    optimizer = torch.optim.Adam(reconstructed_states, lr=lr)\n",
    "    loss_function = torch.nn.MSELoss()\n",
    "    \n",
    "    print(f\"--- Reconstructing Internal State (Optimizing {len(reconstructed_states)} tensors) ---\")\n",
    "    \n",
    "    for step in tqdm(range(epoch), desc=\"Optimization Progress\"):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        total_consistency_loss = 0.0\n",
    "        \n",
    "        # start with the fixed embedding of the second to last token\n",
    "        current_hidden_state = original_hidden_states[0][0, -1, :].unsqueeze(0).unsqueeze(0).detach()\n",
    "        \n",
    "        # run the forward pass layer by layer\n",
    "        for i, layer in enumerate(model.model.layers):\n",
    "            # simplifying by using the previous layers output as input\n",
    "            layer_output = layer(current_hidden_state)[0]\n",
    "            \n",
    "            # trainable guess for the input of layer `i+1`.\n",
    "            consistency_loss = loss_function(layer_output.squeeze(), reconstructed_states[i])\n",
    "            total_consistency_loss += consistency_loss\n",
    "            \n",
    "            # output of this layer becomes the input for the next\n",
    "            current_hidden_state = layer_output\n",
    "\n",
    "        # final hidden state after the last layer\n",
    "        final_hidden_state = current_hidden_state\n",
    "        \n",
    "        final_hidden_state = model.model.norm(final_hidden_state)\n",
    "        reconstructed_logits = model.lm_head(final_hidden_state).squeeze()\n",
    "        \n",
    "        # penalize the difference between our result and the malicious target\n",
    "        target_loss = loss_function(reconstructed_logits, malicious_target_logits)\n",
    "        \n",
    "        total_loss = target_loss + total_consistency_loss\n",
    "        \n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if step % 50 == 0:\n",
    "            print(f\"Step {step}: Total Loss={total_loss.item():.4f}, Target Loss={target_loss.item():.4f}, Consistency Loss={total_consistency_loss.item():.4f}\")\n",
    "\n",
    "    return [state.detach() for state in reconstructed_states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039f076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_reconstruction(original_hidden_states, reconstructed_states):\n",
    "    analysis_results = []\n",
    "    \n",
    "    # Compare the last token's hidden state across all layers\n",
    "    for i in range(len(reconstructed_states)):\n",
    "        original = original_hidden_states[i+1][0, -1, :].to(DEVICE)\n",
    "        reconstructed = reconstructed_states[i]\n",
    "        \n",
    "        # 1. Calculate overall MSE for the layer\n",
    "        mse = F.mse_loss(original, reconstructed).item()\n",
    "        \n",
    "        # 2. Find the neuron with the minimum absolute difference\n",
    "        abs_diff = torch.abs(original - reconstructed)\n",
    "        min_diff_val, min_diff_idx = torch.min(abs_diff, dim=0)\n",
    "        \n",
    "        # 3. Store detailed results for this layer\n",
    "        analysis_results.append({\n",
    "            'layer_index': i,\n",
    "            'mse_error': mse,\n",
    "            'min_abs_difference': min_diff_val.item(),\n",
    "            'min_diff_neuron_index': min_diff_idx.item()\n",
    "        })\n",
    "        \n",
    "    print(\"\\n--- Analysis of Reconstruction ---\")\n",
    "    mean_mse = np.mean([res['mse_error'] for res in analysis_results])\n",
    "    print(f\"Mean Squared Error across all layers: {mean_mse:.6f}\")\n",
    "    \n",
    "    best_layer = min(analysis_results, key=lambda x: x['min_abs_difference'])\n",
    "    print(f\"Most plausible neuron found in Layer {best_layer['layer_index']}:\")\n",
    "    print(f\"  - Neuron Index: {best_layer['min_diff_neuron_index']}\")\n",
    "    print(f\"  - Absolute Difference: {best_layer['min_abs_difference']:.8f}\")\n",
    "\n",
    "    mse_values = [res['mse_error'] for res in analysis_results]\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(mse_values, marker='o', linestyle='-')\n",
    "    plt.title(\"Reconstruction Error (MSE) vs. Layer Depth\")\n",
    "    plt.xlabel(\"Decoder Layer Index\")\n",
    "    plt.ylabel(\"Mean Squared Error\")\n",
    "    plt.grid(True)\n",
    "    save_path = 'attack_success.pdf'\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006087c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"The capital of Turkey is\"\n",
    "PROMPT = \"My favorite color is\"\n",
    "inputs = tokenizer(PROMPT, return_tensors=\"pt\").to(DEVICE)\n",
    "\n",
    "#STEP 1\n",
    "original_logits, original_hidden_states = get_original_activations_and_logits(model, inputs)\n",
    "malicious_target = create_malicious_output(tokenizer, original_logits)\n",
    "\n",
    "#STEP 2\n",
    "reconstructed_hidden_states = reconstruct_internal_state(\n",
    "    model,\n",
    "    original_hidden_states,\n",
    "    malicious_target,\n",
    "    epoch=250,\n",
    "    lr=0.05\n",
    ")\n",
    "\n",
    "#STEP 3\n",
    "analysis_data = analyze_reconstruction(original_hidden_states, reconstructed_hidden_states)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdfd030",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STEP 4: Save the analysis to a CSV file\n",
    "filename=f\"analysis_{PROMPT.replace(' ', '_')}.csv\"\n",
    "df = pd.DataFrame(analysis_data)\n",
    "df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca5354",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
