{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cb8346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf004e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"meta-llama/Llama-2-7b-hf\"  # Using Llama 2 7B\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b40becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_model_weights(model):\n",
    "    weights = {}\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        weights[name] = param.detach().cpu().clone()\n",
    "    \n",
    "    return weights\n",
    "\n",
    "def record_activations(model, input_ids, layers_to_record=None):\n",
    "    activations = {}\n",
    "    hooks = []\n",
    "    \n",
    "    def get_activation_hook(name):\n",
    "        def hook(module, input, output):\n",
    "            if isinstance(output, tuple):\n",
    "                output = output[0]\n",
    "            activations[name] = output.detach().cpu().clone()\n",
    "        return hook\n",
    "    \n",
    "    # Register hooks for specific layers\n",
    "    if layers_to_record is None:\n",
    "        # Record all transformer layers\n",
    "        layers_to_record = []\n",
    "        for i in range(len(model.model.layers)):\n",
    "            layers_to_record.extend([\n",
    "                f'model.layers.{i}.self_attn',\n",
    "                f'model.layers.{i}.mlp',\n",
    "                f'model.layers.{i}.input_layernorm',\n",
    "                f'model.layers.{i}.post_attention_layernorm'\n",
    "            ])\n",
    "    \n",
    "    # Register hooks\n",
    "    for name, module in model.named_modules():\n",
    "        if any(layer_name in name for layer_name in layers_to_record):\n",
    "            hook = module.register_forward_hook(get_activation_hook(name))\n",
    "            hooks.append(hook)\n",
    "    \n",
    "    # Forward pass\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "        logits = outputs.logits\n",
    "    \n",
    "    # Remove hooks\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "    \n",
    "    return activations, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901e5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_activation_dataset(texts, model, tokenizer, save_path='activation_dataset.pkl'):\n",
    "    dataset = []\n",
    "    \n",
    "    for i, text in enumerate(tqdm(texts, desc=\"Recording activations\")):\n",
    "        # Tokenize\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "        input_ids = inputs.input_ids.to(model.device)\n",
    "        \n",
    "        # Record activations\n",
    "        activations, logits = record_activations(model, input_ids)\n",
    "        \n",
    "        # Store data\n",
    "        dataset.append({\n",
    "            'text': text,\n",
    "            'input_ids': input_ids.cpu(),\n",
    "            'logits': logits.cpu(),\n",
    "            'activations': activations\n",
    "        })\n",
    "    \n",
    "    # Save dataset\n",
    "    with open(save_path, 'wb') as f:\n",
    "        pickle.dump(dataset, f)\n",
    "    \n",
    "    print(f\"Saved activation dataset to {save_path}\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ccb95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_TEXTS = [\n",
    "    \"The future of artificial intelligence is\",\n",
    "    \"Climate change is one of the most\",\n",
    "    \"In the field of quantum computing\",\n",
    "    \"The human brain contains approximately\",\n",
    "    \"Machine learning algorithms can be used to\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a0d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "activation_dataset = save_activation_dataset(TEST_TEXTS, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a250d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_reconstruction(target_output, weights, input_ids, \n",
    "                                  learning_rate=0.01, num_iterations=1000,\n",
    "                                  target_layers=None):\n",
    "    # Initialize reconstructed activations with random values\n",
    "    reconstructed_activations = {}\n",
    "    \n",
    "    if target_layers is None:\n",
    "        target_layers = ['model.layers.0.mlp', 'model.layers.0.self_attn']\n",
    "    \n",
    "    # Initialize activations for target layers\n",
    "    batch_size = input_ids.shape[0]\n",
    "    seq_len = input_ids.shape[1]\n",
    "    hidden_size = 4096  # Llama 2 7B hidden size\n",
    "    \n",
    "    for layer_name in target_layers:\n",
    "        # Initialize with random noise\n",
    "        reconstructed_activations[layer_name] = torch.randn(\n",
    "            batch_size, seq_len, hidden_size, \n",
    "            requires_grad=True, dtype=torch.float32\n",
    "        )\n",
    "    \n",
    "    # Optimization loop\n",
    "    losses = []\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        # Forward pass simulation using reconstructed activations\n",
    "        ##########################################################\n",
    "        # This is a simplified version\n",
    "        ##########################################################\n",
    "        # Calculate loss between predicted output and target output\n",
    "        loss = 0\n",
    "        \n",
    "        # For each layer, simulate the computation\n",
    "        for layer_name, activation in reconstructed_activations.items():\n",
    "            if 'mlp' in layer_name:\n",
    "                # Get MLP weights\n",
    "                layer_idx = int(layer_name.split('.')[2])\n",
    "                \n",
    "                # Simplified MLP forward pass\n",
    "                # In reality, you'd need to properly implement the full computation\n",
    "                if f'model.layers.{layer_idx}.mlp.gate_proj.weight' in weights:\n",
    "                    gate_weight = weights[f'model.layers.{layer_idx}.mlp.gate_proj.weight']\n",
    "                    up_weight = weights[f'model.layers.{layer_idx}.mlp.up_proj.weight']\n",
    "                    down_weight = weights[f'model.layers.{layer_idx}.mlp.down_proj.weight']\n",
    "                    \n",
    "                    # Compute MLP output (simplified)\n",
    "                    # Real implementation would need proper attention outputs as input\n",
    "                    hidden = F.silu(activation @ gate_weight.t()) * (activation @ up_weight.t())\n",
    "                    output = hidden @ down_weight.t()\n",
    "                    \n",
    "                    # Add to loss (comparing with target)\n",
    "                    loss += F.mse_loss(output, target_output)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update reconstructed activations\n",
    "        with torch.no_grad():\n",
    "            for layer_name, activation in reconstructed_activations.items():\n",
    "                if activation.grad is not None:\n",
    "                    activation -= learning_rate * activation.grad\n",
    "                    activation.grad.zero_()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        if iteration % 100 == 0:\n",
    "            print(f\"Iteration {iteration}, Loss: {loss.item():.6f}\")\n",
    "    \n",
    "    return reconstructed_activations, losses\n",
    "\n",
    "def compare_activations(real_activations, reconstructed_activations, layer_name):\n",
    "    real = real_activations[layer_name]\n",
    "    reconstructed = reconstructed_activations[layer_name]\n",
    "    \n",
    "    # Convert to same device and dtype\n",
    "    real = real.float()\n",
    "    reconstructed = reconstructed.detach().cpu().float()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mse = F.mse_loss(reconstructed, real).item()\n",
    "    \n",
    "    # Cosine similarity\n",
    "    real_flat = real.flatten()\n",
    "    recon_flat = reconstructed.flatten()\n",
    "    cosine_sim = F.cosine_similarity(real_flat.unsqueeze(0), recon_flat.unsqueeze(0)).item()\n",
    "    \n",
    "    # Correlation\n",
    "    correlation = np.corrcoef(real_flat.numpy(), recon_flat.numpy())[0, 1]\n",
    "    \n",
    "    return {\n",
    "        'mse': mse,\n",
    "        'cosine_similarity': cosine_sim,\n",
    "        'correlation': correlation\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe50315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run reconstruction attack\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RUNNING ACTIVATION RECONSTRUCTION ATTACK\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b988955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract model weights\n",
    "print(\"Extracting model weights...\")\n",
    "model_weights = extract_model_weights(model)\n",
    "print(f\"Extracted {len(model_weights)} weight tensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677d9865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a sample from dataset\n",
    "sample_idx = 0\n",
    "sample = activation_dataset[sample_idx]\n",
    "\n",
    "print(f\"\\nTarget text: {sample['text']}\")\n",
    "print(f\"Input shape: {sample['input_ids'].shape}\")\n",
    "print(f\"Output shape: {sample['logits'].shape}\")\n",
    "\n",
    "# Select layers to reconstruct\n",
    "target_layers = [\n",
    "    'model.layers.0.mlp',\n",
    "    'model.layers.0.self_attn',\n",
    "    'model.layers.1.mlp'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93f7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run gradient descent reconstruction\n",
    "print(f\"\\nReconstructing activations for layers: {target_layers}\")\n",
    "reconstructed_acts, losses = gradient_descent_reconstruction(\n",
    "    target_output=sample['logits'],\n",
    "    weights=model_weights,\n",
    "    input_ids=sample['input_ids'],\n",
    "    learning_rate=0.001,\n",
    "    num_iterations=500,\n",
    "    target_layers=target_layers\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_acts = {k: v for k, v in sample['activations'].items() \n",
    "             if any(target in k for target in target_layers)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb9014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save reconstruction results\n",
    "results = {\n",
    "    'text': sample['text'],\n",
    "    'input_ids': sample['input_ids'],\n",
    "    'real_activations': real_acts,\n",
    "    'reconstructed_activations': {k: v.detach().cpu() for k, v in reconstructed_acts.items()},\n",
    "    'losses': losses,\n",
    "    'metrics': {}\n",
    "}\n",
    "\n",
    "for layer_name in reconstructed_acts.keys():\n",
    "    if layer_name in real_acts:\n",
    "        results['metrics'][layer_name] = compare_activations(\n",
    "            real_acts, reconstructed_acts, layer_name\n",
    "        )\n",
    "\n",
    "with open('reconstruction_results.pkl', 'wb') as f:\n",
    "    pickle.dump(results, f)\n",
    "\n",
    "print(\"\\nReconstruction attack completed!\")\n",
    "print(\"Results saved to reconstruction_results.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2183bac9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6167c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6916e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4a867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec680b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
