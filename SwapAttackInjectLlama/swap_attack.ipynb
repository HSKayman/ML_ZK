{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0de5e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import LlamaTokenizer, LlamaForCausalLM\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import gc\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Any, Optional, Tuple\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed85bda9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976630caa90143ad924c2808492be499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from huggingface_hub import login\n",
    "# login()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "996ac4a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device('cpu')#'cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c302d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(MODEL_PATH)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2680ffe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc8853854d84e168d7e23116a5cd86f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=11008, bias=False)\n",
       "          (down_proj): Linear(in_features=11008, out_features=4096, bias=False)\n",
       "          (act_fn): SiLUActivation()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LlamaForCausalLM.from_pretrained(\n",
    "    MODEL_PATH,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=DEVICE\n",
    ")\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f158c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ExecutionTracer:\n",
    "#     def __init__(self):\n",
    "#         self.execution_order = []\n",
    "#         self.counter = 0\n",
    "    \n",
    "#     def __call__(self, module, input, output):\n",
    "#         self.counter += 1\n",
    "#         module_name = None\n",
    "#         for name, mod in model.named_modules():\n",
    "#             if mod is module:\n",
    "#                 module_name = name\n",
    "#                 break\n",
    "        \n",
    "#         self.execution_order.append({\n",
    "#             'order': self.counter,\n",
    "#             'name': module_name,\n",
    "#             'type': module.__class__.__name__,\n",
    "#             'input_shape': input[0].shape if isinstance(input, tuple) and len(input) > 0 else 'special',\n",
    "#             'output_shape': output.shape if hasattr(output, 'shape') else type(output).__name__\n",
    "#         })\n",
    "\n",
    "# # Create tracer and register hooks\n",
    "# tracer = ExecutionTracer()\n",
    "# hooks = []\n",
    "# for name, module in model.named_modules():\n",
    "#     # Skip container modules\n",
    "#     if len(list(module.children())) == 0:\n",
    "#         hooks.append(module.register_forward_hook(tracer))\n",
    "\n",
    "# # Run a forward pass\n",
    "# input_ids = tokenizer(\"Hello world\", return_tensors=\"pt\").input_ids\n",
    "# with torch.no_grad():\n",
    "#     output = model(input_ids)\n",
    "\n",
    "# # Print execution order\n",
    "# print(\"LAYER EXECUTION ORDER:\")\n",
    "# print(\"=\"*100)\n",
    "# for item in tracer.execution_order:\n",
    "#     print(f\"{item['order']:3d}. {item['name']:<50} | {item['type']:<20} | {item['input_shape']} → {item['output_shape']}\")\n",
    "\n",
    "# # Clean up hooks\n",
    "# for hook in hooks:\n",
    "#     hook.remove()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d95dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Distance Metrics for Comparing Logit Distributions\n",
    "# =============================================================================\n",
    "\n",
    "def compute_l2_distance(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "    # Compute L2 (Euclidean) distance between two logit vectors\n",
    "    return torch.norm(original_logits - perturbed_logits, p=2).item()\n",
    "\n",
    "def compute_cosine_distance(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "    # Compute cosine distance (1 - cosine_similarity) between two logit vectors\n",
    "    cos_sim = F.cosine_similarity(original_logits.unsqueeze(0), perturbed_logits.unsqueeze(0))\n",
    "    return (1 - cos_sim).item()\n",
    "\n",
    "def compute_kl_divergence(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "    # Compute KL divergence: KL(original || perturbed) after softmax\n",
    "    original_probs = F.softmax(original_logits, dim=-1)\n",
    "    perturbed_log_probs = F.log_softmax(perturbed_logits, dim=-1)\n",
    "    # KL(P || Q) = sum(P * log(P/Q)) = sum(P * (log_P - log_Q))\n",
    "    kl_div = F.kl_div(perturbed_log_probs, original_probs, reduction='sum')\n",
    "    return kl_div.item()\n",
    "\n",
    "def compute_js_divergence(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> float:\n",
    "   # Compute Jensen-Shannon divergence: 0.5*KL(P||M) + 0.5*KL(Q||M) where M = 0.5*(P+Q).\n",
    "    P = F.softmax(original_logits, dim=-1)\n",
    "    Q = F.softmax(perturbed_logits, dim=-1)\n",
    "    M = 0.5 * (P + Q)\n",
    "    \n",
    "    # KL(P || M)\n",
    "    kl_pm = F.kl_div(M.log(), P, reduction='sum')\n",
    "    # KL(Q || M)\n",
    "    kl_qm = F.kl_div(M.log(), Q, reduction='sum')\n",
    "    \n",
    "    js_div = 0.5 * (kl_pm + kl_qm)\n",
    "    return js_div.item()\n",
    "\n",
    "def compute_all_distances(original_logits: torch.Tensor, perturbed_logits: torch.Tensor) -> Dict[str, float]:\n",
    "    # Compute all distance metrics between original and perturbed logits.\n",
    "    return {\n",
    "        'l2_distance': compute_l2_distance(original_logits, perturbed_logits),\n",
    "        'cosine_distance': compute_cosine_distance(original_logits, perturbed_logits),\n",
    "        'kl_divergence': compute_kl_divergence(original_logits, perturbed_logits),\n",
    "        'js_divergence': compute_js_divergence(original_logits, perturbed_logits),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "784f29b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables for detailed activation capture\n",
    "captured_activations = {}\n",
    "current_hooks = []\n",
    "hook_errors = []\n",
    "\n",
    "def clear_activations():\n",
    "    global captured_activations\n",
    "    captured_activations.clear()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "def remove_all_hooks():\n",
    "    global current_hooks\n",
    "    for hook in current_hooks:\n",
    "        try:\n",
    "            hook.remove()\n",
    "        except:\n",
    "            pass\n",
    "    current_hooks.clear()\n",
    "\n",
    "def get_activation_hook(name):\n",
    "    def hook(module, input, output):\n",
    "        global hook_errors\n",
    "        try:\n",
    "            # Handle different output types\n",
    "            if output is None:\n",
    "                activation = None\n",
    "            elif isinstance(output, tuple):\n",
    "                activation = output[0]\n",
    "            elif hasattr(output, 'last_hidden_state'):\n",
    "                # Handle model output objects\n",
    "                activation = output.last_hidden_state\n",
    "            else:\n",
    "                activation = output\n",
    "            \n",
    "            # Handle input\n",
    "            input_tensor = input[0] if isinstance(input, tuple) and len(input) > 0 else None\n",
    "\n",
    "            # Safely detach and move to CPU\n",
    "            def safe_detach_cpu(tensor):\n",
    "                if tensor is None:\n",
    "                    return None\n",
    "                try:\n",
    "                    # Check if tensor is on meta device\n",
    "                    if hasattr(tensor, 'device') and str(tensor.device) == 'meta':\n",
    "                        return None\n",
    "                    return tensor.detach().cpu()\n",
    "                except Exception as e:\n",
    "                    hook_errors.append(f\"Detach error in {name}: {str(e)}\")\n",
    "                    return None\n",
    "\n",
    "            captured_activations[name] = {\n",
    "                'output': safe_detach_cpu(activation),\n",
    "                'input': safe_detach_cpu(input_tensor),\n",
    "                'weight': safe_detach_cpu(module.weight) if hasattr(module, 'weight') and module.weight is not None else None,\n",
    "                'bias': safe_detach_cpu(module.bias) if hasattr(module, 'bias') and module.bias is not None else None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Hook error in {name}: {str(e)}\"\n",
    "            hook_errors.append(error_msg)\n",
    "            captured_activations[name] = {'output': None, 'input': None, 'weight': None, 'bias': None}\n",
    "    return hook\n",
    "\n",
    "def register_llama_hooks(model):\n",
    "    global current_hooks\n",
    "    remove_all_hooks() # clear any old hooks first\n",
    "    hook_errors.clear()\n",
    "\n",
    "    total_layers = len(model.model.layers)\n",
    "\n",
    "    for i in range(total_layers):\n",
    "        layer = model.model.layers[i]\n",
    "        layer_prefix = f\"layer_{i}\"\n",
    "        components = [\n",
    "            (layer.self_attn.q_proj, f\"{layer_prefix}_attention_q\"), (layer.self_attn.k_proj, f\"{layer_prefix}_attention_k\"),\n",
    "            (layer.self_attn.v_proj, f\"{layer_prefix}_attention_v\"), (layer.self_attn.o_proj, f\"{layer_prefix}_attention_output\"),\n",
    "            (layer.mlp.gate_proj, f\"{layer_prefix}_mlp_gate\"), (layer.mlp.up_proj, f\"{layer_prefix}_mlp_up\"),\n",
    "            (layer.mlp.down_proj, f\"{layer_prefix}_mlp_down\"), (layer.input_layernorm, f\"{layer_prefix}_input_norm\"),\n",
    "            (layer.post_attention_layernorm, f\"{layer_prefix}_post_attn_norm\"),\n",
    "        ]\n",
    "        for module, name in components:\n",
    "            current_hooks.append(module.register_forward_hook(get_activation_hook(name)))\n",
    "    \n",
    "    current_hooks.append(model.model.norm.register_forward_hook(get_activation_hook(\"final_norm\")))\n",
    "    current_hooks.append(model.lm_head.register_forward_hook(get_activation_hook(\"lm_head\")))\n",
    "    print(f\"Registered {len(current_hooks)} hooks.\")\n",
    "\n",
    "def run_model_and_capture_activations(model, inputs=None, inputs_embeds=None):\n",
    "    global hook_errors\n",
    "    clear_activations()\n",
    "    register_llama_hooks(model)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if inputs is not None:\n",
    "            _ = model(**inputs)\n",
    "        elif inputs_embeds is not None:\n",
    "            _ = model(inputs_embeds=inputs_embeds)\n",
    "        else:\n",
    "            raise ValueError(\"Either inputs or inputs_embeds must be provided.\")\n",
    "            \n",
    "    remove_all_hooks()\n",
    "    \n",
    "    # Print any hook errors that occurred\n",
    "    if hook_errors:\n",
    "        print(f\"WARNING: {len(hook_errors)} hook errors occurred:\")\n",
    "        for err in hook_errors[:5]:\n",
    "            print(f\"  - {err}\")\n",
    "        if len(hook_errors) > 5:\n",
    "            print(f\"  ... and {len(hook_errors) - 5} more\")\n",
    "    \n",
    "    # return a copy of the captured activations\n",
    "    return captured_activations.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2e5c5a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neuron Perturbation Sensitivity Analysis\n",
    "\n",
    "def get_top_k_predictions(logits: torch.Tensor, tokenizer, k: int = 3) -> Dict[str, Any]:\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    top_logits, top_indices = torch.topk(logits, k)\n",
    "    top_probs = probs[top_indices]\n",
    "    \n",
    "    result = {}\n",
    "    for i in range(k):\n",
    "        idx = top_indices[i].item()\n",
    "        word = tokenizer.decode([idx])\n",
    "        result[f'top{i+1}_word'] = word\n",
    "        result[f'top{i+1}_index'] = idx\n",
    "        result[f'top{i+1}_logit'] = top_logits[i].item()\n",
    "        result[f'top{i+1}_softmax'] = top_probs[i].item()\n",
    "    \n",
    "    return result\n",
    "\n",
    "def analyze_neuron_perturbation_sensitivity(\n",
    "    model: \"LlamaForCausalLM\",\n",
    "    tokenizer: \"LlamaTokenizer\",\n",
    "    final_norm_activations: torch.Tensor,\n",
    "    original_logits: torch.Tensor,\n",
    "    k_values: List[int],\n",
    "    perturbation_deltas: List[float] = None,\n",
    "    num_trials_per_k: int = 10,\n",
    ") -> List[Dict[str, Any]]:\n",
    "   \n",
    "    if perturbation_deltas is None:\n",
    "        perturbation_deltas = [0.1]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Get dimensions\n",
    "    seq_len = final_norm_activations.shape[1]\n",
    "    hidden_size = final_norm_activations.shape[2] \n",
    "    last_token_pos = seq_len - 1\n",
    "    \n",
    "    # Get original logits for the last token\n",
    "    original_last_logits = original_logits[0, last_token_pos, :].float()\n",
    "    \n",
    "    # Get top-3 predictions for original logits (same for all trials)\n",
    "    original_top3 = get_top_k_predictions(original_last_logits, tokenizer, k=3)\n",
    "    # Prefix with 'orig_' to distinguish from perturbed\n",
    "    original_top3_prefixed = {f'orig_{k}': v for k, v in original_top3.items()}\n",
    "    \n",
    "    # Get lm_head weights (and bias if present)\n",
    "    lm_head_weight = model.lm_head.weight.detach()\n",
    "    lm_head_bias = None\n",
    "    if hasattr(model.lm_head, 'bias') and model.lm_head.bias is not None:\n",
    "        lm_head_bias = model.lm_head.bias.detach()\n",
    "    \n",
    "    # Iterate over all combinations of K and delta\n",
    "    for delta in perturbation_deltas:\n",
    "        for k in k_values:\n",
    "            if k > hidden_size:\n",
    "                print(f\"Warning: K={k} exceeds hidden_size={hidden_size}, skipping.\")\n",
    "                continue\n",
    "                \n",
    "            for trial in range(num_trials_per_k):\n",
    "                # Clone the activations\n",
    "                perturbed_activations = final_norm_activations.clone()\n",
    "                \n",
    "                # Randomly select K neuron indices to perturb \n",
    "                neuron_indices = torch.randperm(hidden_size)[:k].tolist()\n",
    "                \n",
    "                # Apply perturbation: add delta to selected neurons\n",
    "                for idx in neuron_indices:\n",
    "                    perturbed_activations[0, last_token_pos, idx] += delta\n",
    "                \n",
    "                # Compute perturbed logits through lm_head \n",
    "                perturbed_last_activations = perturbed_activations[0, last_token_pos, :].to(lm_head_weight.device)\n",
    "                perturbed_logits = F.linear(perturbed_last_activations, lm_head_weight, lm_head_bias).float()\n",
    "                \n",
    "                # Compute all distance metrics\n",
    "                distances = compute_all_distances(original_last_logits.to(perturbed_logits.device), perturbed_logits)\n",
    "                \n",
    "                # Get top-3 predictions for perturbed logits\n",
    "                perturbed_top3 = get_top_k_predictions(perturbed_logits, tokenizer, k=3)\n",
    "                # Prefix with 'pert_' to distinguish from original\n",
    "                perturbed_top3_prefixed = {f'pert_{k}': v for k, v in perturbed_top3.items()}\n",
    "                \n",
    "                # Record results\n",
    "                result = {\n",
    "                    'num_neurons_changed': k,\n",
    "                    'trial': trial,\n",
    "                    'perturbation_value': delta,\n",
    "                    'neuron_indices': str(neuron_indices),  \n",
    "                    'total_neurons': hidden_size,\n",
    "                    'soundness_ratio': k / hidden_size,\n",
    "                    **distances,\n",
    "                    **original_top3_prefixed,\n",
    "                    **perturbed_top3_prefixed,\n",
    "                }\n",
    "                results.append(result)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f45d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_perturbation_results(\n",
    "    results_list: List[Dict[str, Any]],\n",
    "    input_text: str,\n",
    "    input_id: int,\n",
    "    filename: str = \"neuron_perturbation_analysis.csv\"\n",
    "):\n",
    "    # Save perturbation analysis results to CSV.\n",
    "    if not results_list:\n",
    "        print(\"No results to save.\")\n",
    "        return\n",
    "        \n",
    "    df = pd.DataFrame(results_list)\n",
    "    df.insert(0, 'input_id', input_id)\n",
    "    #df.insert(0, 'input_text', input_text)\n",
    "    \n",
    "    # Append to the file if it exists, otherwise create it\n",
    "    if os.path.exists(filename):\n",
    "        df.to_csv(filename, mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv(filename, mode='w', header=True, index=False)\n",
    "    \n",
    "    print(f\"--- Saved {len(df)} perturbation analysis rows to {filename} ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22eaf9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Main Workflow: Neuron Perturbation Sensitivity Analysis\n",
    "# =============================================================================\n",
    "\n",
    "def run_perturbation_analysis_workflow(\n",
    "    model: \"LlamaForCausalLM\",\n",
    "    tokenizer: \"LlamaTokenizer\",\n",
    "    string_input: List,  # [input_id, input_text]\n",
    "    k_values: List[int] = None,\n",
    "    perturbation_deltas: List[float] = None,\n",
    "    num_trials_per_k: int = 10,\n",
    "):\n",
    "\n",
    "    input_id, input_text = string_input\n",
    "    sample_input = tokenizer(input_text, return_tensors=\"pt\")\n",
    "    inputs_on_device = {k: v.to(model.device) for k, v in sample_input.items()}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Input ID: {input_id}\")\n",
    "    print(f\"Input: '{tokenizer.decode(inputs_on_device['input_ids'][0])}'\")\n",
    "    print(f\"K values to test: {k_values}\")\n",
    "    print(f\"Perturbation deltas: {perturbation_deltas}\")\n",
    "    print(f\"Trials per (K, delta): {num_trials_per_k}\")\n",
    "    print(f\"Total experiments: {len(k_values) * len(perturbation_deltas) * num_trials_per_k}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # --- Step 1: Get Original Logits and Activations ---\n",
    "    print(\"Running forward pass to capture original state...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        original_logits = model(**inputs_on_device).logits\n",
    "    \n",
    "    # Capture activations (we only need final_norm)\n",
    "    original_activations = run_model_and_capture_activations(model, inputs=inputs_on_device)\n",
    "    \n",
    "    # Get final_norm output (layer n-1, input to lm_head)\n",
    "    try:\n",
    "        final_norm_output = original_activations['final_norm']['output'].to(model.device)\n",
    "    except KeyError:\n",
    "        print(\"ERROR: Could not find 'final_norm' in activations.\")\n",
    "        return\n",
    "    \n",
    "    hidden_size = final_norm_output.shape[2]\n",
    "    print(f\"Final norm output shape: {final_norm_output.shape}\")\n",
    "    print(f\"Hidden size (N = total neurons): {hidden_size}\")\n",
    "    \n",
    "    # Show original prediction\n",
    "    last_token_logits = original_logits[0, -1, :]\n",
    "    top_token_idx = torch.argmax(last_token_logits).item()\n",
    "    print(f\"Original top prediction: '{tokenizer.decode(top_token_idx)}' (ID: {top_token_idx})\")\n",
    "    \n",
    "    # --- Step 2: Run Perturbation Analysis ---\n",
    "    print(f\"\\nRunning perturbation analysis...\")\n",
    "    \n",
    "    results = analyze_neuron_perturbation_sensitivity(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        final_norm_activations=final_norm_output,\n",
    "        original_logits=original_logits,\n",
    "        k_values=k_values,\n",
    "        perturbation_deltas=perturbation_deltas,\n",
    "        num_trials_per_k=num_trials_per_k,\n",
    "    )\n",
    "    \n",
    "    # --- Step 3: Save Results ---\n",
    "    save_perturbation_results(results, input_text, input_id)\n",
    "    \n",
    "    # --- Step 4: Print Summary ---\n",
    "    print(f\"\\n--- Summary for Input {input_id} ---\")\n",
    "    df = pd.DataFrame(results)\n",
    "    # Group by both perturbation_value and num_neurons_changed\n",
    "    summary = df.groupby(['perturbation_value', 'num_neurons_changed']).agg({\n",
    "        'l2_distance': ['mean', 'std'],\n",
    "        'cosine_distance': ['mean', 'std'],\n",
    "        'kl_divergence': ['mean', 'std'],\n",
    "        'js_divergence': ['mean', 'std'],\n",
    "        'soundness_ratio': 'first'\n",
    "    }).round(6)\n",
    "    print(summary)\n",
    "    \n",
    "    # Clean up\n",
    "    del original_activations, final_norm_output, results\n",
    "    clear_activations()\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"Analysis complete.\")\n",
    "    print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56fa7cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_texts = [\n",
    "    [1,\"The capital of France is\"],\n",
    "    [2,\"The largest mammal on Earth is\"],\n",
    "    [3,\"The process of photosynthesis occurs in\"],\n",
    "    [4,\"The speed of light in a vacuum is\"],\n",
    "    [5,\"The chemical symbol for gold is\"],\n",
    "    [6,\"The human body has how many bones\"],\n",
    "    [7,\"The Great Wall of China was built to\"],\n",
    "    [8,\"Water boils at what temperature\"],\n",
    "    [9,\"The smallest unit of matter is\"],\n",
    "    [10,\"Shakespeare wrote the play\"],\n",
    "    [11,\"The currency of Japan is\"],\n",
    "    [12,\"Mount Everest is located in\"],\n",
    "    [13,\"The inventor of the telephone was\"],\n",
    "    [14,\"DNA stands for\"],\n",
    "    [15,\"The largest ocean on Earth is\"],\n",
    "    [16,\"The planet closest to the Sun is\"],\n",
    "    [17,\"Gravity was discovered by\"],\n",
    "    [18,\"The Amazon rainforest is primarily located in\"],\n",
    "    [19,\"The freezing point of water is\"],\n",
    "    [20,\"The most abundant gas in Earth's atmosphere is\"],\n",
    "    [21,\"The Mona Lisa was painted by\"],\n",
    "    [22,\"The longest river in the world is\"],\n",
    "    [23,\"Photosynthesis converts carbon dioxide and water into\"],\n",
    "    [24,\"The study of earthquakes is called\"],\n",
    "    [25,\"The first person to walk on the moon was\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670b639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>> Starting Analysis for Prompt 1 (Mode: min) <<<<\n",
      "\n",
      "============================================================\n",
      "Input: '<s> The capital of France is'\n",
      "============================================================\n",
      "Registered 290 hooks.\n",
      "--- Logit Swap Attack ---\n",
      "Original top prediction: 'Paris' (ID: 3681)\n",
      "Target swap token:     'textt' (ID: 16196)\n",
      "New top prediction after swap: 'a'\n",
      "\n",
      "\n",
      "--- [Recon 1/2] Starting reconstruction ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimizing Recon 1:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Run Perturbation Analysis on All Sample Texts\n",
    "# =============================================================================\n",
    "\n",
    "# Configuration\n",
    "K_VALUES = [i for i in range(1, 1025)] # Number of neurons to perturb\n",
    "PERTURBATION_DELTAS = [i*0.1 for i in range(-100, 101)]  # Multiple delta values to test\n",
    "NUM_TRIALS_PER_K = [5000]  # Number of random trials per (K, delta) combination\n",
    "\n",
    "# Loop through each prompt\n",
    "for i, prompt in enumerate(sample_texts):\n",
    "    print(f\"\\n>>>> Starting Perturbation Analysis for Prompt {i+1}/{len(sample_texts)} <<<<\")\n",
    "    \n",
    "    run_perturbation_analysis_workflow(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        string_input=prompt,\n",
    "        k_values=K_VALUES,\n",
    "        perturbation_deltas=PERTURBATION_DELTAS,\n",
    "        num_trials_per_k=NUM_TRIALS_PER_K,\n",
    "    )\n",
    "\n",
    "print(\"\\n\\n<<<< ALL PERTURBATION ANALYSES COMPLETE >>>>\")\n",
    "print(f\"Results saved to 'neuron_perturbation_analysis.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ca1d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running quick test with multiple deltas...\n",
      "\n",
      "============================================================\n",
      "Input ID: 1\n",
      "Input: '<s> The capital of France is'\n",
      "K values to test: [1, 4, 16, 64]\n",
      "Perturbation deltas: [110]\n",
      "Trials per (K, delta): 3\n",
      "Total experiments: 12\n",
      "============================================================\n",
      "Running forward pass to capture original state...\n",
      "Registered 290 hooks.\n",
      "Final norm output shape: torch.Size([1, 6, 4096])\n",
      "Hidden size (N = total neurons): 4096\n",
      "Original top prediction: 'Paris' (ID: 3681)\n",
      "\n",
      "Running perturbation analysis...\n",
      "--- Saved 12 perturbation analysis rows to neuron_perturbation_analysis.csv ---\n",
      "\n",
      "--- Summary for Input 1 ---\n",
      "                                        l2_distance             \\\n",
      "                                               mean        std   \n",
      "perturbation_value num_neurons_changed                           \n",
      "110                1                     317.804759   9.647455   \n",
      "                   4                     662.068156  32.622029   \n",
      "                   16                   1342.695435  50.912951   \n",
      "                   64                   2603.869548  35.933248   \n",
      "\n",
      "                                       cosine_distance            \\\n",
      "                                                  mean       std   \n",
      "perturbation_value num_neurons_changed                             \n",
      "110                1                          0.211457  0.018753   \n",
      "                   4                          0.392774  0.012706   \n",
      "                   16                         0.599259  0.094524   \n",
      "                   64                         0.808402  0.078759   \n",
      "\n",
      "                                       kl_divergence            js_divergence  \\\n",
      "                                                mean        std          mean   \n",
      "perturbation_value num_neurons_changed                                          \n",
      "110                1                        0.144263   0.043195      0.027914   \n",
      "                   4                        3.408314   1.948616      0.477797   \n",
      "                   16                      14.706082   2.196191      0.691939   \n",
      "                   64                      40.190725  29.602918      0.693114   \n",
      "\n",
      "                                                 soundness_ratio  \n",
      "                                             std           first  \n",
      "perturbation_value num_neurons_changed                            \n",
      "110                1                    0.004930        0.000244  \n",
      "                   4                    0.226160        0.000977  \n",
      "                   16                   0.000432        0.003906  \n",
      "                   64                   0.000067        0.015625  \n",
      "\n",
      "============================================================\n",
      "Analysis complete.\n",
      "============================================================\n",
      "\n",
      "Test complete! Check 'neuron_perturbation_analysis.csv' for output.\n"
     ]
    }
   ],
   "source": [
    "# # =============================================================================\n",
    "# # Quick Test: Run on a single input to verify output\n",
    "# # =============================================================================\n",
    "\n",
    "# # Test with just the first prompt, fewer K values, and multiple deltas\n",
    "# TEST_PROMPT = [1, \"The capital of France is\"]\n",
    "# TEST_K_VALUES = [1, 4, 16, 64]  \n",
    "# TEST_DELTAS = [110]  \n",
    "# TEST_TRIALS = 3  \n",
    "\n",
    "# print(\"Running quick test with multiple deltas...\")\n",
    "# run_perturbation_analysis_workflow(\n",
    "#     model=model,\n",
    "#     tokenizer=tokenizer,\n",
    "#     string_input=TEST_PROMPT,\n",
    "#     k_values=TEST_K_VALUES,\n",
    "#     perturbation_deltas=TEST_DELTAS,\n",
    "#     num_trials_per_k=TEST_TRIALS,\n",
    "# )\n",
    "# print(\"\\nTest complete! Check 'neuron_perturbation_analysis.csv' for output.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dea5844",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
